<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>161250 Data Analysis - Chapter 6: Models with a Single Continuous Predictor</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../studyguide/7-multiple.html" rel="next">
<link href="../studyguide/5-tabulated.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

<script src="../site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="../site_libs/lightable-0.0.1/lightable.css" rel="stylesheet">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">161250 Data Analysis</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../slides.html" rel="" target="">
 <span class="menu-text">Slides</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="../studyguide/index.html" rel="" target="" aria-current="page">
 <span class="menu-text">Study Guide</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../workshops/ws01.html" rel="" target="">
 <span class="menu-text">Workshops</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-extra-code" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Extra Code</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-extra-code">    
        <li>
    <a class="dropdown-item" href="../exercises/Chap2more.R" rel="" target="">
 <span class="dropdown-text">Ex2</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../exercises/Chap3more.R" rel="" target="">
 <span class="dropdown-text">Ex3</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../exercises/Chap4more.R" rel="" target="">
 <span class="dropdown-text">Ex4</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../exercises/Chap5more.R" rel="" target="">
 <span class="dropdown-text">Ex5</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../exercises/Chap6more.R" rel="" target="">
 <span class="dropdown-text">Ex6</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../exercises/Chap7more.R" rel="" target="">
 <span class="dropdown-text">Ex7</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../exercises/Chap8more.R" rel="" target="">
 <span class="dropdown-text">Ex8</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../studyguide/index.html">Study Guide</a></li><li class="breadcrumb-item"><a href="../studyguide/6-single.html">Chapter 6: Models with a Single Continuous Predictor</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../studyguide/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Study Guide</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../studyguide/1-data-collection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 1: Data Collection and Quality Issues</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../studyguide/2-eda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 2: Exploratory Data Analysis (EDA)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../studyguide/3-probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 3: Probability Concepts and Distributions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../studyguide/4-inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 4: Statistical Inference</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../studyguide/5-tabulated.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 5: Tabulated Counts</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../studyguide/6-single.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Chapter 6: Models with a Single Continuous Predictor</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../studyguide/7-multiple.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 7: Models with Multiple Continuous Predictors</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../studyguide/8-anova.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 8: Analysis of Variance (ANOVA) and Covariance (ANCOVA)</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#modelling-bivariate-data" id="toc-modelling-bivariate-data" class="nav-link active" data-scroll-target="#modelling-bivariate-data">Modelling bivariate data</a></li>
  <li><a href="#simple-regression" id="toc-simple-regression" class="nav-link" data-scroll-target="#simple-regression">Simple Regression</a>
  <ul class="collapse">
  <li><a href="#displaying-interpreting-the-fitted-model" id="toc-displaying-interpreting-the-fitted-model" class="nav-link" data-scroll-target="#displaying-interpreting-the-fitted-model">Displaying &amp; Interpreting the Fitted Model</a></li>
  <li><a href="#model-summaries" id="toc-model-summaries" class="nav-link" data-scroll-target="#model-summaries">Model Summaries</a></li>
  <li><a href="#prediction-and-estimation" id="toc-prediction-and-estimation" class="nav-link" data-scroll-target="#prediction-and-estimation">Prediction and Estimation</a></li>
  </ul></li>
  <li><a href="#residual-analysis-for-regression" id="toc-residual-analysis-for-regression" class="nav-link" data-scroll-target="#residual-analysis-for-regression">Residual Analysis for Regression</a>
  <ul class="collapse">
  <li><a href="#improving-simple-regression" id="toc-improving-simple-regression" class="nav-link" data-scroll-target="#improving-simple-regression">Improving Simple Regression</a></li>
  </ul></li>
  <li><a href="#robust-model-fitting" id="toc-robust-model-fitting" class="nav-link" data-scroll-target="#robust-model-fitting">Robust Model Fitting</a>
  <ul class="collapse">
  <li><a href="#cross-validation-cv" id="toc-cross-validation-cv" class="nav-link" data-scroll-target="#cross-validation-cv">Cross Validation (CV)</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a>
  <ul class="collapse">
  <li><a href="#main-points" id="toc-main-points" class="nav-link" data-scroll-target="#main-points">Main points</a></li>
  <li><a href="#models-related-to-simple-regression-model" id="toc-models-related-to-simple-regression-model" class="nav-link" data-scroll-target="#models-related-to-simple-regression-model">Models Related to Simple Regression Model</a></li>
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="6-single.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Chapter 6: Models with a Single Continuous Predictor</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<blockquote class="blockquote">
<p>“<em>The sciences do not try to explain, they hardly even try to interpret, they mainly make models. By a model is meant a mathematical construct which, with the addition of verbal interpretations, describes observed phenomena. The justification of such a mathematical construct is solely and precisely that it is expected to work.</em>”<br> — von Neumann</p>
</blockquote>
<section id="modelling-bivariate-data" class="level1">
<h1>Modelling bivariate data</h1>
<p>In this section, we consider straight line relationships between two variables. We learn how to fit simple regression and robust lines. The later fit to data is not affected by extreme or unusual data points. As a natural outgrowth of this fitting procedure, a method of testing for linearity emerges.</p>
<p>Consider paired data (<span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>) and suppose that we want to describe the response variable (<span class="math inline">\(Y\)</span>) in terms of the covariate or explanatory variable (<span class="math inline">\(X\)</span>) using a straight line. This means that the true assumed relationship is of the form <span class="math display">\[y=\alpha +\beta x+\varepsilon\]</span> where <span class="math inline">\(\alpha\)</span> is the true <span class="math inline">\(y\)</span>-intercept, <span class="math inline">\(\beta\)</span> is the true slope and <span class="math inline">\(\varepsilon\)</span> is the random error term, without which the relationship will become purely deterministic. Note that this model has two parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> which are unknown population quantities which must be estimated using data. In other words, statistical model must be fitted for confirmatory analysis of data.</p>
<p>In general, a fitted statistical model can be expressed in the following form</p>
<p><span class="math display">\[\text{observation = fit + residual}\]</span></p>
<p>For fitting straight line models, we have</p>
<p><span class="math display">\[\text{fit} = a + b\text{x}\]</span></p>
<p>Here <span class="math inline">\(a\)</span> is the <em>estimate</em> of the <span class="math inline">\(y\)</span>-intercept <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(b\)</span> is the <em>estimated</em> slope of the line <span class="math inline">\(\beta\)</span>. The estimates <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> will vary from sample to sample, but the population parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are fixed and unknown.</p>
<p>Fitting a line or curve to data is one of the most common techniques used in statistics. It is applicable whenever two or more measures are obtained on each element. In the case of the Mathematics and English scores for example, both measures are of the same kind, but this need not be the case.</p>
<p>Consider the dataset <strong>horsehearts</strong> and the first 6 rows (cases) are shown below.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_set</span>(<span class="fu">theme_minimal</span>())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">download.file</span>(</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">url =</span> <span class="st">"http://www.massey.ac.nz/~anhsmith/data/horsehearts.RData"</span>,</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">destfile =</span> <span class="st">"horsehearts.RData"</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"horsehearts.RData"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(horsehearts)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>  INNERSYS INNERDIA OUTERSYS OUTERDIA EXTSYS EXTDIA WEIGHT
1      3.8      1.9      2.4      1.5   10.8   10.0  1.432
2      3.0      1.7      2.8      1.7   11.6   12.0  1.226
3      2.9      1.9      2.4      1.7   12.8   12.8  1.460
4      3.6      2.0      2.5      1.7   13.5   13.6  1.354
5      4.3      2.8      2.7      2.0   14.0   14.0  2.211
6      3.6      2.3      2.8      1.7   12.7   13.1  1.212</code></pre>
</div>
</div>
<p>A number of measurements on the left ventricle of a horse’s heart were taken by ultra-sound when each animal was alive and then the weights of the hearts were measured after the animals were killed. Any one of the ultra-sound measurements could be used to predict the weight of the heart, in which case the measurements are of different quantities - one being a length and the other a weight. It is not possible to weigh the heart directly until the animal is dead which is rather a drastic way to collect measurements, so fitting a model relating weight (<span class="math inline">\(y\)</span>) to an ultra-sound measurement (<span class="math inline">\(x\)</span>) allows an estimate of the weight (fitted <span class="math inline">\(y\)</span> or <span class="math inline">\(\hat{y}\)</span>) to be made while the animal is still alive.</p>
<p>Obviously, we would like the model to fit the data as closely as possible which means that the fit will explain most of the variation in the observations. Therefore the residuals should be free of patterns and represent random variation about the fit. In order to eliminate the patterns in the residuals or to reduce their variation (which increases the influence of the fit) it may be necessary to transform the variables or include other variables in the model. These matters will be considered later on and in the next chapter.</p>
<p>Finally we note that there are at least three reasons for fitting a model:</p>
<ol type="1">
<li><p>To <strong>describe the relationships between the variables</strong>. In experiments in industry, agriculture, psychology etc. we may wish to go one step further to understand the process; here we are moving towards cause and effect but we must tread warily. For example, increasing the police force may seem to increase crime but this may be due to more criminals being caught and the public being encouraged to report other crimes.</p></li>
<li><p>The model may be necessary to <strong>predict future observations</strong>.</p></li>
<li><p>The estimates of coefficients, <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span> etc., may have particular meanings and may <strong>help to direct future policy or theory</strong>.</p></li>
</ol>
</section>
<section id="simple-regression" class="level1">
<h1>Simple Regression</h1>
<p>This section gives some theory/maths behind the simple regression, and there is no need to remember any of the formulae presented.</p>
<p>The term <strong>regression</strong> is used to describe the tendency for the <em>average</em> value of one variable (called the <em>response</em> or dependent variable) to vary with other variables (called <em>covariates</em> or explanatory or independent or predictor variables or simply regressors). The <strong>regression equation</strong> is the function that describes this relationship mathematically. A regression model with one explanatory variable is called a <strong>simple regression</strong> model. A <strong>multiple regression</strong> model has at least <strong>two</strong> predictors and this topic is covered in the next chapter.</p>
<p>We can write this regression relationship as <span class="math display">\[y=\mu _{y|x} +\varepsilon\]</span> where <span class="math inline">\(\mu _{y|x}\)</span> is the expected or average value of the response variable <span class="math inline">\(y\)</span> for a given or fixed <span class="math inline">\(x\)</span> value and <span class="math inline">\(e\)</span> represents the random variability of <span class="math inline">\(y\)</span> about its mean. The notation <span class="math inline">\(y|x\)</span> stands for <span class="math inline">\(y\)</span> given <span class="math inline">\(x\)</span>.</p>
<p>If a linear relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> variables is plausible, then we can express <span class="math inline">\(\mu _{y|x}\)</span> as a straight line involving <span class="math inline">\(x\)</span> as <span class="math display">\[\mu _{y|x} =\alpha +\beta x\]</span> While few assumptions need to be made in order to fit a regression model, further assumptions are often needed in order to make inference about the goodness of the fitted model. These assumptions are:</p>
<ol type="1">
<li><p>that <span class="math inline">\(Y\)</span> follows a normal distribution about its mean <span class="math inline">\(\mu _{y|x} =\alpha +\beta x\)</span>.</p></li>
<li><p>that the variance of <span class="math inline">\(Y\)</span> (say <span class="math inline">\(\sigma ^{2}\)</span>) is constant, i.e.&nbsp;unlike the mean it does not change with <span class="math inline">\(x\)</span>.</p></li>
<li><p>that the distribution of <span class="math inline">\(Y\)</span> for a given <span class="math inline">\(x=x_{1}\)</span> is independent of the distribution of <span class="math inline">\(Y\)</span> for another given <span class="math inline">\(x=x_{2}\)</span> (say).</p></li>
</ol>
<p>The first two assumptions together with that of linearity can be combined using the notation <span class="math inline">\(Y\sim N\left(\alpha +\beta x,\, \, \sigma ^{2} \right)\)</span>. This set of assumptions made for performing statistical tests on the fitted regression model is illustrated in <a href="#fig-f4-6">Figure&nbsp;1</a>.</p>
<div id="fig-f4-6" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/4-6.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Assumptions for forming t and F statistics</figcaption>
</figure>
</div>
<p>The <strong>least squares method</strong> is used to obtain estimates of the regression coefficients (that is, of the intercept and the slope), as any straight line fit is an equation of the form <span class="math inline">\(a\)</span> + <em>bx</em>, and hence the coefficients <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are <strong><em>statistics</em></strong> (quantities calculated from the sample) which are used as point estimates of the unknown model parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>.</p>
<p>The least square estimates of the slope estimate <span class="math inline">\(b\)</span> is given by the formula <span class="math display">\[b =\frac{\sum \left(x-\bar{x}\right)\left(y-\bar{y}\right) }{\sum \left(x-\bar{x}\right)^{2}} =\frac{S_{xy} }{S_{xx} } ,\]</span> and hence the y-intercept estimate is <span class="math inline">\(a=\bar{y}-b\bar{x}.\)</span></p>
<p>An approach to answer the question of the goodness of fit of the model is to check whether the coefficient of <span class="math inline">\(x\)</span>, that is <span class="math inline">\(b\)</span>, is significantly different from zero. In other words, does <span class="math inline">\(X\)</span> (<em>extdia</em>) explain a significant amount of the variation in <span class="math inline">\(Y\)</span> (<em>weight</em>)? A <span class="math inline">\(t\)</span>-test is used for answering this question.</p>
<p>The true standard deviation of the errors (i.e., <span class="math inline">\(\sigma _{\varepsilon }\)</span> of the model <span class="math inline">\(y=\mu _{y|x} +\varepsilon\)</span>) is estimated using the residuals of the fitted simple model. This estimate is given by the formula <span class="math display">\[s_{e} =\sqrt{\frac{\sum \left(y-\hat{y}\right)^2 }{n-2} }.\]</span></p>
<p>The the estimated standard error of <span class="math inline">\(b\)</span> is given by the formula <span class="math display">\[s_{b} =\frac{s_{e} }{\sqrt{S_{xx} } }.\]</span></p>
<p>The estimated standard error of <span class="math inline">\(a\)</span> is given by <span class="math display">\[s_{a} =\sqrt{s_{e}^{2} \left(\frac{1}{n} +\frac{\bar{x}^{2} }{S_{xx} } \right)}.\]</span></p>
<p>Note that the 95% confidence intervals for the true <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\alpha\)</span> are found using the <span class="math inline">\(t\)</span>-distribution for the <span class="math inline">\(df\)</span> associated with the residual standard error namely <span class="math inline">\((n-2)\)</span>. For example, the 95% CI of the slope <span class="math inline">\(\beta\)</span> is given by <span class="math inline">\(b\pm t_{n-2} s_{b}\)</span>.</p>
<p>The least squares regression line can be used to estimate the mean response <span class="math inline">\(\mu _{y|x_{0} }\)</span> and predict the actual response <span class="math inline">\(Y_{0}\)</span> for a given value <span class="math inline">\(x_{0}\)</span> of the covariate <span class="math inline">\(X\)</span>. In each case the quantity is found by substituting the value <span class="math inline">\(x_0\)</span> into the regression equation, yielding a fitted value <span class="math inline">\(\hat{\mu }_{y|x_{0} } =a+bx_{0}\)</span>. If assumptions such as <span class="math inline">\(Y\)</span> is normally distributed with standard deviation <span class="math inline">\(\sigma\)</span>, then this prediction has a normal distribution with mean</p>
<p><span class="math display">\[\mu _{y|x_{0} } =\alpha +\beta x_{0}\]</span> and standard deviation</p>
<p><span class="math display">\[\sigma \sqrt{\frac{1}{n} +\frac{\left(x_{0} -\bar{x}\right)^{2} }{S_{xx} } }.\]</span> The standard deviation formula suggests that the predictions become more variable when <span class="math inline">\(x_{0}\)</span> is further away from the mean <span class="math inline">\(\bar{x}\)</span>.</p>
<p>The confidence interval for the <strong>mean</strong> response at <span class="math inline">\(x_{0}\)</span> is given by</p>
<p><span class="math display">\[\left(a+bx_{0}  \right)\pm  t_{n-2} \times s_{e} \sqrt{\frac{1}{n} +\frac{\left(x_{0} -\bar{x}\right)^{2} }{S_{xx} } }\]</span> If our aim is to predict the response itself (instead of predicting the mean response at <span class="math inline">\(x_{0}\)</span>), then the errors will be further more. In other words we obtain the <strong>Prediction Interval</strong> (PI) for an individual value of <span class="math inline">\(Y\)</span> (not as the mean) as</p>
<p><span class="math display">\[\left(a+bx_{0} \right)\pm  t_{n-2} \times s_{e} \sqrt{1+\frac{1}{n} +\frac{\left(x_{0} -\bar{x}\right)^{2} }{S_{xx} } }.\]</span></p>
<p>If <span class="math inline">\(n\)</span> is not small and <span class="math inline">\(x_0\)</span> is near the centre of the distribution of <span class="math inline">\(X\)</span>, then the prediction standard error can be approximated by <span class="math inline">\(\sigma\)</span> which is itself estimated by <span class="math inline">\(s_{e}\)</span>, the residual standard error. This means that an approximate 95% interval for the prediction is given by <span class="math inline">\(\left(a+bx_{0} \right)\pm 2s_{e}\)</span>.</p>
<p>We consider the data set <strong>horsehearts</strong> and discuss simple regression analysis.</p>
<section id="displaying-interpreting-the-fitted-model" class="level2">
<h2 class="anchored" data-anchor-id="displaying-interpreting-the-fitted-model">Displaying &amp; Interpreting the Fitted Model</h2>
<p>It is fairly easy to display fitted simple regression line on a scatter plot; see <a href="#fig-simpreg1">Figure&nbsp;2</a> and the <code>R</code> codes shown below:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(horsehearts) <span class="sc">+</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x=</span>EXTDIA, <span class="at">y=</span>WEIGHT) <span class="sc">+</span> </span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> lm, <span class="at">se =</span> <span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-simpreg1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="6-single_files/figure-html/fig-simpreg1-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Simple regression line</figcaption>
</figure>
</div>
</div>
</div>
<p>The geoms <code>geom_smooth()</code> or <code>stat_smooth()</code> add the fitted regression line to the plot. For the simple regression of <code>WEIGHT</code> (weights of horses’ hearts) on <code>EXTDIA</code> (diastole exterior width), the fitted simple regression model is <span class="math inline">\(\hat{y}=a+bx\)</span> For horses heart data, the coefficient estimates are obtained as <span class="math inline">\(a\)</span> = -2.0003 and <span class="math inline">\(b\)</span> = 0.2996. That is, the fitted model is given by <span class="math inline">\(fitted~~weight = -2.0003 + 0.2996\times extdia\)</span> or after rounding</p>
<p><span class="math display">\[fitted~~weight = -2 +0.3\times extdia\]</span></p>
<p>For a given <code>extdia</code> <span class="math inline">\(\left(x\right)\)</span> value, the expected weight is given by the fitted simple regression equation. For example, the exterior width (during diastole phase) for the <span class="math inline">\(39^{th}\)</span> horse is 15.0mm and fitted weight is therefore</p>
<p><span class="math display">\[fitted~~weight =\hat{y}_{39} = -2 + 0.3 \times 15 = 2.5\]</span></p>
<p>The observed weight of its heart <span class="math inline">\(\left(y_{39} \right)\)</span> is 4.1kg. For this horse, we obtain the residual as</p>
<p><span class="math display">\[e_{39}= \left(y_{39}-\hat{y}_{39} \right) = 4.1- 2.5 = 1.6.\]</span></p>
<p><span class="math inline">\(t\)</span><em>-test for Model Parameters</em></p>
<p>It is desirable to use the <code>R</code> package <code>broom</code> to get parts of the regression outputs. The function <code>tidy()</code> extracts the model and the significance testing results; see <a href="#tbl-fittedmodel">Table&nbsp;1</a>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(kableExtra)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>simplereg <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span>EXTDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(simplereg)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-fittedmodel" class="anchored">
<table class="lightable-classic table table-sm table-striped small" data-quarto-postprocess="true">
<caption>Table&nbsp;1: t-tests for model parameters</caption>
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">term</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">estimate</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">std.error</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">statistic</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">(Intercept)</td>
<td style="text-align: right;">-2.00034</td>
<td style="text-align: right;">0.55881</td>
<td style="text-align: right;">-3.57965</td>
<td style="text-align: right;">0.00085</td>
</tr>
<tr class="even">
<td style="text-align: left;">EXTDIA</td>
<td style="text-align: right;">0.29963</td>
<td style="text-align: right;">0.03877</td>
<td style="text-align: right;">7.72793</td>
<td style="text-align: right;">0.00000</td>
</tr>
</tbody>
</table>
</div>


</div>
</div>
<p>For the horses hearts data, under the null hypothesis that the true (or population) slope <span class="math inline">\(b\)</span> equals zero (i.e., <span class="math inline">\(H_{0}:\beta =0\)</span>), the test statistic becomes <span class="math display">\[t=\frac{b}{s_{b} } =\frac{0.29963}{0.03877} = 7.728.\]</span></p>
<p>The <span class="math inline">\(t\)</span>-statistic is clearly large enough to be considered significant for <span class="math inline">\((n-2)\)</span> <span class="math inline">\(df\)</span> and the <span class="math inline">\(p\)</span>-value is close to zero. Thus, we would reject the null hypothesis <span class="math inline">\(H_{0} :\beta =0\)</span>. In other words, the slope coefficient is significantly different from zero and hence the predictor variable <em>extdia</em> explains a significant amount of variation in the response variable <em>weight</em>.</p>
<p>We can also carry out a similar <span class="math inline">\(t\)</span>-test for the <span class="math inline">\(y\)</span>-intercept <span class="math inline">\(\alpha\)</span> based on the <span class="math inline">\(t\)</span>-statistic <span class="math display">\[t = \frac {a}{s_a}= \frac{-2.00034}{0.55881}=-3.58.\]</span> but the main interest is in the slope parameter <span class="math inline">\(\beta\)</span>. See <a href="#tbl-fittedmodel">Table&nbsp;1</a>.</p>
</section>
<section id="model-summaries" class="level2">
<h2 class="anchored" data-anchor-id="model-summaries">Model Summaries</h2>
<p>Many of the model summary measures can be obtained for assessing the quality of the fitted model using the <code>glance()</code> function from the <code>broom</code> package (<a href="#tbl-modelsumry">Table&nbsp;2</a>).</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>simplereg <span class="sc">|&gt;</span> </span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glance</span>() <span class="sc">|&gt;</span> </span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(r.squared, sigma, statistic, p.value, AIC, BIC)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-modelsumry" class="anchored">
<table class="lightable-classic table table-sm table-striped small" data-quarto-postprocess="true">
<caption>Table&nbsp;2: Model summary measures</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;">r.squared</td>
<td style="text-align: right;">0.58</td>
</tr>
<tr class="even">
<td style="text-align: left;">sigma</td>
<td style="text-align: right;">0.74</td>
</tr>
<tr class="odd">
<td style="text-align: left;">statistic</td>
<td style="text-align: right;">59.72</td>
</tr>
<tr class="even">
<td style="text-align: left;">p.value</td>
<td style="text-align: right;">0.00</td>
</tr>
<tr class="odd">
<td style="text-align: left;">AIC</td>
<td style="text-align: right;">106.83</td>
</tr>
<tr class="even">
<td style="text-align: left;">BIC</td>
<td style="text-align: right;">112.32</td>
</tr>
</tbody>
</table>
</div>


</div>
</div>
<p>How to interpret entries appearing in the R output <a href="#tbl-modelsumry">Table&nbsp;2</a> is explained below. Note that the <span class="math inline">\(R^{2}\)</span> statistic and the residual standard error are two common summary measures for the fitted model. The other measures such as the AIC and BIC shown in in <a href="#tbl-modelsumry">Table&nbsp;2</a> are useful for comparison of models, and selecting a <em>best</em> model, which will be discussed later on.</p>
<p><strong>Residual standard error</strong></p>
<p>The size of the residual standard error <span class="math inline">\(s_{e}\)</span>, which is called sigma in <a href="#tbl-modelsumry">Table&nbsp;2</a>, is important for many reasons. In general, we prefer to have <span class="math inline">\(s_{e}\)</span> no more than 5% of <span class="math inline">\(\bar{y}\)</span> or small compared the range of <span class="math inline">\(y\)</span> data. For the model fitted to horses hearts , the residual standard error is labelled as <em>sigma</em> in <a href="#tbl-modelsumry">Table&nbsp;2</a>. This value of is rather large (compared to the range of <span class="math inline">\(y\)</span> data), and hence the fitted model may not be good for prediction purposes.</p>
<p>The size of <span class="math inline">\(s_{e}\)</span> also controls the size of the standard error of the slope estimate <span class="math inline">\(b\)</span> (and hence its confidence interval).</p>
<p><strong>R-squared</strong> <span class="math inline">\(\left(R^{2} \right)\)</span> <strong>statistic:</strong></p>
<p>The R-Squared statistic, the proportion of the variation explained by the fitted model, is 0.58. This means that 58 percent of the total variation of the weights is explained by the exterior widths (diastole) using the fitted straight line model namely</p>
<p><span class="math display">\[\text {fitted  weight = -2 +0.3}\times \text {extdia}\]</span></p>
<p>The <span class="math inline">\(R^{2}\)</span> value is also known as the coefficient of (multiple) determination. Notice that when there is only one explanatory variable <span class="math inline">\(X\)</span>, then the <span class="math inline">\(R^{2}\)</span> is equal to the square of the <span class="math inline">\((X,Y)\)</span> correlation coefficient, i.e.&nbsp;<span class="math inline">\(R^{2} =\left(r_{x,y} \right)^{2}\)</span>.</p>
<p>We usually require that <span class="math inline">\(R^{2}\)</span> <strong>be at least 0.5</strong> so that at least half of the variation is explained by the fit. For the Horse data the model <span class="math inline">\(R^{2}\)</span> is not much better than this. However the scatterplot revealed that there may be two different groups of observations in the data and/or the curvature in the data may indicate that a transformation would be advisable so this low <span class="math inline">\(R^{2}\)</span> is not really surprising.</p>
<p>Remember that there is a difference between a <strong>meaningful model</strong> and a <strong>statistically significant model</strong>. An <span class="math inline">\(R^{2}\)</span> of 0.5 or more indicates a meaningful model whereas the <span class="math inline">\(t\)</span>-test for slope indicates a statistically significant model. A statistically significant model may not always be a meaningful model - in this case the significance is high but the <span class="math inline">\(R^{2}\)</span> of 57.6% is barely adequate.</p>
<p><strong>ANOVA and</strong> <span class="math inline">\(F\)</span><strong>-test</strong></p>
<p><a href="#tbl-modelsumry">Table&nbsp;2</a> gives the F-statistic (labelled as just <em>statistic</em>) and the P-value for this F-statistic. The concept behind this statistic is explained below:</p>
<p>The variation in a data set can be measured as the sum of the squared deviation from its central value. This Sum of Squares is abbreviated as SS or SumSq in software regression outputs. For a regression model, we have</p>
<p><strong>I</strong> : total SumSq = variation in the observed values about the mean = <span class="math inline">\(\sum \left(y-\bar{y}\right)^{2}\)</span>.</p>
<p><strong>II</strong> : regression SumSq = Variation in the fitted values about the mean = <span class="math inline">\(\sum \left(\hat{y}-\bar{y}\right)^{2}\)</span> (Note that <em>fit</em> is denoted by <span class="math inline">\(\hat{y}\)</span>).</p>
<p><strong>III</strong> : error or residual SumSq = Variation in the residuals <span class="math inline">\(=\sum \left(y-\hat{y}\right)^{2} =\sum e^{2}\)</span>.</p>
<p>These sums of squares due to regression, error and total etc are usually displayed in the form of a table known as the analysis of variance table, which is usually shortened to ANOVA or anova. A typical ANOVA table for a simple regression model will appear as in <a href="#fig-f4-8">Figure&nbsp;3</a>. Depending on the package used, the ANOVA table may differ slightly in style.</p>
<div id="fig-f4-8" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="images/4-8.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;3: A typical ANOVA table</figcaption>
</figure>
</div>
<p><code>R</code> does not print the last row while displaying the F-statistic and ANOVA table. The following codes can be used to obtain the ANOVA output for the regression model (<a href="#tbl-anovatable">Table&nbsp;3</a>).</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>simplereg <span class="sc">|&gt;</span> <span class="fu">anova</span>()</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co"># or </span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>simplereg <span class="sc">|&gt;</span> <span class="fu">anova</span>() <span class="sc">|&gt;</span> <span class="fu">tidy</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-anovatable" class="anchored">
<table class="lightable-classic table table-sm table-striped small" data-quarto-postprocess="true">
<caption>Table&nbsp;3: Analysis of Variance Table</caption>
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">term</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">df</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">sumsq</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">meansq</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">statistic</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">EXTDIA</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">32.731</td>
<td style="text-align: right;">32.731</td>
<td style="text-align: right;">59.721</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">Residuals</td>
<td style="text-align: right;">44</td>
<td style="text-align: right;">24.115</td>
<td style="text-align: right;">0.548</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">NA</td>
</tr>
</tbody>
</table>
</div>


</div>
</div>
<p>Each sum of squares (source of variation) has associated with it a <strong>degrees of freedom</strong> <span class="math inline">\(df\)</span>). For one explanatory variable, the regression <span class="math inline">\(df\)</span> = 1. The total <span class="math inline">\(df\)</span> is always one less than the sample size, that is <span class="math inline">\(n-1.\)</span> In other words, residual <span class="math inline">\(df\)</span> = <span class="math inline">\(n-2\)</span>. From the sums of squares, the variance estimates are calculated as <strong>SumSq/df</strong> which are called Mean Squares (<strong>MeanSq</strong>).</p>
<p>For the horses’ heart data, we have Regression SumSq = 32.731, Error SumSq= 24.115 and Total SumSq = 56.845. We also have regression <span class="math inline">\(df\)</span> = 1, total <span class="math inline">\(df\)</span> = <span class="math inline">\(n-1 = 45\)</span> and by subtraction residual <span class="math inline">\(df= 45-1= 44\)</span>. Dividing the SumSq by the associated <span class="math inline">\(df\)</span>, we compute</p>
<ol type="i">
<li>Regression Mean Sq = 32.731/1 = 32.731<br>
</li>
<li>Residual Mean Sq = 24.115/44 = 0.548<br>
</li>
<li>Total Mean Sq = Total SumSq/45 = <span class="math inline">\(\sum(y-\bar{y})^2/(n-1)=1.263\)</span></li>
</ol>
<p>Note that the Total Mean Sq is nothing but the variance of <span class="math inline">\(y\)</span>, which is usually not displayed in the ANOVA table.</p>
<p>It is possible to formalise the goodness of fit of the model by carrying out an <span class="math inline">\(F\)</span>-test. The <span class="math inline">\(F\)</span> statistic is formed by the ratio of two estimates of variances, the regression Mean Sq or variance and the error Mean Sq or variance. The distribution of the <span class="math inline">\(F\)</span> statistic is governed by the numerator <span class="math inline">\(df\)</span> and the denominator <span class="math inline">\(df\)</span>. For the horses’ heart data, we obtain</p>
<p><span class="math display">\[F =
\frac{{\text {regression MeanSq} }}{{\text {residual MeanSq}}}
= \frac{32.731}{0.548} = 59.721 \]</span></p>
<p>with 1 <span class="math inline">\(df\)</span> for the numerator and 44 <span class="math inline">\(df\)</span> for the denominator.</p>
<p>The null hypothesis is that the model does not fit the data well. That is, the model explains too little of the variation in the <span class="math inline">\(y\)</span> values to be significant. This hypothesis is generally rejected whenever the <span class="math inline">\(p\)</span>-value of the <span class="math inline">\(F\)</span>-test is less than 0.05. In ANOVA table, the <span class="math inline">\(F\)</span> statistic is displayed along with the <span class="math inline">\(p\)</span>-value. Here the <span class="math inline">\(p\)</span>-value is the probability of observing an <span class="math inline">\(F\)</span> statistic larger than the computed value. For horses’ heart data, the computed <span class="math inline">\(F\)</span> statistic is 59.721. <span class="math inline">\(F\)</span> statistic is always positive (being the ratio of mean squares) and hence the alternative hypothesis must be one-sided. That is, the <span class="math inline">\(p\)</span>-value is given by <span class="math inline">\(\Pr \left(F_{1,44} &gt;59.721\right)\)</span> which is very close to zero. This means that the null hypothesis is firmly rejected and we conclude that the regression model using the explanatory variable <em>extdia</em> explains a significantly large proportion of the variation of the response variable <em>weight</em>.</p>
<p>Note that the <span class="math inline">\(R^{2}\)</span> can also be calculated from the ANOVA table</p>
<p><span class="math display">\[R^{2} =\frac{{\text {regression SumSq}}}{{\text {total SumSq}}} = \frac{32.731}{56.845} = 0.5758\]</span> or alternatively</p>
<p><span class="math display">\[R^{2} = 1-\frac{{\text {residual SumSq}}}{{\text {total SumSq}}} = 1 -- \frac{24.115}{56.845} = 0.5758.\]</span> The degrees of freedom for residual SumSq and total SumSq are not identical; while they are very close this is not always the case (e.g.&nbsp;in multiple regression which we will meet in the next chapter). Hence we can adjust for this to obtain the <strong>adjusted R-Squared</strong> (<span class="math inline">\(R_{adj}^{2}\)</span>):</p>
<p><span class="math display">\[
\begin{aligned}
R_{adj}^{2}
&amp;= 1-\frac{\left(\frac{{\text {residual SumSq}}}{{\text {residual df}}} \right)}{\left(\frac{{\text {totalSumSq}}}{{\text {total df}}} \right)\, } \\
&amp;= 1-\frac{24.115/44}{56.845/45} \\
&amp;=0.5661.
\end{aligned}
\]</span></p>
<p>For the simple regression, the <span class="math inline">\(F\)</span>-test is equivalent to the previous <span class="math inline">\(t\)</span>-test (and produces exactly the same <span class="math inline">\(p\)</span>-value). In fact when there is only one explanatory variable the two test statistics are related by the equation <span class="math inline">\(F\)</span> = <span class="math inline">\(t^2\)</span>. A further relationship between the two is that the residual standard error is the square root of the residual mean square.</p>
<p>The <code>summary()</code> function in base <code>R</code> gives rather a bulky output for the fitted regression model particularly when the number of predictors is large.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>simplereg <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span>EXTDIA, <span class="at">data=</span>horsehearts) </span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(simplereg)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The <code>R</code> package <code>lessR</code> will get you even a bigger output of model quality and summary measures. We wont be covering all of them but only the essential ones obtained by the <code>broom</code> package function <code>glance()</code>. Try-</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lessR)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>
lessR 4.2.9                         feedback: gerbing@pdx.edu 
--------------------------------------------------------------
&gt; d &lt;- Read("")   Read text, Excel, SPSS, SAS, or R data file
  d is default data frame, data= in analysis routines optional

Learn about reading, writing, and manipulating data, graphics,
testing means and proportions, regression, factor analysis,
customization, and descriptive statistics from pivot tables
  Enter:  browseVignettes("lessR")

View changes in this and recent versions of lessR
  Enter: news(package="lessR")

Interactive data analysis
  Enter: interact()</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'lessR'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following objects are masked from 'package:dplyr':

    recode, rename</code></pre>
</div>
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">reg</span>(WEIGHT<span class="sc">~</span>EXTDIA, <span class="at">data=</span>horsehearts)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="6-single_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="6-single_files/figure-html/unnamed-chunk-12-2.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output-display">
<p><img src="6-single_files/figure-html/unnamed-chunk-12-3.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="prediction-and-estimation" class="level2">
<h2 class="anchored" data-anchor-id="prediction-and-estimation">Prediction and Estimation</h2>
<p>Recall that the fitted value for the weight of a heart with an <em>extdia</em> value of 15.0mm was 2.5kg. This value can be interpreted as the predicted weight of a horse heart with <em>extdia</em> = 15mm, or as the estimated of all horse hearts with <em>extdia</em> = 15mm. The 95% confidence limits for the <strong>mean</strong> response for the mean weight of horses hearts with <em>extdia</em> = 15mm is given by <span class="math inline">\(\left(2.26kg,2.72kg\right)\)</span>. However the weight of <strong>any</strong> individual heart with <em>extdia</em> = 15mm could (with the same confidence) be as low as 0.98kg or as high as 4.00kg (the prediction interval being (0.98kg, 4.00kg). Notice that the approximate PI formula works as well here: <span class="math inline">\(s\)</span> = 0.7403 and so 2.50 <span class="math inline">\(\pm\)</span> (2 <span class="math inline">\(\times\)</span> 0.74) = (1.0kg, 4.0kg). Note that manual computation of the prediction intervals is harder, and we prefer to use <code>R</code> for this.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># confidence interval</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(simplereg, <span class="fu">list</span>(<span class="at">EXTDIA =</span> <span class="dv">15</span>), <span class="at">interval =</span> <span class="st">"confidence"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>       fit      lwr      upr
1 2.494161 2.264023 2.724299</code></pre>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># prediction interval</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(simplereg, <span class="fu">list</span>(<span class="at">EXTDIA =</span> <span class="dv">15</span>), <span class="at">interval =</span> <span class="st">"prediction"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>       fit       lwr      upr
1 2.494161 0.9845172 4.003805</code></pre>
</div>
</div>
<p>We can also create a dataset with the desired intervals using the <code>augment()</code> function from the <code>broom</code> package.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>horseCI <span class="ot">&lt;-</span> <span class="fu">augment</span>(simplereg, <span class="at">interval =</span> <span class="st">"confidence"</span>)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>horsePI <span class="ot">&lt;-</span> <span class="fu">augment</span>(simplereg, <span class="at">interval =</span> <span class="st">"prediction"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Let’s visualise the confidence and prediction bands for the fitted line on a scatter plot using the <code>geom_ribbon()</code> function; see <a href="#fig-simpregpi">Figure&nbsp;4</a>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> simplereg <span class="sc">|&gt;</span> </span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">augment</span>(<span class="at">interval =</span> <span class="st">"confidence"</span>) <span class="sc">|&gt;</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x =</span> EXTDIA) <span class="sc">+</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> WEIGHT)) <span class="sc">+</span> </span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> .lower, <span class="at">ymax =</span> .upper), <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> .fitted)) <span class="sc">+</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Confidence interval"</span>) </span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> simplereg <span class="sc">|&gt;</span> </span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">augment</span>(<span class="at">interval =</span> <span class="st">"prediction"</span>) <span class="sc">|&gt;</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x =</span> EXTDIA) <span class="sc">+</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> WEIGHT)) <span class="sc">+</span> </span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> .lower, <span class="at">ymax =</span> .upper), <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> .fitted)) <span class="sc">+</span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Prediction interval"</span>) <span class="sc">+</span></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>()</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>p1<span class="sc">/</span>p2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-simpregpi" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="6-single_files/figure-html/fig-simpregpi-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;4: Confidence intervals and prediction intervals</figcaption>
</figure>
</div>
</div>
</div>
<p>The R package <em>visreg</em> readily shows the confidence bands too. Try-</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(visreg)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="fu">visreg</span>(<span class="fu">lm</span>(WEIGHT<span class="sc">~</span>EXTDIA, <span class="at">data=</span>horsehearts),)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
</section>
<section id="residual-analysis-for-regression" class="level1">
<h1>Residual Analysis for Regression</h1>
<p>A careful examination of the residuals indicates how well a model fits the data and also helps to identify shortcomings and possible ways of improving the model fit. In this section, we review some of the points to notice and use them to improve fitted simple as well as multiple regression models covered in the next Chapter.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggfortify)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>ggplot2<span class="sc">::</span><span class="fu">autoplot</span>(simplereg, <span class="at">which=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-f4-10" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="6-single_files/figure-html/fig-f4-10-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;5: Residual vs Fits Plot and Normal Quantile plot of the residuals</figcaption>
</figure>
</div>
</div>
</div>
<p>We would like to plot the residuals against the fitted values. For horses’ heart data, the residuals vs.&nbsp;fits plot (see <a href="#fig-f4-10">Figure&nbsp;5</a>) does not show a random scatter of points about zero, but rather a clear trend of U-shaped curvature together with a pattern of increasing variability about the trend. This indicates that a shrinking transformation of the <span class="math inline">\(Y\)</span> variable should be considered (as does the marginal distribution of <span class="math inline">\(Y\)</span> – see the next section for details). This is not surprising given our initial examination showed that a curved fit was more appropriate, but in general systematic departures from a model fit are easier to see in a residual plot than in the original scatterplot of the data.</p>
<p>The normal quantile plot enables us to assess whether the residuals are normally distributed – there is some evidence of right skewness but not much so the normality assumption appears to be justified (a test for normality can always be carried out for confirmation).</p>
<p>The plot of residuals against the order of occurrence in the data set is used to judge whether the residuals are independent. In our case, the residual vs.&nbsp;observation order plot reveals no trend for the first 30 values but an increasing trend after that. An examination of the data set reveals that the last values in the data are also those with the largest <em>extdia</em> values which is where the maximum deviation from a straight line was already noted. Once again, an appropriate residual plot makes it easier to spot features of model fit (or lack of fit). <strong>Durbin-Watson (DW) test</strong> for the serial correlation in the residuals can be performed. The test statistic for the DW test is <span class="math display">\[d = \frac{\sum _{i=2}^{n}\left(e_{i} -e_{i-1} \right)^{2} }{\sum _{t=1}^{n}e_{i} ^{2} } .\]</span> If <span class="math inline">\(d\)</span> is about 2, it suggests independence of the residuals. If residuals are positively correlated, then <span class="math inline">\(d\)</span> will be close to zero. If <span class="math inline">\(d\)</span> is large and close to 4, then negative correlation among the residuals is indicated. Critical values for the DW statistic are available in tables. The <strong>car</strong> package provides the <span class="math inline">\(p\)</span>-value for the null hypothesis that there is no serial correlation in the residuals.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>simplereg <span class="sc">|&gt;</span> </span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">residuals</span>() <span class="sc">|&gt;</span> </span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>  car<span class="sc">::</span><span class="fu">durbinWatsonTest</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9482249</code></pre>
</div>
</div>
<p>The <strong>residuals vs.&nbsp;fits plot</strong> also helps to identify outliers – there appears to be at least one possible outlier with a residual greater than 1.5. If the residuals appear to be normally distributed, however, we can automate outlier detection by calculating the standardised residuals. Note that residuals are standardised by subtracting the mean (which is zero) and dividing by the standard deviation. For the <span class="math inline">\(i^{th}\)</span> residual, the standard deviation (i.e.&nbsp;standard error) is given by</p>
<p><span class="math display">\[
s_{e_{i} } =s_{e} \sqrt{1-\left(\frac{1}{n} +\frac{(x_{i} -\bar{x})^2}{S_{xx} } \right)}
\]</span></p>
<p>Any value with a standardised residual whose magnitude is greater than 2 is a potential outlier as we only expect this to happen about 5% of the time: i.e.&nbsp;two observations (39 and 44) gave rise to standardised residuals greater than 2. For a sample of size 46 we would expect (5% of 46 =) 2 or 3 values to give standardised residuals greater than 2, so this is not unexpected. However if the standardised residual of any point is extremely large, we should check the original data to decide whether an error has been made. Alternatively, we may decide that this point does not fit the given model and hence remove that point from the data. Statisticians are very loathe to throw data points away as even the unusual points may contain information about the model and why it does or does not fit well. For the present data set, the standardised residuals are not particularly large and within the expected 5% so that we would not remove them from the data set.</p>
<p>The residuals may be greatly influenced by outliers or unusual points because the slope estimate of the regression line is sensitive to these outliers. In order to overcome this difficulty, we may find the fitted values corresponding to each <span class="math inline">\(x\)</span> value using all the data except for that data point. In other words, the data point <span class="math inline">\(\left(x_{i} ,y{}_{i} \right)\)</span> can be omitted, and a line can be fitted. We then obtain the fitted value for the <span class="math inline">\(i^{ th}\)</span> data point say <span class="math inline">\(\hat{y}_{i,-i}\)</span> and the associated <strong>deleted residual</strong> (also known as <strong>studentised residual</strong>) <span class="math inline">\(e_{i,-i} =y_{i} -\hat{y}_{i,-i}\)</span>. We can explore the deleted residuals instead of the ordinary residuals. These deleted residuals are also externally studentised (a process similar to standardisation) so that the residual error estimate is done without the <span class="math inline">\(i^{th}\)</span> data point (see <a href="#fig-rstudent">Figure&nbsp;6</a>).</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>del.resid <span class="ot">&lt;-</span> <span class="fu">rstudent</span>(simplereg)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="fu">qplot</span>(<span class="fu">seq_along</span>(del.resid), del.resid) <span class="sc">+</span> </span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"observation"</span>) <span class="sc">+</span> </span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"studentised residual"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-rstudent" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="6-single_files/figure-html/fig-rstudent-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;6: Index Plot of Deleted Residuals</figcaption>
</figure>
</div>
</div>
</div>
<p>Some scenarios concerning residual plots are explained below:</p>
<p><strong>(a)</strong> <strong>Transformations</strong></p>
<p>In <a href="#fig-resipattern1">Figure&nbsp;7</a>, <strong>residuals are plotted against fitted values but show a funnel pattern instead of falling approximately in a horizontal band.</strong> <a href="#fig-resipattern1">Figure&nbsp;7</a>(a) indicates that a shrinking transformation of square root or logarithm may be appropriate; <a href="#fig-resipattern1">Figure&nbsp;7</a>(b) suggests a stretching transformation such as squaring the response variable.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-resipattern1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="6-single_files/figure-html/fig-resipattern1-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;7: Non-constant Residual Variation</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>(b) Addition of other variables</strong></p>
<p><a href="#fig-resipattern2">Figure&nbsp;8</a>(a) residuals are plotted against fitted values. This plot suggests the addition of a quadratic, <span class="math inline">\(x_2\)</span>, term to the model. In <a href="#fig-resipattern2">Figure&nbsp;8</a>(b) the residuals are plotted against a potential explanatory variable, <span class="math inline">\(X_i\)</span>, which is not yet included in the model. This plot indicates a linear relationship between the residuals and <span class="math inline">\(X_i\)</span> suggesting that <span class="math inline">\(X_i\)</span> should be added to the linear model.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-resipattern2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="6-single_files/figure-html/fig-resipattern2-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;8: Need to add predictors</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>(c)</strong> <strong>Subgroups</strong></p>
<p>Plots may show that a model seems to fit very well, as in <a href="#fig-resipattern3">Figure&nbsp;9</a>(a). But this is a spurious effect brought about by the presence of two or more subgroups in the data. Models fitted to each of the subgroups would not show up as being good fits to the data. In <a href="#fig-resipattern3">Figure&nbsp;9</a>(b), on the other hand, a poorly fitting model may be due to subgroups but if individual models were fitted, they would fit the data well.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-resipattern3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="6-single_files/figure-html/fig-resipattern3-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;9: Subgrouping patterns</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>(d)</strong> <strong>Outliers</strong></p>
<p>Plots of residuals against the fitted <span class="math inline">\(y\)</span> values or the explanatory variables may indicate peculiar values. It may be that a few data points are very unusual; perhaps unusual conditions prevailed at those times when those data points were recorded; errors may have been made by those taking these measurements; errors may have occurred in coding or entering data into the computer (see <a href="#fig-resipattern4">Figure&nbsp;10</a>(a)).</p>
<p>In <a href="#fig-resipattern4">Figure&nbsp;10</a>(b), the outliers may indicate that the model does not fit very well at the larger observed values of <span class="math inline">\(y\)</span>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-resipattern4" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="6-single_files/figure-html/fig-resipattern4-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;10: Non-constant Residual Variation</figcaption>
</figure>
</div>
</div>
</div>
<p><strong>(e)</strong> <strong>Autocorrelation</strong></p>
<p><a href="#fig-resipattern5">Figure&nbsp;11</a> shows patterns in plots of residuals against time. In (a), a positive residual tends to be followed by another positive residual. If the residuals are correlated with themselves ‘lagged’ by one time period, this correlation is called autocorrelation and the coefficient would be positive for (a). In (b), the autocorrelation would be negative; this could occur with the price of potatoes as a high price one year may encourage gardeners to plant even more the next year leading to a glut and low prices, followed by a hesitancy the next year leading to scarcity and higher prices, and so on.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-resipattern5" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="6-single_files/figure-html/fig-resipattern5-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;11: Neighbouring residuals depend on each other</figcaption>
</figure>
</div>
</div>
</div>
<p>The above figures show the residuals on the <span class="math inline">\(y\)</span>-axis. We may also plot the standardised residuals, deleted residuals etc. Some prefer to plot the square root of the absolute standardised residuals against the fitted values (instead of plotting ordinary residuals against the fitted values). This plot, known as the <strong>Scale-Location plot</strong>, helps us to judge whether the residual variation is constant, and also to identify the observations having large residuals (i.e.&nbsp;<span class="math inline">\(\sqrt{\left|{\text {standardised residual}}\right|} &gt;\sqrt{2} =1.41\)</span>; see <a href="#fig-scaloc">Figure&nbsp;12</a>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>full.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> ., <span class="at">data=</span>horsehearts)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(full.model, <span class="at">which=</span><span class="dv">3</span>, <span class="at">ncol=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-scaloc" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="6-single_files/figure-html/fig-scaloc-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;12: Scale-Location plot</figcaption>
</figure>
</div>
</div>
</div>
<p>Depending on the <code>R</code> package used, a variety of plots for exploring the residuals can be obtained.</p>
<p>In summary, residuals give important information about the fit of a model and how it might be improved:</p>
<ol type="1">
<li><p>Large variability of residuals in relation to the total variability in <span class="math inline">\(Y\)</span> indicates a feeble relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>. We can try transforming <span class="math inline">\(Y\)</span> or adding other variables to the fitted model.</p></li>
<li><p>The residuals should fall in a horizontal band when plotted against the fit, that is, the variance of the residuals should be constant over different values of the fit. If not, try a transformation.</p></li>
<li><p>Normality of the residuals confirms that the normality assumption required for the <span class="math inline">\(t\)</span> and <span class="math inline">\(F\)</span> tests is satisfied. Otherwise a transformation of the response variable may be required.</p></li>
<li><p>Plotting the residuals against the order of the data allows us to check whether successive values are independent of one another, and hence may reveal further relationships in the data.</p></li>
</ol>
<section id="improving-simple-regression" class="level2">
<h2 class="anchored" data-anchor-id="improving-simple-regression">Improving Simple Regression</h2>
<p>If the fitted simple regression is rather poor, what can be done?</p>
<p><strong>(a) Use a different predictor variable</strong></p>
<p>For this Chapter example, we could choose another one of the ultra-sound measurements to predict the weight of the horses heart.</p>
<p><strong>(b) Transform the</strong> <span class="math inline">\(Y\)</span> variable</p>
<p>We could choose a transformation which makes physical sense. For example, we could argue that the weight of the heart should be closely related to the volume of the heart and volume is related to the product of three lengths or any one length cubed. Rather than cubing the <span class="math inline">\(X\)</span> variable we usually transform the response variable <span class="math inline">\(Y\)</span>. Alternatively we might choose a transformation based on statistical grounds. Our previous discussion suggests that a shrinking transformation should be used, so suppose we take the logarithm of <span class="math inline">\(Y\)</span>. The distribution of weights is compared before and after transformation in <a href="#fig-weighttrans">Figure&nbsp;13</a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-weighttrans" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="6-single_files/figure-html/fig-weighttrans-1.png" class="img-fluid figure-img" width="768"></p>
<figcaption class="figure-caption">Figure&nbsp;13: Comparison of raw and log-transformed Weight data</figcaption>
</figure>
</div>
</div>
</div>
<p>We can see the effect of logarithmic transformation from the boxplot in <a href="#fig-weighttrans">Figure&nbsp;13</a>. Clearly the distribution has become more symmetric. In order to make the distribution even more symmetric we might also try a <strong>power</strong> transformation as shown in <a href="#fig-weighttrans">Figure&nbsp;13</a>. Here we have applied the negative reciprocal cubic root transformation <span class="math inline">\(-\frac {1}{Y^{1/3}}\)</span> which makes more physical sense. This yields a slightly symmetric distribution. A minimal summary output of the regression of <span class="math inline">\(WEIGHT^{1/3}\)</span> on <em>EXTDIA</em> is shown in <a href="#tbl-transweightreg">Table&nbsp;4</a>:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(WEIGHT<span class="sc">^</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>)<span class="sc">~</span>EXTDIA, <span class="at">data=</span>horsehearts) <span class="sc">|&gt;</span> </span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glance</span>() <span class="sc">|&gt;</span> </span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(r.squared, sigma, statistic, p.value, AIC, BIC)<span class="sc">|&gt;</span> </span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate_if</span>(is.numeric, round,<span class="dv">3</span>) <span class="sc">|&gt;</span> </span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">t</span>() <span class="sc">|&gt;</span> </span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>() <span class="sc">|&gt;</span> </span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_classic</span>(<span class="at">full_width =</span> F) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="tbl-transweightreg" class="anchored">
<table class="lightable-classic table table-sm table-striped small" data-quarto-postprocess="true">
<caption>Table&nbsp;4: Cubic Root Transformed Response Model Summary</caption>
<tbody>
<tr class="odd">
<td style="text-align: left;">r.squared</td>
<td style="text-align: right;">0.616</td>
</tr>
<tr class="even">
<td style="text-align: left;">sigma</td>
<td style="text-align: right;">0.128</td>
</tr>
<tr class="odd">
<td style="text-align: left;">statistic</td>
<td style="text-align: right;">70.498</td>
</tr>
<tr class="even">
<td style="text-align: left;">p.value</td>
<td style="text-align: right;">0.000</td>
</tr>
<tr class="odd">
<td style="text-align: left;">AIC</td>
<td style="text-align: right;">-54.588</td>
</tr>
<tr class="even">
<td style="text-align: left;">BIC</td>
<td style="text-align: right;">-49.102</td>
</tr>
</tbody>
</table>
</div>


</div>
</div>
<p>This output shows an improvement in the <span class="math inline">\(R^{2}\)</span> value. However, for technical reasons one cannot meaningfully compare <span class="math inline">\(R^{2}\)</span> values for the raw and transformed data. The estimated standard deviation of the residuals is also meaningless when comparing raw and transformed data (recall that this quantity is the square root of the residual MeanSq). There is really only one way to confirm whether a transformed model is better than the original model and that is by analysing the residuals. Only if the residuals are better behaved, in that they comply more closely with the regression assumptions, can one claim that the transformed model is preferable. This is a very important point.</p>
<p>In the next Chapter, we will cover more on <code>AIC</code> and <code>BIC</code> values shown in@tbl-transweightreg but the simple thumb rule is to opt a model with the smallest AIC or BIC while we go for a model with the largest log-likelihood.</p>
<p>These values also support the model based on the negative reciprocal cubic root transformed data.</p>
<p><strong>(c) Add other explanatory variables to the model</strong><br>
This will cause the <span class="math inline">\(R^{2}\)</span> to increase (although we may decide that the increase is not worth the effect of making the model more complicated). We will study multiple regression models having two or more predictors in the next chapter.</p>
</section>
</section>
<section id="robust-model-fitting" class="level1">
<h1>Robust Model Fitting</h1>
<p>The regression fit by the least squares method can be affected by outliers. If data are explored using scatterplots, then we often obtain which of the observations are suspicious or appear to be rogue.</p>
<p>The residual standard error at a given <span class="math inline">\(x\)</span> value is given by <span class="math display">\[s_{e_{i} } =s_{e} \sqrt{1-\left(\frac{1}{n} +\frac{x_{i} -\bar{x}}{S_{xx} } \right)}.\]</span> From the above expression, we see that if an <span class="math inline">\(x\)</span> value is further away from the mean <span class="math inline">\(\bar{x}\)</span>, then the residual variance will be small. If an <span class="math inline">\(x\)</span> value is closer to the mean <span class="math inline">\(\bar{x}\)</span>, then the residual variance will be greater. This means that <span class="math inline">\(x\)</span>-values far from <span class="math inline">\(\bar{x}\)</span> pull the regression line closer to the corresponding <span class="math inline">\(y\)</span>-values or alternatively such a distant <span class="math inline">\(x\)</span> value has a higher <strong><em>leverage</em></strong>. This leverage is often measured by the hi values namely <span class="math display">\[h_{ii} =\frac{1}{n} +\frac{\left(x_{i} -\bar{x}\right)^{2} }{S_{xx} }.\]</span> The above leverage measure <span class="math inline">\(h_{ii}\)</span> always lies between zero and one, and does not depend on the actual <span class="math inline">\(y\)</span> values. The higher the leverage of an <span class="math inline">\(x\)</span>-value, the greater its <em>potential influence</em> on the regression coefficients. If a <span class="math inline">\(h_{ii}\)</span> value is greater than <span class="math inline">\(\frac{3p}{n}\)</span> (where <span class="math inline">\(p\)</span> is the number of model terms (including the constant) and <span class="math inline">\(n\)</span> is the number of observations), then the associated data point is generally regarded as having high leverage. When the number of predictors is small, say 1 to 4, some use a conservative cut-off value <span class="math inline">\(\frac{4}{n}\)</span> instead of <span class="math inline">\(\frac{3p}{n}\)</span>.</p>
<p>One of the measures of influence on the regression results is known as the <strong>Cook’s distance</strong> which is related to difference between the regression coefficients with and without the <span class="math inline">\(i^{th}\)</span> data point. The formula for the Cook’s distance for the <span class="math inline">\(i^{th}\)</span> data point is given by</p>
<p><span class="math display">\[D_{i} =\left(\frac{h_{ii} }{1-h_{ii} } \right)\left(\frac{r_{i}^{2} }{p} \right).\]</span> where <span class="math inline">\(r_{i}\)</span> is the standardised residual given by <span class="math display">\[r_{i} =\frac{e_{i} }{s_{e} \sqrt{1-\left(\frac{1}{n} +\frac{x_{i} -\bar{x}}{S_{xx} } \right)} }.\]</span></p>
<p>As a rule of thumb, points with <span class="math inline">\(D_{i} &gt;0.7\)</span> can be deemed as being influential (for <span class="math inline">\(n&gt;15\)</span>). If <span class="math inline">\(D_{i} &gt;1\)</span>, then the influence of this point is far greater and must be investigated further.</p>
<p>We prefer to examine plots of <span class="math inline">\(D_{i}\)</span> (and <span class="math inline">\(h_{ii}\)</span>) against the residuals, standardised residuals, explanatory variables, fitted values or time order etc for a visual identification of any observation with markedly higher influence than the other observations in the data. As an example, consider the data set <strong>Rangitikei</strong>. <a href="#fig-rangiHi">Figure&nbsp;14</a> shows that the 26th observation is clearly anomalous.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">download.file</span>(</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">url =</span> <span class="st">"http://www.massey.ac.nz/~anhsmith/data/rangitikei.RData"</span>,</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">destfile =</span> <span class="st">"rangitikei.RData"</span>)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"rangitikei.RData"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(rangitikei, <span class="fu">aes</span>(<span class="at">x=</span>vehicle, <span class="at">y=</span>people)) <span class="sc">+</span> </span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">"lm"</span>) <span class="sc">+</span> </span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Rangitikei Data"</span>) <span class="sc">+</span> </span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">label =</span> <span class="st">"# 26"</span>, <span class="at">x =</span> <span class="dv">115</span>, <span class="at">y =</span> <span class="dv">475</span>, <span class="at">size =</span> <span class="dv">4</span>, <span class="at">colour =</span> <span class="st">"red"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using formula = 'y ~ x'</code></pre>
</div>
<div class="cell-output-display">
<div id="fig-rangiHi" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="6-single_files/figure-html/fig-rangiHi-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;14: Scatter plot of People vs Vehicle</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#fig-rangiHiCook">Figure&nbsp;15</a> shows the standardised residuals vs.&nbsp;leverage plot of the linear regression of people (<span class="math inline">\(Y\)</span>) on vehicles (<span class="math inline">\(X\)</span>). This plot also shows the Cook’s distance and warning limits at 0.5 and 1. Clearly the observation #26 is a point of high leverage (<span class="math inline">\(h_{ii}\)</span> being 0.63) as well as influential (<span class="math inline">\(D_{i}\)</span> being 4.97).</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(<span class="fu">lm</span>(people<span class="sc">~</span>vehicle, <span class="at">data=</span>rangitikei), <span class="at">which=</span><span class="dv">6</span>, <span class="at">ncol=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-rangiHiCook" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="6-single_files/figure-html/fig-rangiHiCook-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;15: Residual Diagnostic Plot: Cook’s distance vs Leverage</figcaption>
</figure>
</div>
</div>
</div>
<p>The formulae for <span class="math inline">\(h_{ii}\)</span> and <span class="math inline">\(D_{i}\)</span> presented in this section are valid for simple regression only. It is general practice to examine the four plots (which are placed in a single layout) shown in <a href="#fig-fourinone">Figure&nbsp;16</a>) for residual analysis of a regression fit.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>ggplot2<span class="sc">::</span><span class="fu">autoplot</span>(<span class="fu">lm</span>(people<span class="sc">~</span>vehicle, <span class="at">data=</span>rangitikei))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-fourinone" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="6-single_files/figure-html/fig-fourinone-1.png" class="img-fluid figure-img" width="768"></p>
<figcaption class="figure-caption">Figure&nbsp;16: Residual Diagnostic Plots</figcaption>
</figure>
</div>
</div>
</div>
<p>The fourth plot will show the Cook’s distance contours when the base <code>plot()</code> function is used instead of <code>autoplot()</code> function.</p>
<p>The weighted least squares regression approach places differing weights for each pair of points and minimises the sum of weighted squared residuals. The <code>R</code> function <code>lm()</code> allows for this. A popular approach is to employ the reciprocal of error variance of the response <span class="math inline">\(Y_i\)</span> at a given <span class="math inline">\(X_i\)</span>. An example of weighted least squares line is shown in <a href="#fig-ols">Figure&nbsp;17</a>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>ols <span class="ot">&lt;-</span> <span class="fu">lm</span>(people<span class="sc">~</span>vehicle, <span class="at">data=</span>rangitikei)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>wts <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">/</span> <span class="fu">lm</span>(<span class="fu">abs</span>(ols<span class="sc">$</span>residuals) <span class="sc">~</span> ols<span class="sc">$</span>fitted.values)<span class="sc">$</span>fitted.values<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(rangitikei) <span class="sc">+</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x=</span>vehicle, <span class="at">y=</span>people) <span class="sc">+</span> </span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">"lm"</span>, <span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">weight =</span> wts)) <span class="sc">+</span> </span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Weighted regression"</span>) <span class="sc">+</span> </span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">label =</span> <span class="st">"# 26"</span>, <span class="at">x =</span> <span class="dv">115</span>, <span class="at">y =</span> <span class="dv">475</span>, <span class="at">size =</span> <span class="dv">4</span>, <span class="at">colour =</span> <span class="st">"blue"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using formula = 'y ~ x'</code></pre>
</div>
<div class="cell-output-display">
<div id="fig-ols" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="6-single_files/figure-html/fig-ols-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;17: Weighted least squares fit</figcaption>
</figure>
</div>
</div>
</div>
<p><em>median-median or resistant line</em></p>
<p>The median–median line is an alternative to the least squares regression and is resistant or robust to outliers. To obtain this line, we divide the data into three equal size groups after sorting the <span class="math inline">\(X\)</span> variable data. If equal division cannot be done, the middle group can be larger than the low and high groups. For the low and high groups, obtain the medians of the <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> values separately. The median–median line (also called Rline) is the line joining these two sets of median points. A more sophisticated version of fitting a resistant line is available in statistical software programs including R, which mainly implement the procedure suggested by <span class="citation" data-cites="Hoaglin1983">Hoaglin, Mosteller, and Tukey (<a href="#ref-Hoaglin1983" role="doc-biblioref">1983</a>)</span>. Such approaches place additional restrictions on the residuals of the fitted resistant line or shift the original line one-third of the way from its original position toward the median-median point of the middle group.</p>
<p>The R function <code>line()</code> will fit a resistant line using a method proposed by Tukey, and hence this fit is called <strong>Tukey Line</strong>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">download.file</span>(</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">url =</span> <span class="st">"http://www.massey.ac.nz/~anhsmith/data/testmarks.RData"</span>, </span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">destfile =</span> <span class="st">"testmarks.RData"</span>)</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"testmarks.RData"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">line</span>(<span class="at">x=</span> testmarks<span class="sc">$</span>Maths, <span class="at">y=</span>testmarks<span class="sc">$</span>English)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The fitted Tukey line is shown in <a href="#fig-tukline">Figure&nbsp;18</a>:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>Tukeyline <span class="ot">&lt;-</span> <span class="fu">line</span>(<span class="at">x =</span> testmarks<span class="sc">$</span>Maths, <span class="at">y =</span> testmarks<span class="sc">$</span>English)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>testmarks <span class="sc">|&gt;</span> </span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">fits=</span><span class="fu">fitted</span>(Tukeyline)) <span class="sc">|&gt;</span> </span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span> </span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x =</span> Maths, <span class="at">y =</span> English) <span class="sc">+</span> </span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x=</span>Maths, <span class="at">y=</span>fits))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-tukline" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="6-single_files/figure-html/fig-tukline-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;18: Tukey line fit</figcaption>
</figure>
</div>
</div>
</div>
<p>There are variations to robust modelling. We may use the means rather than medians in each group after dividing the data into three parts. Generally speaking, if the data set is large or the residuals distributed nearly normally then the means of the lower and upper groups are more appropriate than the medians. The other approaches include (i) minimising the sum of absolute residuals (ii) least median of squares (LMS) etc.</p>
<p>For best fitting procedures, we minimise the residuals in some way - for example, by minimising <span class="math inline">\(\Sigma e_{i}^{p}\)</span> for some value of <em>p</em>. For fitting regression lines, we use the method of least squares where <em>p</em> = 2, i.e.&nbsp;the fitted line is such that the sum of squares of the residuals is as small as possible. However this procedure of minimising sums of squares is unduly affected by large residuals and so the regression line is pulled towards points which would give large residuals.</p>
<p>Unusual observations of <span class="math inline">\(Y\)</span> tend to have more influence on the line than we would like. Some authors suggest that a better value for <em>p</em> would be 1.5. Another approach is to use <em>p</em> = 2 if the residuals are of moderate size but to reduce the value of <em>p</em> if the residual is large. Alternatively, if the residual is larger in absolute value than some high but realistic value then the residual is replaced by this value with the appropriate sign. Other procedures have also been devised which limit the influence on the regression line of unusually large or small values of <span class="math inline">\(Y\)</span>.</p>
<p>The advantage of robust estimation is that a few peculiar values of data do not have a large influence on the estimates. However the theory behind the statistical tests done on the estimated coefficients is more complicated when compared to the traditional methods. Two further R based robust methods of fitting lines are discussed below.</p>
<p>The <code>R</code> package function <code>rlm()</code> fits a robust linear model using an iterative procedure method, and we will not cover the theory behind this method in this course.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(testmarks) <span class="sc">+</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x =</span> Maths, <span class="at">y =</span> English) <span class="sc">+</span> </span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">"rlm"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using formula = 'y ~ x'</code></pre>
</div>
</div>
<div class="cell">
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'MASS'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following object is masked from 'package:patchwork':

    area</code></pre>
</div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="6-single_files/figure-html/unnamed-chunk-39-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Graph showing robust linear fit</figcaption>
</figure>
</div>
</div>
</div>
<p>The <code>R</code> package <code>robustbase</code> function <code>lmrob()</code> is another option; see <a href="#fig-robbaseline">Figure&nbsp;19</a>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(testmarks) <span class="sc">+</span> </span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x =</span> Maths, <span class="at">y =</span> English) <span class="sc">+</span> </span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">"lmrob"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>`geom_smooth()` using formula = 'y ~ x'</code></pre>
</div>
<div class="cell-output-display">
<div id="fig-robbaseline" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="6-single_files/figure-html/fig-robbaseline-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;19: Graph showing robust regression</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(robustbase)</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="fu">lmrob</span>(English <span class="sc">~</span> Maths, <span class="at">data =</span> testmarks) <span class="sc">|&gt;</span> <span class="fu">summary</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lmrob(formula = English ~ Maths, data = testmarks)
 \--&gt; method = "MM"
Residuals:
    Min      1Q  Median      3Q     Max 
-30.571  -8.295   1.757   8.234  20.291 

Coefficients:
            Estimate Std. Error t value            Pr(&gt;|t|)    
(Intercept) 11.33456    2.83623   3.996            0.000285 ***
Maths        0.72098    0.05813  12.402 0.00000000000000625 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Robust residual standard error: 13.17 
Multiple R-squared:  0.7558,    Adjusted R-squared:  0.7494 
Convergence in 8 IRWLS iterations

Robustness weights: 
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.5692  0.9093  0.9644  0.9363  0.9835  0.9990 
Algorithmic parameters: 
       tuning.chi                bb        tuning.psi        refine.tol 
  1.5476400000000   0.5000000000000   4.6850610000000   0.0000001000000 
          rel.tol         scale.tol         solve.tol          zero.tol 
  0.0000001000000   0.0000000001000   0.0000001000000   0.0000000001000 
      eps.outlier             eps.x warn.limit.reject warn.limit.meanrw 
  0.0025000000000   0.0000000001728   0.5000000000000   0.5000000000000 
     nResample         max.it       best.r.s       k.fast.s          k.max 
           500             50              2              1            200 
   maxit.scale      trace.lev            mts     compute.rd fast.s.large.n 
           200              0           1000              0           2000 
                  psi           subsampling                   cov 
           "bisquare"         "nonsingular"         ".vcov.avar1" 
compute.outlier.stats 
                 "SM" 
seed : int(0) </code></pre>
</div>
</div>
<p>The slope estimates are similar for the above robust fits. The standard error of the estimated y-intercept is usually large. The slope of the line being the important parameter, we may conclude that the fitted slope of 0.72 is the robust value.</p>
<section id="cross-validation-cv" class="level2">
<h2 class="anchored" data-anchor-id="cross-validation-cv">Cross Validation (CV)</h2>
<p>This technique is commonly employed for validating models for prediction purposes. The available data is split randomly into <span class="math inline">\(k\)</span> (equal) folds (parts), often by resampling. A model is fitted for the <span class="math inline">\((k-1)\)</span> folds of the data, and then the prediction errors are calculated for the fold that was omitted for modelling. This process can be repeated omitting one subset (out of the <span class="math inline">\(k\)</span> subsets) so that all the <span class="math inline">\(k\)</span> subsets contribute to the estimation of prediction accuracy. This exercise is computationally intensive, and hence we will leave it to the software package such as <em>caret</em>, <em>rsample</em> or <em>modelr</em> to perform the cross validation. Consider the simple regression of WEIGHT on EXTDIA done with the horsesheart data. The following <code>R</code> code perform the 5-fold cross validation of the model for prediction purposes and compare the root mean square errors for both the regression and robust regression models.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS, <span class="at">exclude =</span> <span class="st">"select"</span>)</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up cross validation</span></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>fitControl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"repeatedcv"</span>, </span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>                           <span class="at">number =</span> <span class="dv">5</span>, </span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>                           <span class="at">repeats =</span> <span class="dv">100</span>)</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a><span class="co"># lmfit</span></span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>lmfit <span class="ot">&lt;-</span>  <span class="fu">train</span>(WEIGHT <span class="sc">~</span> EXTDIA,</span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a>                <span class="at">data =</span> horsehearts, </span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a>                <span class="at">trControl =</span> fitControl, </span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a>                <span class="at">method =</span> <span class="st">"lm"</span>)</span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a><span class="co"># rlmfit</span></span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a>rlmfit <span class="ot">&lt;-</span> <span class="fu">train</span>(WEIGHT <span class="sc">~</span> EXTDIA, </span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a>                <span class="at">data =</span> horsehearts, </span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a>                <span class="at">trControl =</span> fitControl, </span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a>                <span class="at">method =</span> <span class="st">"rlm"</span>)</span>
<span id="cb46-22"><a href="#cb46-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-23"><a href="#cb46-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the RMSE scores</span></span>
<span id="cb46-24"><a href="#cb46-24" aria-hidden="true" tabindex="-1"></a>dfm <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb46-25"><a href="#cb46-25" aria-hidden="true" tabindex="-1"></a>  <span class="at">lm =</span> lmfit <span class="sc">|&gt;</span> <span class="fu">pluck</span>(<span class="st">"resample"</span>) <span class="sc">|&gt;</span> <span class="fu">pull</span>(RMSE),</span>
<span id="cb46-26"><a href="#cb46-26" aria-hidden="true" tabindex="-1"></a>  <span class="at">rlm =</span> rlmfit <span class="sc">|&gt;</span> <span class="fu">pluck</span>(<span class="st">"resample"</span>) <span class="sc">|&gt;</span> <span class="fu">pull</span>(RMSE)</span>
<span id="cb46-27"><a href="#cb46-27" aria-hidden="true" tabindex="-1"></a>) <span class="sc">|&gt;</span> </span>
<span id="cb46-28"><a href="#cb46-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols=</span><span class="fu">everything</span>(),</span>
<span id="cb46-29"><a href="#cb46-29" aria-hidden="true" tabindex="-1"></a>               <span class="at">names_to =</span> <span class="st">"Method"</span>,</span>
<span id="cb46-30"><a href="#cb46-30" aria-hidden="true" tabindex="-1"></a>               <span class="at">values_to =</span> <span class="st">"RMSE"</span>)</span>
<span id="cb46-31"><a href="#cb46-31" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb46-32"><a href="#cb46-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Make plot of RMSE</span></span>
<span id="cb46-33"><a href="#cb46-33" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dfm) <span class="sc">+</span></span>
<span id="cb46-34"><a href="#cb46-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x=</span>Method, <span class="at">y=</span>RMSE, <span class="at">col =</span> Method) <span class="sc">+</span> </span>
<span id="cb46-35"><a href="#cb46-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>() <span class="sc">+</span></span>
<span id="cb46-36"><a href="#cb46-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span> </span>
<span id="cb46-37"><a href="#cb46-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-cvgraph" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="6-single_files/figure-html/fig-cvgraph-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;20: Comparison of Residual Mean Square Error (RMSE) of lm() vs rlm() fits</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#fig-cvgraph">Figure&nbsp;20</a> shows that the robust <code>rlm()</code> fit slightly outperforms the simple regression fit in terms of RMSE. The number of folds fixed can affect the comparison. The choice of k=5 or 10 is usually recommended.</p>
<p><a href="#fig-cvgraph1">Figure&nbsp;21</a> shows the cross validation RMSEs for the <code>lm()</code> and <code>rlm()</code> fits for the Rangitikei dataset based on <code>modelr</code> package codes. The robust model again perform slightly better but this does not mean the fitted model is the best one for prediction.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(purrr)</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(modelr)</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up cross validation</span></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>cv2 <span class="ot">&lt;-</span> <span class="fu">crossv_mc</span>(rangitikei, <span class="dv">500</span>)</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the models</span></span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a>lm_models <span class="ot">&lt;-</span> <span class="fu">map</span>(cv2<span class="sc">$</span>train, <span class="sc">~</span> <span class="fu">lm</span>(people <span class="sc">~</span> vehicle, <span class="at">data =</span> .))</span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a>rlm_models <span class="ot">&lt;-</span> <span class="fu">map</span>(cv2<span class="sc">$</span>train, <span class="sc">~</span> <span class="fu">rlm</span>(people <span class="sc">~</span> vehicle, <span class="at">data =</span> .))</span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the RMSE scores</span></span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a>dfm <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb47-15"><a href="#cb47-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">lm =</span> <span class="fu">map2_dbl</span>(lm_models, cv2<span class="sc">$</span>test, rmse),</span>
<span id="cb47-16"><a href="#cb47-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">rlm =</span> <span class="fu">map2_dbl</span>(rlm_models, cv2<span class="sc">$</span>test, rmse)</span>
<span id="cb47-17"><a href="#cb47-17" aria-hidden="true" tabindex="-1"></a>) <span class="sc">|&gt;</span> </span>
<span id="cb47-18"><a href="#cb47-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols=</span><span class="fu">everything</span>(),</span>
<span id="cb47-19"><a href="#cb47-19" aria-hidden="true" tabindex="-1"></a>               <span class="at">names_to =</span> <span class="st">"Method"</span>,</span>
<span id="cb47-20"><a href="#cb47-20" aria-hidden="true" tabindex="-1"></a>               <span class="at">values_to =</span> <span class="st">"RMSE"</span>)</span>
<span id="cb47-21"><a href="#cb47-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-22"><a href="#cb47-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a plot</span></span>
<span id="cb47-23"><a href="#cb47-23" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dfm) <span class="sc">+</span></span>
<span id="cb47-24"><a href="#cb47-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x=</span>Method, <span class="at">y=</span>RMSE, <span class="at">col =</span> Method) <span class="sc">+</span> </span>
<span id="cb47-25"><a href="#cb47-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>() <span class="sc">+</span></span>
<span id="cb47-26"><a href="#cb47-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span> </span>
<span id="cb47-27"><a href="#cb47-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-cvgraph1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="6-single_files/figure-html/fig-cvgraph1-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;21: Comparison of RMSEs of lm() and rlm() fits under cross validation</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="summary" class="level1">
<h1>Summary</h1>
<p>Once a model is fitted to data, the question must be asked as to whether the fit is a good one. Perhaps it would be more in keeping with the spirit of statistical tests to ask if the fit is bad. The fitted model is of the general form</p>
<p><span class="math display">\[ \text{observation = fit+ residual}\]</span></p>
<p>Model improvement will take place to capture all the systematic variation in the data. This chapter considered only straight line models with a single predictor variable. If the fit is poor, a transformation could be tried by stretching or shrinking <span class="math inline">\(Y\)</span> by a power transformation.</p>
<p>Scatterplots and correlation coefficients provide important clues to the inter-relationships between the variables and hence form the first step in building a regression model. The simple regression model is one of the most commonly used tools. Here the main aim is to fit a model (slope and <span class="math inline">\(y\)</span>-intercept) by the least squares method to explain the variation in <span class="math inline">\(Y\)</span>, the response variable, by fitting the explanatory (<span class="math inline">\(X\)</span>) variable. Regression models are often improved in several ways after residual analysis.</p>
<p><strong>What is THE best model for this data?</strong> If there is an answer to this question, it should not be determined solely on statistical grounds. Statistics as a tool (often a very powerful tool) can only suggest the best model given that a number of assumptions have been agreed on. Ideally, one would not have to make a decision on the basis of a single sample as we have here. We should examine the literature to discover similar examples and see how they were tackled or, even better, one could discuss the matter with a researcher who has worked on similar data sets. If the aim is to estimate the coefficients or to predict the weight of the heart of another living horse from ultrasound measurements, we tend to select the simplest, feasible model. In this case, we could choose a model with ONE predictor variable (say <em>innerdia</em>). And a cube root or logarithm transformation might be applied. With more than one explanatory variable, the number of possibilities increases for relationships between these variables and between the response variable <span class="math inline">\(Y\)</span>. These possibilities will be discussed further in the next chapter.</p>
<section id="main-points" class="level2">
<h2 class="anchored" data-anchor-id="main-points">Main points</h2>
<p>Concepts and practical skills you should have at the end of this chapter:</p>
<ul>
<li>Understand and be able to perform a simple linear regression on bivariate related data sets</li>
<li>Use scatter plots or other appropriate plots to visualize the data and regression line</li>
<li>Summarize regression results and appropriate tests of significance. Interpret these results in context of your data</li>
<li>Examine residual diagnostic plots and test assumptions, then perform appropriate transformations as necessary</li>
<li>Use a regression line to predict new data and explain confidence and prediction intervals</li>
<li>Understand and explain the concepts of robust regression modeling, Tukey Line, and cross-validation.</li>
</ul>
</section>
<section id="models-related-to-simple-regression-model" class="level2">
<h2 class="anchored" data-anchor-id="models-related-to-simple-regression-model">Models Related to Simple Regression Model</h2>
<p>For some applications, the true <span class="math inline">\(y\)</span>-intercept <span class="math inline">\(\alpha\)</span> is <em>known</em> to be zero. An example is when a model is fitted with compositional characteristics as predictors such as percentage fat, protein, moisture in milk powder. The sum of these compositional characteristics is always 100% and this constraint removes the intercept due to theoretical reasons. In such cases, we will be fitting only the slope(s). When the model without the <span class="math inline">\(y\)</span>-intercept is the true or correct model, both the fitted models (with and without the <span class="math inline">\(y\)</span>-intercept) provide unbiased estimates of the true parameters. However the model without the intercept will provide precise estimates. This regression model without the intercept must be used with caution because a very strong assumption is made on the true <span class="math inline">\(y\)</span>-intercept. The first differences of certain time series data may be analysed with a model having no intercept term.</p>
<p>For some applications such as measurement system analysis in metrology <strong>orthogonal regression</strong> models are fitted because both X and Y variables are subject to measurement errors. In the least squares method, we minimise the sum of the squared vertical distances between the actual Y and fitted Y values. For orthogonal regression, we consider the perpendicular distances instead. This approach is a subset of a theory known as <strong>principal components</strong>. The orthogonal regression approach was popularised by Deming for industrial applications and hence this fit is also known as <strong>Deming regression</strong>. <code>R</code> software packages (such as <code>MethComp</code>, <code>deming</code> and <code>mcr</code>) will fit orthogonal regression models. <a href="#fig-dmng">Figure&nbsp;22</a> shows the Deming regression model to <strong>testmarks</strong> data but you do not have to perform this regression for this course.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>my.pca <span class="ot">&lt;-</span> <span class="fu">prcomp</span>( <span class="sc">~</span> Maths<span class="sc">+</span>English, <span class="at">data=</span>testmarks)</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>slp <span class="ot">&lt;-</span> my.pca<span class="sc">$</span>rotation[<span class="dv">2</span>,<span class="dv">1</span>] <span class="sc">/</span> my.pca<span class="sc">$</span>rotation[<span class="dv">1</span>,<span class="dv">1</span>]</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>intr <span class="ot">&lt;-</span> my.pca<span class="sc">$</span>center[<span class="dv">2</span>] <span class="sc">-</span> slp<span class="sc">*</span>my.pca<span class="sc">$</span>center[<span class="dv">1</span>]</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>my.caption <span class="ot">=</span> <span class="fu">paste</span>(<span class="st">"Slope="</span>, <span class="fu">round</span>(slp, <span class="dv">2</span>), <span class="st">"  "</span>, <span class="st">"Intercept"</span>, <span class="fu">round</span>(intr, <span class="dv">2</span>))</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(testmarks) <span class="sc">+</span> </span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x=</span>Maths,<span class="at">y=</span>English)) <span class="sc">+</span> </span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> intr, <span class="at">slope =</span> slp) <span class="sc">+</span> </span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Orthogonal Regression"</span>) <span class="sc">+</span> </span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">caption =</span> my.caption)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-dmng" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="6-single_files/figure-html/fig-dmng-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;22: Orthogonal regression</figcaption>
</figure>
</div>
</div>
</div>
<p>A number of relationships between variables can be linearised by transformations. For example, the relationship <span class="math inline">\(y=\alpha x^{\beta }\)</span> is linearised by taking <span class="math inline">\(\log\)</span> on both sides as <span class="math display">\[\log (y)=\log (\alpha )+\beta \log (x).\]</span> The methods discussed in this chapter will equally apply for models which can be rewritten as a straight line equation.</p>


<!-- -->


</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-Hoaglin1983" class="csl-entry" role="listitem">
Hoaglin, D. S., F. Mosteller, and J. W. Tukey. 1983. <em>Understanding Robust and Exploratory Analysis</em>. NY: Wiley.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../studyguide/5-tabulated.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Chapter 5: Tabulated Counts</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../studyguide/7-multiple.html" class="pagination-link">
        <span class="nav-page-text">Chapter 7: Models with Multiple Continuous Predictors</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb49" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Chapter 6: Models with a Single Continuous Predictor"</span></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; "*The sciences do not try to explain, they hardly even try to interpret, they mainly make models. By a model is meant a mathematical construct which, with the addition of verbal interpretations, describes observed phenomena. The justification of such a mathematical construct is solely and precisely that it is expected to work.*"</span><span class="kw">&lt;br&gt;</span></span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; — von Neumann</span></span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a><span class="fu"># Modelling bivariate data</span></span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>In this section, we consider straight line relationships between two variables. We learn how to fit simple regression and robust lines. The later fit to data is not affected by extreme or unusual data points. As a natural outgrowth of this fitting procedure, a method of testing for linearity emerges.</span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>Consider paired data ($X$, $Y$) and suppose that we want to describe the response variable ($Y$) in terms of the covariate or explanatory variable ($X$) using a straight line. This means that the true assumed relationship is of the form $$y=\alpha +\beta x+\varepsilon$$ where $\alpha$ is the true $y$-intercept, $\beta$ is the true slope and $\varepsilon$ is the random error term, without which the relationship will become purely deterministic. Note that this model has two parameters $\alpha$ and $\beta$ which are unknown population quantities which must be estimated using data. In other words, statistical model must be fitted for confirmatory analysis of data.</span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a>In general, a fitted statistical model can be expressed in the following form</span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a>$$\text{observation = fit + residual}$$</span>
<span id="cb49-17"><a href="#cb49-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-18"><a href="#cb49-18" aria-hidden="true" tabindex="-1"></a>For fitting straight line models, we have</span>
<span id="cb49-19"><a href="#cb49-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-20"><a href="#cb49-20" aria-hidden="true" tabindex="-1"></a>$$\text{fit} = a + b\text{x}$$</span>
<span id="cb49-21"><a href="#cb49-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-22"><a href="#cb49-22" aria-hidden="true" tabindex="-1"></a>Here $a$ is the *estimate* of the $y$-intercept $\alpha$ and $b$ is the *estimated* slope of the line $\beta$. The estimates $a$ and $b$ will vary from sample to sample, but the population parameters $\alpha$ and $\beta$ are fixed and unknown.</span>
<span id="cb49-23"><a href="#cb49-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-24"><a href="#cb49-24" aria-hidden="true" tabindex="-1"></a>Fitting a line or curve to data is one of the most common techniques used in statistics. It is applicable whenever two or more measures are obtained on each element. In the case of the Mathematics and English scores for example, both measures are of the same kind, but this need not be the case.</span>
<span id="cb49-25"><a href="#cb49-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-26"><a href="#cb49-26" aria-hidden="true" tabindex="-1"></a>Consider the dataset **horsehearts** and the first 6 rows (cases) are shown below.</span>
<span id="cb49-27"><a href="#cb49-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-30"><a href="#cb49-30" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-31"><a href="#cb49-31" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb49-32"><a href="#cb49-32" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb49-33"><a href="#cb49-33" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_set</span>(<span class="fu">theme_minimal</span>())</span>
<span id="cb49-34"><a href="#cb49-34" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-35"><a href="#cb49-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-38"><a href="#cb49-38" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-39"><a href="#cb49-39" aria-hidden="true" tabindex="-1"></a><span class="fu">download.file</span>(</span>
<span id="cb49-40"><a href="#cb49-40" aria-hidden="true" tabindex="-1"></a>  <span class="at">url =</span> <span class="st">"http://www.massey.ac.nz/~anhsmith/data/horsehearts.RData"</span>,</span>
<span id="cb49-41"><a href="#cb49-41" aria-hidden="true" tabindex="-1"></a>  <span class="at">destfile =</span> <span class="st">"horsehearts.RData"</span>)</span>
<span id="cb49-42"><a href="#cb49-42" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"horsehearts.RData"</span>)</span>
<span id="cb49-43"><a href="#cb49-43" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-44"><a href="#cb49-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-47"><a href="#cb49-47" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-48"><a href="#cb49-48" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(horsehearts)</span>
<span id="cb49-49"><a href="#cb49-49" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-50"><a href="#cb49-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-51"><a href="#cb49-51" aria-hidden="true" tabindex="-1"></a>A number of measurements on the left ventricle of a horse's heart were taken by ultra-sound when each animal was alive and then the weights of the hearts were measured after the animals were killed. Any one of the ultra-sound measurements could be used to predict the weight of the heart, in which case the measurements are of different quantities - one being a length and the other a weight. It is not possible to weigh the heart directly until the animal is dead which is rather a drastic way to collect measurements, so fitting a model relating weight ($y$) to an ultra-sound measurement ($x$) allows an estimate of the weight (fitted $y$ or $\hat{y}$) to be made while the animal is still alive.</span>
<span id="cb49-52"><a href="#cb49-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-53"><a href="#cb49-53" aria-hidden="true" tabindex="-1"></a>Obviously, we would like the model to fit the data as closely as possible which means that the fit will explain most of the variation in the observations. Therefore the residuals should be free of patterns and represent random variation about the fit. In order to eliminate the patterns in the residuals or to reduce their variation (which increases the influence of the fit) it may be necessary to transform the variables or include other variables in the model. These matters will be considered later on and in the next chapter.</span>
<span id="cb49-54"><a href="#cb49-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-55"><a href="#cb49-55" aria-hidden="true" tabindex="-1"></a>Finally we note that there are at least three reasons for fitting a model:</span>
<span id="cb49-56"><a href="#cb49-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-57"><a href="#cb49-57" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>To **describe the relationships between the variables**. In experiments in industry, agriculture, psychology etc. we may wish to go one step further to understand the process; here we are moving towards cause and effect but we must tread warily. For example, increasing the police force may seem to increase crime but this may be due to more criminals being caught and the public being encouraged to report other crimes.</span>
<span id="cb49-58"><a href="#cb49-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-59"><a href="#cb49-59" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>The model may be necessary to **predict future observations**.</span>
<span id="cb49-60"><a href="#cb49-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-61"><a href="#cb49-61" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>The estimates of coefficients, $a$, $b$ etc., may have particular meanings and may **help to direct future policy or theory**.</span>
<span id="cb49-62"><a href="#cb49-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-63"><a href="#cb49-63" aria-hidden="true" tabindex="-1"></a><span class="fu"># Simple Regression</span></span>
<span id="cb49-64"><a href="#cb49-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-65"><a href="#cb49-65" aria-hidden="true" tabindex="-1"></a>This section gives some theory/maths behind the simple regression, and there is no need to remember any of the formulae presented.</span>
<span id="cb49-66"><a href="#cb49-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-67"><a href="#cb49-67" aria-hidden="true" tabindex="-1"></a>The term **regression** is used to describe the tendency for the *average* value of one variable (called the *response* or dependent variable) to vary with other variables (called *covariates* or explanatory or independent or predictor variables or simply regressors). The **regression equation** is the function that describes this relationship mathematically. A regression model with one explanatory variable is called a **simple regression** model. A **multiple regression** model has at least **two** predictors and this topic is covered in the next chapter.</span>
<span id="cb49-68"><a href="#cb49-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-69"><a href="#cb49-69" aria-hidden="true" tabindex="-1"></a>We can write this regression relationship as $$y=\mu _{y|x} +\varepsilon$$ where $\mu _{y|x}$ is the expected or average value of the response variable $y$ for a given or fixed $x$ value and $e$ represents the random variability of $y$ about its mean. The notation $y|x$ stands for $y$ given $x$.</span>
<span id="cb49-70"><a href="#cb49-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-71"><a href="#cb49-71" aria-hidden="true" tabindex="-1"></a>If a linear relationship between $Y$ and $X$ variables is plausible, then we can express $\mu _{y|x}$ as a straight line involving $x$ as $$\mu _{y|x} =\alpha +\beta x$$ While few assumptions need to be made in order to fit a regression model, further assumptions are often needed in order to make inference about the goodness of the fitted model. These assumptions are:</span>
<span id="cb49-72"><a href="#cb49-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-73"><a href="#cb49-73" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>that $Y$ follows a normal distribution about its mean $\mu _{y|x} =\alpha +\beta x$.</span>
<span id="cb49-74"><a href="#cb49-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-75"><a href="#cb49-75" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>that the variance of $Y$ (say $\sigma ^{2}$) is constant, i.e. unlike the mean it does not change with $x$.</span>
<span id="cb49-76"><a href="#cb49-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-77"><a href="#cb49-77" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>that the distribution of $Y$ for a given $x=x_{1}$ is independent of the distribution of $Y$ for another given $x=x_{2}$ (say).</span>
<span id="cb49-78"><a href="#cb49-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-79"><a href="#cb49-79" aria-hidden="true" tabindex="-1"></a>The first two assumptions together with that of linearity can be combined using the notation $Y\sim N\left(\alpha +\beta x,\, \, \sigma ^{2} \right)$. This set of assumptions made for performing statistical tests on the fitted regression model is illustrated in @fig-f4-6.</span>
<span id="cb49-80"><a href="#cb49-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-81"><a href="#cb49-81" aria-hidden="true" tabindex="-1"></a><span class="al">![Assumptions for forming t and F statistics](images/4-6.png)</span>{#fig-f4-6}</span>
<span id="cb49-82"><a href="#cb49-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-83"><a href="#cb49-83" aria-hidden="true" tabindex="-1"></a>The **least squares method** is used to obtain estimates of the regression coefficients (that is, of the intercept and the slope), as any straight line fit is an equation of the form $a$ + *bx*, and hence the coefficients $a$ and $b$ are ***statistics*** (quantities calculated from the sample) which are used as point estimates of the unknown model parameters $\alpha$ and $\beta$.</span>
<span id="cb49-84"><a href="#cb49-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-85"><a href="#cb49-85" aria-hidden="true" tabindex="-1"></a>The least square estimates of the slope estimate $b$ is given by the formula $$b =\frac{\sum \left(x-\bar{x}\right)\left(y-\bar{y}\right) }{\sum \left(x-\bar{x}\right)^{2}} =\frac{S_{xy} }{S_{xx} } ,$$ and hence the y-intercept estimate is $a=\bar{y}-b\bar{x}.$</span>
<span id="cb49-86"><a href="#cb49-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-87"><a href="#cb49-87" aria-hidden="true" tabindex="-1"></a>An approach to answer the question of the goodness of fit of the model is to check whether the coefficient of $x$, that is $b$, is significantly different from zero. In other words, does $X$ (*extdia*) explain a significant amount of the variation in $Y$ (*weight*)? A $t$-test is used for answering this question.</span>
<span id="cb49-88"><a href="#cb49-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-89"><a href="#cb49-89" aria-hidden="true" tabindex="-1"></a>The true standard deviation of the errors (i.e., $\sigma _{\varepsilon }$ of the model $y=\mu _{y|x} +\varepsilon$) is estimated using the residuals of the fitted simple model. This estimate is given by the formula $$s_{e} =\sqrt{\frac{\sum \left(y-\hat{y}\right)^2 }{n-2} }.$$</span>
<span id="cb49-90"><a href="#cb49-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-91"><a href="#cb49-91" aria-hidden="true" tabindex="-1"></a>The the estimated standard error of $b$ is given by the formula $$s_{b} =\frac{s_{e} }{\sqrt{S_{xx} } }.$$</span>
<span id="cb49-92"><a href="#cb49-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-93"><a href="#cb49-93" aria-hidden="true" tabindex="-1"></a>The estimated standard error of $a$ is given by $$s_{a} =\sqrt{s_{e}^{2} \left(\frac{1}{n} +\frac{\bar{x}^{2} }{S_{xx} } \right)}.$$</span>
<span id="cb49-94"><a href="#cb49-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-95"><a href="#cb49-95" aria-hidden="true" tabindex="-1"></a>Note that the 95% confidence intervals for the true $\beta$ and $\alpha$ are found using the $t$-distribution for the $df$ associated with the residual standard error namely $(n-2)$. For example, the 95% CI of the slope $\beta$ is given by $b\pm t_{n-2} s_{b}$.</span>
<span id="cb49-96"><a href="#cb49-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-97"><a href="#cb49-97" aria-hidden="true" tabindex="-1"></a>The least squares regression line can be used to estimate the mean response $\mu _{y|x_{0} }$ and predict the actual response $Y_{0}$ for a given value $x_{0}$ of the covariate $X$. In each case the quantity is found by substituting the value $x_0$ into the regression equation, yielding a fitted value $\hat{\mu }_{y|x_{0} } =a+bx_{0}$. If assumptions such as $Y$ is normally distributed with standard deviation $\sigma$, then this prediction has a normal distribution with mean</span>
<span id="cb49-98"><a href="#cb49-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-99"><a href="#cb49-99" aria-hidden="true" tabindex="-1"></a>$$\mu _{y|x_{0} } =\alpha +\beta x_{0}$$ and standard deviation</span>
<span id="cb49-100"><a href="#cb49-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-101"><a href="#cb49-101" aria-hidden="true" tabindex="-1"></a>$$\sigma \sqrt{\frac{1}{n} +\frac{\left(x_{0} -\bar{x}\right)^{2} }{S_{xx} } }.$$ The standard deviation formula suggests that the predictions become more variable when $x_{0}$ is further away from the mean $\bar{x}$.</span>
<span id="cb49-102"><a href="#cb49-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-103"><a href="#cb49-103" aria-hidden="true" tabindex="-1"></a>The confidence interval for the **mean** response at $x_{0}$ is given by</span>
<span id="cb49-104"><a href="#cb49-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-105"><a href="#cb49-105" aria-hidden="true" tabindex="-1"></a>$$\left(a+bx_{0}  \right)\pm  t_{n-2} \times s_{e} \sqrt{\frac{1}{n} +\frac{\left(x_{0} -\bar{x}\right)^{2} }{S_{xx} } }$$ If our aim is to predict the response itself (instead of predicting the mean response at $x_{0}$), then the errors will be further more. In other words we obtain the **Prediction Interval** (PI) for an individual value of $Y$ (not as the mean) as </span>
<span id="cb49-106"><a href="#cb49-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-107"><a href="#cb49-107" aria-hidden="true" tabindex="-1"></a>$$\left(a+bx_{0} \right)\pm  t_{n-2} \times s_{e} \sqrt{1+\frac{1}{n} +\frac{\left(x_{0} -\bar{x}\right)^{2} }{S_{xx} } }.$$ </span>
<span id="cb49-108"><a href="#cb49-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-109"><a href="#cb49-109" aria-hidden="true" tabindex="-1"></a>If $n$ is not small and $x_0$ is near the centre of the distribution of $X$, then the prediction standard error can be approximated by $\sigma$ which is itself estimated by $s_{e}$, the residual standard error. This means that an approximate 95% interval for the prediction is given by $\left(a+bx_{0} \right)\pm 2s_{e}$.</span>
<span id="cb49-110"><a href="#cb49-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-111"><a href="#cb49-111" aria-hidden="true" tabindex="-1"></a>We consider the data set **horsehearts** and discuss simple regression analysis.</span>
<span id="cb49-112"><a href="#cb49-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-113"><a href="#cb49-113" aria-hidden="true" tabindex="-1"></a><span class="fu">## Displaying &amp; Interpreting the Fitted Model</span></span>
<span id="cb49-114"><a href="#cb49-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-115"><a href="#cb49-115" aria-hidden="true" tabindex="-1"></a>It is fairly easy to display fitted simple regression line on a scatter plot; see @fig-simpreg1 and the <span class="in">`R`</span> codes shown below:</span>
<span id="cb49-116"><a href="#cb49-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-119"><a href="#cb49-119" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-120"><a href="#cb49-120" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb49-121"><a href="#cb49-121" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb49-122"><a href="#cb49-122" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-simpreg1</span></span>
<span id="cb49-123"><a href="#cb49-123" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Simple regression line'</span></span>
<span id="cb49-124"><a href="#cb49-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-125"><a href="#cb49-125" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(horsehearts) <span class="sc">+</span></span>
<span id="cb49-126"><a href="#cb49-126" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x=</span>EXTDIA, <span class="at">y=</span>WEIGHT) <span class="sc">+</span> </span>
<span id="cb49-127"><a href="#cb49-127" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb49-128"><a href="#cb49-128" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> lm, <span class="at">se =</span> <span class="cn">FALSE</span>)</span>
<span id="cb49-129"><a href="#cb49-129" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-130"><a href="#cb49-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-131"><a href="#cb49-131" aria-hidden="true" tabindex="-1"></a>The geoms <span class="in">`geom_smooth()`</span> or <span class="in">`stat_smooth()`</span> add the fitted regression line to the plot. For the simple regression of <span class="in">`WEIGHT`</span> (weights of horses' hearts) on <span class="in">`EXTDIA`</span> (diastole exterior width), the fitted simple regression model is $\hat{y}=a+bx$ For horses heart data, the coefficient estimates are obtained as $a$ = -2.0003 and $b$ = 0.2996. That is, the fitted model is given by $fitted~~weight = -2.0003 + 0.2996\times extdia$ or after rounding</span>
<span id="cb49-132"><a href="#cb49-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-133"><a href="#cb49-133" aria-hidden="true" tabindex="-1"></a>$$fitted~~weight = -2 +0.3\times extdia$$</span>
<span id="cb49-134"><a href="#cb49-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-135"><a href="#cb49-135" aria-hidden="true" tabindex="-1"></a>For a given <span class="in">`extdia`</span> $\left(x\right)$ value, the expected weight is given by the fitted simple regression equation. For example, the exterior width (during diastole phase) for the $39^{th}$ horse is 15.0mm and fitted weight is therefore</span>
<span id="cb49-136"><a href="#cb49-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-137"><a href="#cb49-137" aria-hidden="true" tabindex="-1"></a>$$fitted~~weight =\hat{y}_{39} = -2 + 0.3 \times 15 = 2.5$$</span>
<span id="cb49-138"><a href="#cb49-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-139"><a href="#cb49-139" aria-hidden="true" tabindex="-1"></a>The observed weight of its heart $\left(y_{39} \right)$ is 4.1kg. For this horse, we obtain the residual as</span>
<span id="cb49-140"><a href="#cb49-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-141"><a href="#cb49-141" aria-hidden="true" tabindex="-1"></a>$$e_{39}= \left(y_{39}-\hat{y}_{39} \right) = 4.1- 2.5 = 1.6.$$</span>
<span id="cb49-142"><a href="#cb49-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-143"><a href="#cb49-143" aria-hidden="true" tabindex="-1"></a>$t$*-test for Model Parameters*</span>
<span id="cb49-144"><a href="#cb49-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-145"><a href="#cb49-145" aria-hidden="true" tabindex="-1"></a>It is desirable to use the <span class="in">`R`</span> package <span class="in">`broom`</span> to get parts of the regression outputs. The function <span class="in">`tidy()`</span> extracts the model and the significance testing results; see @tbl-fittedmodel.</span>
<span id="cb49-146"><a href="#cb49-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-149"><a href="#cb49-149" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-150"><a href="#cb49-150" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb49-151"><a href="#cb49-151" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb49-152"><a href="#cb49-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-153"><a href="#cb49-153" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb49-154"><a href="#cb49-154" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(kableExtra)</span>
<span id="cb49-155"><a href="#cb49-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-156"><a href="#cb49-156" aria-hidden="true" tabindex="-1"></a>simplereg <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span>EXTDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb49-157"><a href="#cb49-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-158"><a href="#cb49-158" aria-hidden="true" tabindex="-1"></a><span class="fu">tidy</span>(simplereg)</span>
<span id="cb49-159"><a href="#cb49-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-160"><a href="#cb49-160" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-161"><a href="#cb49-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-162"><a href="#cb49-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-165"><a href="#cb49-165" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-166"><a href="#cb49-166" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb49-167"><a href="#cb49-167" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb49-168"><a href="#cb49-168" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: "tbl-fittedmodel"</span></span>
<span id="cb49-169"><a href="#cb49-169" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "t-tests for model parameters"</span></span>
<span id="cb49-170"><a href="#cb49-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-171"><a href="#cb49-171" aria-hidden="true" tabindex="-1"></a>simplereg <span class="sc">|&gt;</span> </span>
<span id="cb49-172"><a href="#cb49-172" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span></span>
<span id="cb49-173"><a href="#cb49-173" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate_if</span>(is.numeric, round, <span class="dv">5</span>) <span class="sc">|&gt;</span> </span>
<span id="cb49-174"><a href="#cb49-174" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>() <span class="sc">|&gt;</span> </span>
<span id="cb49-175"><a href="#cb49-175" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_classic</span>(<span class="at">full_width =</span> F) </span>
<span id="cb49-176"><a href="#cb49-176" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-177"><a href="#cb49-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-178"><a href="#cb49-178" aria-hidden="true" tabindex="-1"></a>For the horses hearts data, under the null hypothesis that the true (or population) slope $b$ equals zero (i.e., $H_{0}:\beta =0$), the test statistic becomes $$t=\frac{b}{s_{b} } =\frac{0.29963}{0.03877} = 7.728.$$</span>
<span id="cb49-179"><a href="#cb49-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-180"><a href="#cb49-180" aria-hidden="true" tabindex="-1"></a>The $t$-statistic is clearly large enough to be considered significant for $(n-2)$ $df$ and the $p$-value is close to zero. Thus, we would reject the null hypothesis $H_{0} :\beta =0$. In other words, the slope coefficient is significantly different from zero and hence the predictor variable *extdia* explains a significant amount of variation in the response variable *weight*.</span>
<span id="cb49-181"><a href="#cb49-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-182"><a href="#cb49-182" aria-hidden="true" tabindex="-1"></a>We can also carry out a similar $t$-test for the $y$-intercept $\alpha$ based on the $t$-statistic $$t = \frac {a}{s_a}= \frac{-2.00034}{0.55881}=-3.58.$$ but the main interest is in the slope parameter $\beta$. See @tbl-fittedmodel.</span>
<span id="cb49-183"><a href="#cb49-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-184"><a href="#cb49-184" aria-hidden="true" tabindex="-1"></a><span class="fu">## Model Summaries</span></span>
<span id="cb49-185"><a href="#cb49-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-186"><a href="#cb49-186" aria-hidden="true" tabindex="-1"></a>Many of the model summary measures can be obtained for assessing the quality of the fitted model using the <span class="in">`glance()`</span> function from the <span class="in">`broom`</span> package (@tbl-modelsumry).</span>
<span id="cb49-187"><a href="#cb49-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-190"><a href="#cb49-190" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-191"><a href="#cb49-191" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb49-192"><a href="#cb49-192" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb49-193"><a href="#cb49-193" aria-hidden="true" tabindex="-1"></a>simplereg <span class="sc">|&gt;</span> </span>
<span id="cb49-194"><a href="#cb49-194" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glance</span>() <span class="sc">|&gt;</span> </span>
<span id="cb49-195"><a href="#cb49-195" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(r.squared, sigma, statistic, p.value, AIC, BIC)</span>
<span id="cb49-196"><a href="#cb49-196" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-197"><a href="#cb49-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-198"><a href="#cb49-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-201"><a href="#cb49-201" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-202"><a href="#cb49-202" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb49-203"><a href="#cb49-203" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: "tbl-modelsumry"</span></span>
<span id="cb49-204"><a href="#cb49-204" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: "Model summary measures"</span></span>
<span id="cb49-205"><a href="#cb49-205" aria-hidden="true" tabindex="-1"></a><span class="fu">glance</span>(simplereg) <span class="sc">|&gt;</span> </span>
<span id="cb49-206"><a href="#cb49-206" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(r.squared, sigma, statistic, p.value, AIC, BIC) <span class="sc">|&gt;</span> </span>
<span id="cb49-207"><a href="#cb49-207" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate_if</span>(is.numeric, round, <span class="dv">2</span>) <span class="sc">|&gt;</span></span>
<span id="cb49-208"><a href="#cb49-208" aria-hidden="true" tabindex="-1"></a>  <span class="fu">t</span>() <span class="sc">|&gt;</span> </span>
<span id="cb49-209"><a href="#cb49-209" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>() <span class="sc">|&gt;</span>  </span>
<span id="cb49-210"><a href="#cb49-210" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_classic</span>(<span class="at">full_width =</span> F) </span>
<span id="cb49-211"><a href="#cb49-211" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-212"><a href="#cb49-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-213"><a href="#cb49-213" aria-hidden="true" tabindex="-1"></a>How to interpret entries appearing in the R output @tbl-modelsumry is explained below. Note that the $R^{2}$ statistic and the residual standard error are two common summary measures for the fitted model. The other measures such as the AIC and BIC shown in in @tbl-modelsumry are useful for comparison of models, and selecting a *best* model, which will be discussed later on.</span>
<span id="cb49-214"><a href="#cb49-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-215"><a href="#cb49-215" aria-hidden="true" tabindex="-1"></a>**Residual standard error**</span>
<span id="cb49-216"><a href="#cb49-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-217"><a href="#cb49-217" aria-hidden="true" tabindex="-1"></a>The size of the residual standard error $s_{e}$, which is called sigma in @tbl-modelsumry, is important for many reasons. In general, we prefer to have $s_{e}$ no more than 5% of $\bar{y}$ or small compared the range of $y$ data. For the model fitted to horses hearts , the residual standard error is labelled as *sigma* in @tbl-modelsumry. This value of is rather large (compared to the range of $y$ data), and hence the fitted model may not be good for prediction purposes.</span>
<span id="cb49-218"><a href="#cb49-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-219"><a href="#cb49-219" aria-hidden="true" tabindex="-1"></a>The size of $s_{e}$ also controls the size of the standard error of the slope estimate $b$ (and hence its confidence interval).</span>
<span id="cb49-220"><a href="#cb49-220" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-221"><a href="#cb49-221" aria-hidden="true" tabindex="-1"></a>**R-squared** $\left(R^{2} \right)$ **statistic:**</span>
<span id="cb49-222"><a href="#cb49-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-223"><a href="#cb49-223" aria-hidden="true" tabindex="-1"></a>The R-Squared statistic, the proportion of the variation explained by the fitted model, is 0.58. This means that 58 percent of the total variation of the weights is explained by the exterior widths (diastole) using the fitted straight line model namely</span>
<span id="cb49-224"><a href="#cb49-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-225"><a href="#cb49-225" aria-hidden="true" tabindex="-1"></a>$$\text {fitted  weight = -2 +0.3}\times \text {extdia}$$</span>
<span id="cb49-226"><a href="#cb49-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-227"><a href="#cb49-227" aria-hidden="true" tabindex="-1"></a>The $R^{2}$ value is also known as the coefficient of (multiple) determination. Notice that when there is only one explanatory variable $X$, then the $R^{2}$ is equal to the square of the $(X,Y)$ correlation coefficient, i.e. $R^{2} =\left(r_{x,y} \right)^{2}$.</span>
<span id="cb49-228"><a href="#cb49-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-229"><a href="#cb49-229" aria-hidden="true" tabindex="-1"></a>We usually require that $R^{2}$ **be at least 0.5** so that at least half of the variation is explained by the fit. For the Horse data the model $R^{2}$ is not much better than this. However the scatterplot revealed that there may be two different groups of observations in the data and/or the curvature in the data may indicate that a transformation would be advisable so this low $R^{2}$ is not really surprising.</span>
<span id="cb49-230"><a href="#cb49-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-231"><a href="#cb49-231" aria-hidden="true" tabindex="-1"></a>Remember that there is a difference between a **meaningful model** and a **statistically significant model**. An $R^{2}$ of 0.5 or more indicates a meaningful model whereas the $t$-test for slope indicates a statistically significant model. A statistically significant model may not always be a meaningful model - in this case the significance is high but the $R^{2}$ of 57.6% is barely adequate.</span>
<span id="cb49-232"><a href="#cb49-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-233"><a href="#cb49-233" aria-hidden="true" tabindex="-1"></a>**ANOVA and** $F$**-test**</span>
<span id="cb49-234"><a href="#cb49-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-235"><a href="#cb49-235" aria-hidden="true" tabindex="-1"></a>@tbl-modelsumry gives the F-statistic (labelled as just *statistic*) and the P-value for this F-statistic. The concept behind this statistic is explained below:</span>
<span id="cb49-236"><a href="#cb49-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-237"><a href="#cb49-237" aria-hidden="true" tabindex="-1"></a>The variation in a data set can be measured as the sum of the squared deviation from its central value. This Sum of Squares is abbreviated as SS or SumSq in software regression outputs. For a regression model, we have</span>
<span id="cb49-238"><a href="#cb49-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-239"><a href="#cb49-239" aria-hidden="true" tabindex="-1"></a>**I** : total SumSq = variation in the observed values about the mean = $\sum \left(y-\bar{y}\right)^{2}$.</span>
<span id="cb49-240"><a href="#cb49-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-241"><a href="#cb49-241" aria-hidden="true" tabindex="-1"></a>**II** : regression SumSq = Variation in the fitted values about the mean = $\sum \left(\hat{y}-\bar{y}\right)^{2}$ (Note that *fit* is denoted by $\hat{y}$).</span>
<span id="cb49-242"><a href="#cb49-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-243"><a href="#cb49-243" aria-hidden="true" tabindex="-1"></a>**III** : error or residual SumSq = Variation in the residuals $=\sum \left(y-\hat{y}\right)^{2} =\sum e^{2}$.</span>
<span id="cb49-244"><a href="#cb49-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-245"><a href="#cb49-245" aria-hidden="true" tabindex="-1"></a>These sums of squares due to regression, error and total etc are usually displayed in the form of a table known as the analysis of variance table, which is usually shortened to ANOVA or anova. A typical ANOVA table for a simple regression model will appear as in @fig-f4-8. Depending on the package used, the ANOVA table may differ slightly in style.</span>
<span id="cb49-246"><a href="#cb49-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-247"><a href="#cb49-247" aria-hidden="true" tabindex="-1"></a><span class="al">![A typical ANOVA table](images/4-8.png)</span>{#fig-f4-8}</span>
<span id="cb49-248"><a href="#cb49-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-249"><a href="#cb49-249" aria-hidden="true" tabindex="-1"></a><span class="in">`R`</span> does not print the last row while displaying the F-statistic and ANOVA table. The following codes can be used to obtain the ANOVA output for the regression model (@tbl-anovatable).</span>
<span id="cb49-250"><a href="#cb49-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-253"><a href="#cb49-253" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-254"><a href="#cb49-254" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb49-255"><a href="#cb49-255" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb49-256"><a href="#cb49-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-257"><a href="#cb49-257" aria-hidden="true" tabindex="-1"></a>simplereg <span class="sc">|&gt;</span> <span class="fu">anova</span>()</span>
<span id="cb49-258"><a href="#cb49-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-259"><a href="#cb49-259" aria-hidden="true" tabindex="-1"></a><span class="co"># or </span></span>
<span id="cb49-260"><a href="#cb49-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-261"><a href="#cb49-261" aria-hidden="true" tabindex="-1"></a>simplereg <span class="sc">|&gt;</span> <span class="fu">anova</span>() <span class="sc">|&gt;</span> <span class="fu">tidy</span>()</span>
<span id="cb49-262"><a href="#cb49-262" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-263"><a href="#cb49-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-266"><a href="#cb49-266" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-267"><a href="#cb49-267" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb49-268"><a href="#cb49-268" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-anovatable</span></span>
<span id="cb49-269"><a href="#cb49-269" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: 'Analysis of Variance Table'</span></span>
<span id="cb49-270"><a href="#cb49-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-271"><a href="#cb49-271" aria-hidden="true" tabindex="-1"></a>simplereg <span class="sc">|&gt;</span> </span>
<span id="cb49-272"><a href="#cb49-272" aria-hidden="true" tabindex="-1"></a>  <span class="fu">anova</span>() <span class="sc">|&gt;</span> </span>
<span id="cb49-273"><a href="#cb49-273" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">|&gt;</span> </span>
<span id="cb49-274"><a href="#cb49-274" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="fu">where</span>(is.numeric), <span class="sc">~</span><span class="fu">round</span>(., <span class="dv">3</span>)))  <span class="sc">|&gt;</span> </span>
<span id="cb49-275"><a href="#cb49-275" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>() <span class="sc">|&gt;</span></span>
<span id="cb49-276"><a href="#cb49-276" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_classic</span>(<span class="at">full_width =</span> F) </span>
<span id="cb49-277"><a href="#cb49-277" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-278"><a href="#cb49-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-279"><a href="#cb49-279" aria-hidden="true" tabindex="-1"></a>Each sum of squares (source of variation) has associated with it a **degrees of freedom** $df$). For one explanatory variable, the regression $df$ = 1. The total $df$ is always one less than the sample size, that is $n-1.$ In other words, residual $df$ = $n-2$. From the sums of squares, the variance estimates are calculated as **SumSq/df** which are called Mean Squares (**MeanSq**).</span>
<span id="cb49-280"><a href="#cb49-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-281"><a href="#cb49-281" aria-hidden="true" tabindex="-1"></a>For the horses' heart data, we have Regression SumSq = 32.731, Error SumSq= 24.115 and Total SumSq = 56.845. We also have regression $df$ = 1, total $df$ = $n-1 = 45$ and by subtraction residual $df= 45-1= 44$. Dividing the SumSq by the associated $df$, we compute</span>
<span id="cb49-282"><a href="#cb49-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-283"><a href="#cb49-283" aria-hidden="true" tabindex="-1"></a>(i) Regression Mean Sq = 32.731/1 = 32.731\</span>
<span id="cb49-284"><a href="#cb49-284" aria-hidden="true" tabindex="-1"></a>(ii) Residual Mean Sq = 24.115/44 = 0.548\</span>
<span id="cb49-285"><a href="#cb49-285" aria-hidden="true" tabindex="-1"></a>(iii) Total Mean Sq = Total SumSq/45 = $\sum(y-\bar{y})^2/(n-1)=1.263$</span>
<span id="cb49-286"><a href="#cb49-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-287"><a href="#cb49-287" aria-hidden="true" tabindex="-1"></a>Note that the Total Mean Sq is nothing but the variance of $y$, which is usually not displayed in the ANOVA table.</span>
<span id="cb49-288"><a href="#cb49-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-289"><a href="#cb49-289" aria-hidden="true" tabindex="-1"></a>It is possible to formalise the goodness of fit of the model by carrying out an $F$-test. The $F$ statistic is formed by the ratio of two estimates of variances, the regression Mean Sq or variance and the error Mean Sq or variance. The distribution of the $F$ statistic is governed by the numerator $df$ and the denominator $df$. For the horses' heart data, we obtain</span>
<span id="cb49-290"><a href="#cb49-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-291"><a href="#cb49-291" aria-hidden="true" tabindex="-1"></a>$$F =</span>
<span id="cb49-292"><a href="#cb49-292" aria-hidden="true" tabindex="-1"></a>\frac{{\text {regression MeanSq} }}{{\text {residual MeanSq}}}</span>
<span id="cb49-293"><a href="#cb49-293" aria-hidden="true" tabindex="-1"></a>= \frac{32.731}{0.548} = 59.721 $$</span>
<span id="cb49-294"><a href="#cb49-294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-295"><a href="#cb49-295" aria-hidden="true" tabindex="-1"></a>with 1 $df$ for the numerator and 44 $df$ for the denominator.</span>
<span id="cb49-296"><a href="#cb49-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-297"><a href="#cb49-297" aria-hidden="true" tabindex="-1"></a>The null hypothesis is that the model does not fit the data well. That is, the model explains too little of the variation in the $y$ values to be significant. This hypothesis is generally rejected whenever the $p$-value of the $F$-test is less than 0.05. In ANOVA table, the $F$ statistic is displayed along with the $p$-value. Here the $p$-value is the probability of observing an $F$ statistic larger than the computed value. For horses' heart data, the computed $F$ statistic is 59.721. $F$ statistic is always positive (being the ratio of mean squares) and hence the alternative hypothesis must be one-sided. That is, the $p$-value is given by $\Pr \left(F_{1,44} &gt;59.721\right)$ which is very close to zero. This means that the null hypothesis is firmly rejected and we conclude that the regression model using the explanatory variable *extdia* explains a significantly large proportion of the variation of the response variable *weight*.</span>
<span id="cb49-298"><a href="#cb49-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-299"><a href="#cb49-299" aria-hidden="true" tabindex="-1"></a>Note that the $R^{2}$ can also be calculated from the ANOVA table</span>
<span id="cb49-300"><a href="#cb49-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-301"><a href="#cb49-301" aria-hidden="true" tabindex="-1"></a>$$R^{2} =\frac{{\text {regression SumSq}}}{{\text {total SumSq}}} = \frac{32.731}{56.845} = 0.5758$$ or alternatively</span>
<span id="cb49-302"><a href="#cb49-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-303"><a href="#cb49-303" aria-hidden="true" tabindex="-1"></a>$$R^{2} = 1-\frac{{\text {residual SumSq}}}{{\text {total SumSq}}} = 1 -- \frac{24.115}{56.845} = 0.5758.$$ The degrees of freedom for residual SumSq and total SumSq are not identical; while they are very close this is not always the case (e.g. in multiple regression which we will meet in the next chapter). Hence we can adjust for this to obtain the **adjusted R-Squared** ($R_{adj}^{2}$): </span>
<span id="cb49-304"><a href="#cb49-304" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-305"><a href="#cb49-305" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-306"><a href="#cb49-306" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb49-307"><a href="#cb49-307" aria-hidden="true" tabindex="-1"></a>R_{adj}^{2} </span>
<span id="cb49-308"><a href="#cb49-308" aria-hidden="true" tabindex="-1"></a>&amp;= 1-\frac{\left(\frac{{\text {residual SumSq}}}{{\text {residual df}}} \right)}{\left(\frac{{\text {totalSumSq}}}{{\text {total df}}} \right)\, } <span class="sc">\\</span> </span>
<span id="cb49-309"><a href="#cb49-309" aria-hidden="true" tabindex="-1"></a>&amp;= 1-\frac{24.115/44}{56.845/45} <span class="sc">\\</span> </span>
<span id="cb49-310"><a href="#cb49-310" aria-hidden="true" tabindex="-1"></a>&amp;=0.5661.</span>
<span id="cb49-311"><a href="#cb49-311" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb49-312"><a href="#cb49-312" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-313"><a href="#cb49-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-314"><a href="#cb49-314" aria-hidden="true" tabindex="-1"></a>For the simple regression, the $F$-test is equivalent to the previous $t$-test (and produces exactly the same $p$-value). In fact when there is only one explanatory variable the two test statistics are related by the equation $F$ = $t^2$. A further relationship between the two is that the residual standard error is the square root of the residual mean square.</span>
<span id="cb49-315"><a href="#cb49-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-316"><a href="#cb49-316" aria-hidden="true" tabindex="-1"></a>The <span class="in">`summary()`</span> function in base <span class="in">`R`</span> gives rather a bulky output for the fitted regression model particularly when the number of predictors is large.</span>
<span id="cb49-317"><a href="#cb49-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-318"><a href="#cb49-318" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=TRUE, results='hide'}</span></span>
<span id="cb49-319"><a href="#cb49-319" aria-hidden="true" tabindex="-1"></a>simplereg <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span>EXTDIA, <span class="at">data=</span>horsehearts) </span>
<span id="cb49-320"><a href="#cb49-320" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(simplereg)</span>
<span id="cb49-321"><a href="#cb49-321" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-322"><a href="#cb49-322" aria-hidden="true" tabindex="-1"></a>The <span class="in">`R`</span> package <span class="in">`lessR`</span> will get you even a bigger output of model quality and summary measures. We wont be covering all of them but only the essential ones obtained by the <span class="in">`broom`</span> package function <span class="in">`glance()`</span>. Try-</span>
<span id="cb49-323"><a href="#cb49-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-326"><a href="#cb49-326" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-327"><a href="#cb49-327" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb49-328"><a href="#cb49-328" aria-hidden="true" tabindex="-1"></a><span class="co">#| results: false</span></span>
<span id="cb49-329"><a href="#cb49-329" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lessR)</span>
<span id="cb49-330"><a href="#cb49-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-331"><a href="#cb49-331" aria-hidden="true" tabindex="-1"></a><span class="fu">reg</span>(WEIGHT<span class="sc">~</span>EXTDIA, <span class="at">data=</span>horsehearts)</span>
<span id="cb49-332"><a href="#cb49-332" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-333"><a href="#cb49-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-334"><a href="#cb49-334" aria-hidden="true" tabindex="-1"></a><span class="fu">## Prediction and Estimation</span></span>
<span id="cb49-335"><a href="#cb49-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-336"><a href="#cb49-336" aria-hidden="true" tabindex="-1"></a>Recall that the fitted value for the weight of a heart with an *extdia* value of 15.0mm was 2.5kg. This value can be interpreted as the predicted weight of a horse heart with *extdia* = 15mm, or as the estimated of all horse hearts with *extdia* = 15mm. The 95% confidence limits for the **mean** response for the mean weight of horses hearts with *extdia* = 15mm is given by $\left(2.26kg,2.72kg\right)$. However the weight of **any** individual heart with *extdia* = 15mm could (with the same confidence) be as low as 0.98kg or as high as 4.00kg (the prediction interval being (0.98kg, 4.00kg). Notice that the approximate PI formula works as well here: $s$ = 0.7403 and so 2.50 $\pm$ (2 $\times$ 0.74) = (1.0kg, 4.0kg). Note that manual computation of the prediction intervals is harder, and we prefer to use <span class="in">`R`</span> for this.</span>
<span id="cb49-337"><a href="#cb49-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-338"><a href="#cb49-338" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=TRUE}</span></span>
<span id="cb49-339"><a href="#cb49-339" aria-hidden="true" tabindex="-1"></a><span class="co"># confidence interval</span></span>
<span id="cb49-340"><a href="#cb49-340" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(simplereg, <span class="fu">list</span>(<span class="at">EXTDIA =</span> <span class="dv">15</span>), <span class="at">interval =</span> <span class="st">"confidence"</span>)</span>
<span id="cb49-341"><a href="#cb49-341" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-342"><a href="#cb49-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-343"><a href="#cb49-343" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=TRUE}</span></span>
<span id="cb49-344"><a href="#cb49-344" aria-hidden="true" tabindex="-1"></a><span class="co"># prediction interval</span></span>
<span id="cb49-345"><a href="#cb49-345" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(simplereg, <span class="fu">list</span>(<span class="at">EXTDIA =</span> <span class="dv">15</span>), <span class="at">interval =</span> <span class="st">"prediction"</span>)</span>
<span id="cb49-346"><a href="#cb49-346" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-347"><a href="#cb49-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-348"><a href="#cb49-348" aria-hidden="true" tabindex="-1"></a>We can also create a dataset with the desired intervals using the <span class="in">`augment()`</span> function from the <span class="in">`broom`</span> package. </span>
<span id="cb49-349"><a href="#cb49-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-352"><a href="#cb49-352" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-353"><a href="#cb49-353" aria-hidden="true" tabindex="-1"></a>horseCI <span class="ot">&lt;-</span> <span class="fu">augment</span>(simplereg, <span class="at">interval =</span> <span class="st">"confidence"</span>)</span>
<span id="cb49-354"><a href="#cb49-354" aria-hidden="true" tabindex="-1"></a>horsePI <span class="ot">&lt;-</span> <span class="fu">augment</span>(simplereg, <span class="at">interval =</span> <span class="st">"prediction"</span>)</span>
<span id="cb49-355"><a href="#cb49-355" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-356"><a href="#cb49-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-357"><a href="#cb49-357" aria-hidden="true" tabindex="-1"></a>Let's visualise the confidence and prediction bands for the fitted line on a scatter plot using the <span class="in">`geom_ribbon()`</span> function; see @fig-simpregpi.</span>
<span id="cb49-358"><a href="#cb49-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-361"><a href="#cb49-361" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-362"><a href="#cb49-362" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb49-363"><a href="#cb49-363" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-simpregpi</span></span>
<span id="cb49-364"><a href="#cb49-364" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Confidence intervals and prediction intervals'</span></span>
<span id="cb49-365"><a href="#cb49-365" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 7</span></span>
<span id="cb49-366"><a href="#cb49-366" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 7</span></span>
<span id="cb49-367"><a href="#cb49-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-368"><a href="#cb49-368" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> simplereg <span class="sc">|&gt;</span> </span>
<span id="cb49-369"><a href="#cb49-369" aria-hidden="true" tabindex="-1"></a>  <span class="fu">augment</span>(<span class="at">interval =</span> <span class="st">"confidence"</span>) <span class="sc">|&gt;</span></span>
<span id="cb49-370"><a href="#cb49-370" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb49-371"><a href="#cb49-371" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x =</span> EXTDIA) <span class="sc">+</span></span>
<span id="cb49-372"><a href="#cb49-372" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> WEIGHT)) <span class="sc">+</span> </span>
<span id="cb49-373"><a href="#cb49-373" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> .lower, <span class="at">ymax =</span> .upper), <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb49-374"><a href="#cb49-374" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> .fitted)) <span class="sc">+</span></span>
<span id="cb49-375"><a href="#cb49-375" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Confidence interval"</span>) </span>
<span id="cb49-376"><a href="#cb49-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-377"><a href="#cb49-377" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> simplereg <span class="sc">|&gt;</span> </span>
<span id="cb49-378"><a href="#cb49-378" aria-hidden="true" tabindex="-1"></a>  <span class="fu">augment</span>(<span class="at">interval =</span> <span class="st">"prediction"</span>) <span class="sc">|&gt;</span></span>
<span id="cb49-379"><a href="#cb49-379" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb49-380"><a href="#cb49-380" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x =</span> EXTDIA) <span class="sc">+</span></span>
<span id="cb49-381"><a href="#cb49-381" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> WEIGHT)) <span class="sc">+</span> </span>
<span id="cb49-382"><a href="#cb49-382" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> .lower, <span class="at">ymax =</span> .upper), <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb49-383"><a href="#cb49-383" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> .fitted)) <span class="sc">+</span></span>
<span id="cb49-384"><a href="#cb49-384" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Prediction interval"</span>) <span class="sc">+</span></span>
<span id="cb49-385"><a href="#cb49-385" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_light</span>()</span>
<span id="cb49-386"><a href="#cb49-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-387"><a href="#cb49-387" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb49-388"><a href="#cb49-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-389"><a href="#cb49-389" aria-hidden="true" tabindex="-1"></a>p1<span class="sc">/</span>p2</span>
<span id="cb49-390"><a href="#cb49-390" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-391"><a href="#cb49-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-392"><a href="#cb49-392" aria-hidden="true" tabindex="-1"></a>The R package *visreg* readily shows the confidence bands too. Try-</span>
<span id="cb49-393"><a href="#cb49-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-394"><a href="#cb49-394" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=TRUE, fig.show='hide'}</span></span>
<span id="cb49-395"><a href="#cb49-395" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(visreg)</span>
<span id="cb49-396"><a href="#cb49-396" aria-hidden="true" tabindex="-1"></a><span class="fu">visreg</span>(<span class="fu">lm</span>(WEIGHT<span class="sc">~</span>EXTDIA, <span class="at">data=</span>horsehearts),)</span>
<span id="cb49-397"><a href="#cb49-397" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-398"><a href="#cb49-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-399"><a href="#cb49-399" aria-hidden="true" tabindex="-1"></a><span class="fu"># Residual Analysis for Regression</span></span>
<span id="cb49-400"><a href="#cb49-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-401"><a href="#cb49-401" aria-hidden="true" tabindex="-1"></a>A careful examination of the residuals indicates how well a model fits the data and also helps to identify shortcomings and possible ways of improving the model fit. In this section, we review some of the points to notice and use them to improve fitted simple as well as multiple regression models covered in the next Chapter.</span>
<span id="cb49-402"><a href="#cb49-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-405"><a href="#cb49-405" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-406"><a href="#cb49-406" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb49-407"><a href="#cb49-407" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb49-408"><a href="#cb49-408" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-f4-10</span></span>
<span id="cb49-409"><a href="#cb49-409" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Residual vs Fits Plot and Normal Quantile plot of the residuals'</span></span>
<span id="cb49-410"><a href="#cb49-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-411"><a href="#cb49-411" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggfortify)</span>
<span id="cb49-412"><a href="#cb49-412" aria-hidden="true" tabindex="-1"></a>ggplot2<span class="sc">::</span><span class="fu">autoplot</span>(simplereg, <span class="at">which=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>)</span>
<span id="cb49-413"><a href="#cb49-413" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-414"><a href="#cb49-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-415"><a href="#cb49-415" aria-hidden="true" tabindex="-1"></a>We would like to plot the residuals against the fitted values. For horses' heart data, the residuals vs. fits plot (see @fig-f4-10) does not show a random scatter of points about zero, but rather a clear trend of U-shaped curvature together with a pattern of increasing variability about the trend. This indicates that a shrinking transformation of the $Y$ variable should be considered (as does the marginal distribution of $Y$ -- see the next section for details). This is not surprising given our initial examination showed that a curved fit was more appropriate, but in general systematic departures from a model fit are easier to see in a residual plot than in the original scatterplot of the data.</span>
<span id="cb49-416"><a href="#cb49-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-417"><a href="#cb49-417" aria-hidden="true" tabindex="-1"></a>The normal quantile plot enables us to assess whether the residuals are normally distributed -- there is some evidence of right skewness but not much so the normality assumption appears to be justified (a test for normality can always be carried out for confirmation).</span>
<span id="cb49-418"><a href="#cb49-418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-419"><a href="#cb49-419" aria-hidden="true" tabindex="-1"></a>The plot of residuals against the order of occurrence in the data set is used to judge whether the residuals are independent. In our case, the residual vs. observation order plot reveals no trend for the first 30 values but an increasing trend after that. An examination of the data set reveals that the last values in the data are also those with the largest *extdia* values which is where the maximum deviation from a straight line was already noted. Once again, an appropriate residual plot makes it easier to spot features of model fit (or lack of fit). **Durbin-Watson (DW) test** for the serial correlation in the residuals can be performed. The test statistic for the DW test is $$d = \frac{\sum _{i=2}^{n}\left(e_{i} -e_{i-1} \right)^{2} }{\sum _{t=1}^{n}e_{i} ^{2} } .$$ If $d$ is about 2, it suggests independence of the residuals. If residuals are positively correlated, then $d$ will be close to zero. If $d$ is large and close to 4, then negative correlation among the residuals is indicated. Critical values for the DW statistic are available in tables. The **car** package provides the $p$-value for the null hypothesis that there is no serial correlation in the residuals.</span>
<span id="cb49-420"><a href="#cb49-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-421"><a href="#cb49-421" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo=TRUE}</span></span>
<span id="cb49-422"><a href="#cb49-422" aria-hidden="true" tabindex="-1"></a>simplereg <span class="sc">|&gt;</span> </span>
<span id="cb49-423"><a href="#cb49-423" aria-hidden="true" tabindex="-1"></a>  <span class="fu">residuals</span>() <span class="sc">|&gt;</span> </span>
<span id="cb49-424"><a href="#cb49-424" aria-hidden="true" tabindex="-1"></a>  car<span class="sc">::</span><span class="fu">durbinWatsonTest</span>()</span>
<span id="cb49-425"><a href="#cb49-425" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-426"><a href="#cb49-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-427"><a href="#cb49-427" aria-hidden="true" tabindex="-1"></a>The **residuals vs. fits plot** also helps to identify outliers -- there appears to be at least one possible outlier with a residual greater than 1.5. If the residuals appear to be normally distributed, however, we can automate outlier detection by calculating the standardised residuals. Note that residuals are standardised by subtracting the mean (which is zero) and dividing by the standard deviation. For the $i^{th}$ residual, the standard deviation (i.e. standard error) is given by</span>
<span id="cb49-428"><a href="#cb49-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-429"><a href="#cb49-429" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-430"><a href="#cb49-430" aria-hidden="true" tabindex="-1"></a>s_{e_{i} } =s_{e} \sqrt{1-\left(\frac{1}{n} +\frac{(x_{i} -\bar{x})^2}{S_{xx} } \right)}</span>
<span id="cb49-431"><a href="#cb49-431" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb49-432"><a href="#cb49-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-433"><a href="#cb49-433" aria-hidden="true" tabindex="-1"></a>Any value with a standardised residual whose magnitude is greater than 2 is a potential outlier as we only expect this to happen about 5% of the time: i.e. two observations (39 and 44) gave rise to standardised residuals greater than 2. For a sample of size 46 we would expect (5% of 46 =) 2 or 3 values to give standardised residuals greater than 2, so this is not unexpected. However if the standardised residual of any point is extremely large, we should check the original data to decide whether an error has been made. Alternatively, we may decide that this point does not fit the given model and hence remove that point from the data. Statisticians are very loathe to throw data points away as even the unusual points may contain information about the model and why it does or does not fit well. For the present data set, the standardised residuals are not particularly large and within the expected 5% so that we would not remove them from the data set.</span>
<span id="cb49-434"><a href="#cb49-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-435"><a href="#cb49-435" aria-hidden="true" tabindex="-1"></a>The residuals may be greatly influenced by outliers or unusual points because the slope estimate of the regression line is sensitive to these outliers. In order to overcome this difficulty, we may find the fitted values corresponding to each $x$ value using all the data except for that data point. In other words, the data point $\left(x_{i} ,y{}_{i} \right)$ can be omitted, and a line can be fitted. We then obtain the fitted value for the $i^{ th}$ data point say $\hat{y}_{i,-i}$ and the associated **deleted residual** (also known as **studentised residual**) $e_{i,-i} =y_{i} -\hat{y}_{i,-i}$. We can explore the deleted residuals instead of the ordinary residuals. These deleted residuals are also externally studentised (a process similar to standardisation) so that the residual error estimate is done without the $i^{th}$ data point (see @fig-rstudent).</span>
<span id="cb49-436"><a href="#cb49-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-439"><a href="#cb49-439" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-440"><a href="#cb49-440" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb49-441"><a href="#cb49-441" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-rstudent</span></span>
<span id="cb49-442"><a href="#cb49-442" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Index Plot of Deleted Residuals'</span></span>
<span id="cb49-443"><a href="#cb49-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-444"><a href="#cb49-444" aria-hidden="true" tabindex="-1"></a>del.resid <span class="ot">&lt;-</span> <span class="fu">rstudent</span>(simplereg)</span>
<span id="cb49-445"><a href="#cb49-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-446"><a href="#cb49-446" aria-hidden="true" tabindex="-1"></a><span class="fu">qplot</span>(<span class="fu">seq_along</span>(del.resid), del.resid) <span class="sc">+</span> </span>
<span id="cb49-447"><a href="#cb49-447" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"observation"</span>) <span class="sc">+</span> </span>
<span id="cb49-448"><a href="#cb49-448" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"studentised residual"</span>)</span>
<span id="cb49-449"><a href="#cb49-449" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-450"><a href="#cb49-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-451"><a href="#cb49-451" aria-hidden="true" tabindex="-1"></a>Some scenarios concerning residual plots are explained below:</span>
<span id="cb49-452"><a href="#cb49-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-453"><a href="#cb49-453" aria-hidden="true" tabindex="-1"></a>**(a)** **Transformations**</span>
<span id="cb49-454"><a href="#cb49-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-455"><a href="#cb49-455" aria-hidden="true" tabindex="-1"></a>In @fig-resipattern1, **residuals are plotted against fitted values but show a funnel pattern instead of falling approximately in a horizontal band.** @fig-resipattern1(a) indicates that a shrinking transformation of square root or logarithm may be appropriate; @fig-resipattern1(b) suggests a stretching transformation such as squaring the response variable.</span>
<span id="cb49-456"><a href="#cb49-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-459"><a href="#cb49-459" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-460"><a href="#cb49-460" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb49-461"><a href="#cb49-461" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-resipattern1</span></span>
<span id="cb49-462"><a href="#cb49-462" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Non-constant Residual Variation'</span></span>
<span id="cb49-463"><a href="#cb49-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-464"><a href="#cb49-464" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb49-465"><a href="#cb49-465" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">60</span>,<span class="dv">2</span>)</span>
<span id="cb49-466"><a href="#cb49-466" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb49-467"><a href="#cb49-467" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb49-468"><a href="#cb49-468" aria-hidden="true" tabindex="-1"></a>sigma2 <span class="ot">&lt;-</span> n<span class="sc">^</span><span class="fl">1.5</span></span>
<span id="cb49-469"><a href="#cb49-469" aria-hidden="true" tabindex="-1"></a>eps <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n,<span class="at">mean=</span><span class="dv">0</span>,<span class="at">sd=</span><span class="fu">sqrt</span>(sigma2))</span>
<span id="cb49-470"><a href="#cb49-470" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> a<span class="sc">+</span>b<span class="sc">*</span>n <span class="sc">+</span> eps</span>
<span id="cb49-471"><a href="#cb49-471" aria-hidden="true" tabindex="-1"></a>modl <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> n)</span>
<span id="cb49-472"><a href="#cb49-472" aria-hidden="true" tabindex="-1"></a>residuals <span class="ot">&lt;-</span> <span class="fu">residuals</span>(modl)</span>
<span id="cb49-473"><a href="#cb49-473" aria-hidden="true" tabindex="-1"></a>fits <span class="ot">&lt;-</span> <span class="fu">fitted.values</span>(modl)</span>
<span id="cb49-474"><a href="#cb49-474" aria-hidden="true" tabindex="-1"></a>dfm <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">fits =</span> fits, <span class="at">residuals =</span> residuals)</span>
<span id="cb49-475"><a href="#cb49-475" aria-hidden="true" tabindex="-1"></a>my.plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(dfm, <span class="fu">aes</span>(<span class="at">x =</span> fits, <span class="at">y =</span> residuals)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span>
<span id="cb49-476"><a href="#cb49-476" aria-hidden="true" tabindex="-1"></a>my.plot <span class="ot">&lt;-</span> my.plot <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">"(a) Increasing Residual Variation"</span>)</span>
<span id="cb49-477"><a href="#cb49-477" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> my.plot <span class="sc">+</span><span class="fu">theme</span>(</span>
<span id="cb49-478"><a href="#cb49-478" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.line =</span> <span class="fu">element_line</span>(),</span>
<span id="cb49-479"><a href="#cb49-479" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-480"><a href="#cb49-480" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.ticks.x =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-481"><a href="#cb49-481" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-482"><a href="#cb49-482" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.text.x =</span> <span class="fu">element_blank</span>()) </span>
<span id="cb49-483"><a href="#cb49-483" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> p1<span class="sc">+</span><span class="fu">labs</span>(<span class="at">caption=</span><span class="st">"SHRINK - Square root or Log"</span>)</span>
<span id="cb49-484"><a href="#cb49-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-485"><a href="#cb49-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-486"><a href="#cb49-486" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> a<span class="sc">+</span>b<span class="sc">*</span>n <span class="sc">+</span> eps</span>
<span id="cb49-487"><a href="#cb49-487" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="sc">-</span>y</span>
<span id="cb49-488"><a href="#cb49-488" aria-hidden="true" tabindex="-1"></a>modl <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> n)</span>
<span id="cb49-489"><a href="#cb49-489" aria-hidden="true" tabindex="-1"></a>residuals <span class="ot">&lt;-</span> <span class="fu">residuals</span>(modl)</span>
<span id="cb49-490"><a href="#cb49-490" aria-hidden="true" tabindex="-1"></a>fits <span class="ot">&lt;-</span> <span class="fu">fitted.values</span>(modl)</span>
<span id="cb49-491"><a href="#cb49-491" aria-hidden="true" tabindex="-1"></a>dfm <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">fits =</span> fits, <span class="at">residuals =</span> residuals)</span>
<span id="cb49-492"><a href="#cb49-492" aria-hidden="true" tabindex="-1"></a>my.plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(dfm, <span class="fu">aes</span>(<span class="at">x =</span> fits, <span class="at">y =</span> residuals)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span>
<span id="cb49-493"><a href="#cb49-493" aria-hidden="true" tabindex="-1"></a>my.plot <span class="ot">&lt;-</span> my.plot <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">"(b) Decreasing Residual Variation"</span>)</span>
<span id="cb49-494"><a href="#cb49-494" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> my.plot <span class="sc">+</span><span class="fu">theme</span>(</span>
<span id="cb49-495"><a href="#cb49-495" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.line =</span> <span class="fu">element_line</span>(),</span>
<span id="cb49-496"><a href="#cb49-496" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-497"><a href="#cb49-497" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.ticks.x =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-498"><a href="#cb49-498" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-499"><a href="#cb49-499" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.text.x =</span> <span class="fu">element_blank</span>() ) </span>
<span id="cb49-500"><a href="#cb49-500" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> p2<span class="sc">+</span><span class="fu">labs</span>(<span class="at">caption=</span><span class="st">"STRETCH - Square or exponentiate"</span>)</span>
<span id="cb49-501"><a href="#cb49-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-502"><a href="#cb49-502" aria-hidden="true" tabindex="-1"></a>gridExtra<span class="sc">::</span><span class="fu">grid.arrange</span>(p1,p2, <span class="at">ncol=</span><span class="dv">2</span>)</span>
<span id="cb49-503"><a href="#cb49-503" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-504"><a href="#cb49-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-505"><a href="#cb49-505" aria-hidden="true" tabindex="-1"></a>**(b) Addition of other variables**</span>
<span id="cb49-506"><a href="#cb49-506" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-507"><a href="#cb49-507" aria-hidden="true" tabindex="-1"></a>@fig-resipattern2(a) residuals are plotted against fitted values. This plot suggests the addition of a quadratic, $x_2$, term to the model. In @fig-resipattern2(b) the residuals are plotted against a potential explanatory variable, $X_i$, which is not yet included in the model. This plot indicates a linear relationship between the residuals and $X_i$ suggesting that $X_i$ should be added to the linear model.</span>
<span id="cb49-508"><a href="#cb49-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-509"><a href="#cb49-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-512"><a href="#cb49-512" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-513"><a href="#cb49-513" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb49-514"><a href="#cb49-514" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-resipattern2</span></span>
<span id="cb49-515"><a href="#cb49-515" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Need to add predictors'</span></span>
<span id="cb49-516"><a href="#cb49-516" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb49-517"><a href="#cb49-517" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">60</span>,<span class="dv">2</span>)</span>
<span id="cb49-518"><a href="#cb49-518" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb49-519"><a href="#cb49-519" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb49-520"><a href="#cb49-520" aria-hidden="true" tabindex="-1"></a>sigma2 <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb49-521"><a href="#cb49-521" aria-hidden="true" tabindex="-1"></a>eps <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n,<span class="at">mean=</span><span class="dv">0</span>,<span class="at">sd=</span><span class="fu">sqrt</span>(sigma2))</span>
<span id="cb49-522"><a href="#cb49-522" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> a<span class="sc">+</span>b<span class="sc">*</span>n<span class="sc">^</span><span class="fl">1.2</span> <span class="sc">+</span> eps</span>
<span id="cb49-523"><a href="#cb49-523" aria-hidden="true" tabindex="-1"></a>modl <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> n)</span>
<span id="cb49-524"><a href="#cb49-524" aria-hidden="true" tabindex="-1"></a>residuals <span class="ot">&lt;-</span> <span class="fu">residuals</span>(modl)</span>
<span id="cb49-525"><a href="#cb49-525" aria-hidden="true" tabindex="-1"></a>fits <span class="ot">&lt;-</span> <span class="fu">fitted.values</span>(modl)</span>
<span id="cb49-526"><a href="#cb49-526" aria-hidden="true" tabindex="-1"></a>dfm <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">fits =</span> fits, <span class="at">residuals =</span> residuals)</span>
<span id="cb49-527"><a href="#cb49-527" aria-hidden="true" tabindex="-1"></a>my.plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(dfm, <span class="fu">aes</span>(<span class="at">x =</span> fits, <span class="at">y =</span> residuals)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span>
<span id="cb49-528"><a href="#cb49-528" aria-hidden="true" tabindex="-1"></a>my.plot <span class="ot">&lt;-</span> my.plot <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">"(a) Quadratic Residual pattern"</span>)</span>
<span id="cb49-529"><a href="#cb49-529" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> my.plot <span class="sc">+</span><span class="fu">theme</span>(</span>
<span id="cb49-530"><a href="#cb49-530" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.line =</span> <span class="fu">element_line</span>(),</span>
<span id="cb49-531"><a href="#cb49-531" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-532"><a href="#cb49-532" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.ticks.x =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-533"><a href="#cb49-533" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-534"><a href="#cb49-534" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.text.x =</span> <span class="fu">element_blank</span>() ) </span>
<span id="cb49-535"><a href="#cb49-535" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> p1<span class="sc">+</span><span class="fu">labs</span>(<span class="at">caption=</span><span class="st">"ADD - Polynomial terms"</span>)</span>
<span id="cb49-536"><a href="#cb49-536" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">324</span>)</span>
<span id="cb49-537"><a href="#cb49-537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-538"><a href="#cb49-538" aria-hidden="true" tabindex="-1"></a>n<span class="ot">=</span><span class="dv">50</span></span>
<span id="cb49-539"><a href="#cb49-539" aria-hidden="true" tabindex="-1"></a><span class="co"># library(MASS)</span></span>
<span id="cb49-540"><a href="#cb49-540" aria-hidden="true" tabindex="-1"></a><span class="do">## means of individual distributions</span></span>
<span id="cb49-541"><a href="#cb49-541" aria-hidden="true" tabindex="-1"></a>mu1 <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb49-542"><a href="#cb49-542" aria-hidden="true" tabindex="-1"></a>mu2 <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb49-543"><a href="#cb49-543" aria-hidden="true" tabindex="-1"></a><span class="do">## variance</span></span>
<span id="cb49-544"><a href="#cb49-544" aria-hidden="true" tabindex="-1"></a>sigma1 <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb49-545"><a href="#cb49-545" aria-hidden="true" tabindex="-1"></a><span class="do">## Correlation</span></span>
<span id="cb49-546"><a href="#cb49-546" aria-hidden="true" tabindex="-1"></a>YX1 <span class="ot">&lt;-</span> <span class="fl">0.9</span></span>
<span id="cb49-547"><a href="#cb49-547" aria-hidden="true" tabindex="-1"></a>Sigma <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(sigma1, YX1,YX1, sigma1),<span class="at">ncol =</span> <span class="dv">2</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb49-548"><a href="#cb49-548" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> MASS<span class="sc">::</span><span class="fu">mvrnorm</span>(n, <span class="at">mu =</span> <span class="fu">c</span>(mu1, mu2), <span class="at">Sigma =</span> Sigma, <span class="at">empirical =</span> <span class="cn">TRUE</span>)</span>
<span id="cb49-549"><a href="#cb49-549" aria-hidden="true" tabindex="-1"></a>residuals <span class="ot">&lt;-</span> dat[,<span class="dv">1</span>]</span>
<span id="cb49-550"><a href="#cb49-550" aria-hidden="true" tabindex="-1"></a>fits <span class="ot">&lt;-</span> dat[,<span class="dv">2</span>]</span>
<span id="cb49-551"><a href="#cb49-551" aria-hidden="true" tabindex="-1"></a>dfm <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">fits =</span> fits, <span class="at">residuals =</span> residuals)</span>
<span id="cb49-552"><a href="#cb49-552" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb49-553"><a href="#cb49-553" aria-hidden="true" tabindex="-1"></a>my.plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(dfm, <span class="fu">aes</span>(<span class="at">x =</span> fits, <span class="at">y =</span> residuals)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span>
<span id="cb49-554"><a href="#cb49-554" aria-hidden="true" tabindex="-1"></a>my.plot <span class="ot">&lt;-</span> my.plot <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">"(b) Linear Residual pattern"</span>)<span class="sc">+</span><span class="fu">xlab</span>(<span class="st">"X variable NOT in the model"</span>)</span>
<span id="cb49-555"><a href="#cb49-555" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> my.plot <span class="sc">+</span><span class="fu">theme</span>(</span>
<span id="cb49-556"><a href="#cb49-556" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.line =</span> <span class="fu">element_line</span>(),</span>
<span id="cb49-557"><a href="#cb49-557" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-558"><a href="#cb49-558" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.ticks.x =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-559"><a href="#cb49-559" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-560"><a href="#cb49-560" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.text.x =</span> <span class="fu">element_blank</span>() ) </span>
<span id="cb49-561"><a href="#cb49-561" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> p2<span class="sc">+</span><span class="fu">labs</span>(<span class="at">caption=</span><span class="st">"Include the new predictor"</span>)</span>
<span id="cb49-562"><a href="#cb49-562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-563"><a href="#cb49-563" aria-hidden="true" tabindex="-1"></a>gridExtra<span class="sc">::</span><span class="fu">grid.arrange</span>(p1,p2, <span class="at">ncol=</span><span class="dv">2</span>)</span>
<span id="cb49-564"><a href="#cb49-564" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-565"><a href="#cb49-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-566"><a href="#cb49-566" aria-hidden="true" tabindex="-1"></a>**(c)** **Subgroups**</span>
<span id="cb49-567"><a href="#cb49-567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-568"><a href="#cb49-568" aria-hidden="true" tabindex="-1"></a>Plots may show that a model seems to fit very well, as in @fig-resipattern3(a). But this is a spurious effect brought about by the presence of two or more subgroups in the data. Models fitted to each of the subgroups would not show up as being good fits to the data. In @fig-resipattern3(b), on the other hand, a poorly fitting model may be due to subgroups but if individual models were fitted, they would fit the data well.</span>
<span id="cb49-569"><a href="#cb49-569" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-572"><a href="#cb49-572" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-573"><a href="#cb49-573" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb49-574"><a href="#cb49-574" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-resipattern3</span></span>
<span id="cb49-575"><a href="#cb49-575" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Subgrouping patterns'</span></span>
<span id="cb49-576"><a href="#cb49-576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-577"><a href="#cb49-577" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb49-578"><a href="#cb49-578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-579"><a href="#cb49-579" aria-hidden="true" tabindex="-1"></a>residuals <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">120</span>, <span class="dv">0</span>, .<span class="dv">2</span>)</span>
<span id="cb49-580"><a href="#cb49-580" aria-hidden="true" tabindex="-1"></a>fits <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">120</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb49-581"><a href="#cb49-581" aria-hidden="true" tabindex="-1"></a>fits[<span class="dv">61</span><span class="sc">:</span><span class="dv">120</span>] <span class="ot">&lt;-</span> fits[<span class="dv">61</span><span class="sc">:</span><span class="dv">120</span>]<span class="sc">+</span><span class="dv">15</span></span>
<span id="cb49-582"><a href="#cb49-582" aria-hidden="true" tabindex="-1"></a>dfm <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">fits =</span> fits, <span class="at">residuals =</span> residuals)</span>
<span id="cb49-583"><a href="#cb49-583" aria-hidden="true" tabindex="-1"></a>my.plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(dfm, <span class="fu">aes</span>(<span class="at">x =</span> fits, <span class="at">y =</span> residuals)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span>
<span id="cb49-584"><a href="#cb49-584" aria-hidden="true" tabindex="-1"></a>my.plot <span class="ot">&lt;-</span> my.plot <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">"(a) Spurious Residual pattern"</span>)</span>
<span id="cb49-585"><a href="#cb49-585" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> my.plot <span class="sc">+</span><span class="fu">theme</span>(</span>
<span id="cb49-586"><a href="#cb49-586" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.line =</span> <span class="fu">element_line</span>(),</span>
<span id="cb49-587"><a href="#cb49-587" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-588"><a href="#cb49-588" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.ticks.x =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-589"><a href="#cb49-589" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-590"><a href="#cb49-590" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.text.x =</span> <span class="fu">element_blank</span>() ) </span>
<span id="cb49-591"><a href="#cb49-591" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> p1<span class="sc">+</span><span class="fu">labs</span>(<span class="at">caption=</span><span class="st">"Fit appears OK but</span><span class="sc">\n</span><span class="st">individual models fail"</span>)</span>
<span id="cb49-592"><a href="#cb49-592" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> p1<span class="sc">+</span><span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fu">mean</span>(residuals))</span>
<span id="cb49-593"><a href="#cb49-593" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">324</span>)</span>
<span id="cb49-594"><a href="#cb49-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-595"><a href="#cb49-595" aria-hidden="true" tabindex="-1"></a>n<span class="ot">=</span><span class="dv">40</span></span>
<span id="cb49-596"><a href="#cb49-596" aria-hidden="true" tabindex="-1"></a><span class="co"># library(MASS)</span></span>
<span id="cb49-597"><a href="#cb49-597" aria-hidden="true" tabindex="-1"></a><span class="do">## means of individual distributions</span></span>
<span id="cb49-598"><a href="#cb49-598" aria-hidden="true" tabindex="-1"></a>mu1 <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb49-599"><a href="#cb49-599" aria-hidden="true" tabindex="-1"></a>mu2 <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb49-600"><a href="#cb49-600" aria-hidden="true" tabindex="-1"></a><span class="do">## variance</span></span>
<span id="cb49-601"><a href="#cb49-601" aria-hidden="true" tabindex="-1"></a>sigma1 <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb49-602"><a href="#cb49-602" aria-hidden="true" tabindex="-1"></a><span class="do">## Correlation</span></span>
<span id="cb49-603"><a href="#cb49-603" aria-hidden="true" tabindex="-1"></a>YX1 <span class="ot">&lt;-</span> <span class="fl">0.9</span></span>
<span id="cb49-604"><a href="#cb49-604" aria-hidden="true" tabindex="-1"></a>Sigma <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(sigma1, YX1,YX1, sigma1),<span class="at">ncol =</span> <span class="dv">2</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb49-605"><a href="#cb49-605" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> MASS<span class="sc">::</span><span class="fu">mvrnorm</span>(n, <span class="at">mu =</span> <span class="fu">c</span>(mu1, mu2), <span class="at">Sigma =</span> Sigma, <span class="at">empirical =</span> <span class="cn">TRUE</span>)</span>
<span id="cb49-606"><a href="#cb49-606" aria-hidden="true" tabindex="-1"></a>residuals1 <span class="ot">&lt;-</span> dat[,<span class="dv">1</span>]</span>
<span id="cb49-607"><a href="#cb49-607" aria-hidden="true" tabindex="-1"></a>fits1 <span class="ot">&lt;-</span> dat[,<span class="dv">2</span>]</span>
<span id="cb49-608"><a href="#cb49-608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-609"><a href="#cb49-609" aria-hidden="true" tabindex="-1"></a>mu1 <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb49-610"><a href="#cb49-610" aria-hidden="true" tabindex="-1"></a>mu2 <span class="ot">&lt;-</span> <span class="dv">7</span></span>
<span id="cb49-611"><a href="#cb49-611" aria-hidden="true" tabindex="-1"></a>Sigma <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(sigma1, YX1,YX1, sigma1),<span class="at">ncol =</span> <span class="dv">2</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb49-612"><a href="#cb49-612" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> MASS<span class="sc">::</span><span class="fu">mvrnorm</span>(n, <span class="at">mu =</span> <span class="fu">c</span>(mu1, mu2), <span class="at">Sigma =</span> Sigma, <span class="at">empirical =</span> <span class="cn">TRUE</span>)</span>
<span id="cb49-613"><a href="#cb49-613" aria-hidden="true" tabindex="-1"></a>residuals2 <span class="ot">&lt;-</span> dat[,<span class="dv">1</span>]</span>
<span id="cb49-614"><a href="#cb49-614" aria-hidden="true" tabindex="-1"></a>fits2 <span class="ot">&lt;-</span> dat[,<span class="dv">2</span>]<span class="sc">+</span><span class="dv">20</span></span>
<span id="cb49-615"><a href="#cb49-615" aria-hidden="true" tabindex="-1"></a>fits <span class="ot">&lt;-</span> <span class="fu">append</span>(fits1, fits2)</span>
<span id="cb49-616"><a href="#cb49-616" aria-hidden="true" tabindex="-1"></a>residuals  <span class="ot">&lt;-</span>  <span class="fu">append</span>(residuals1, residuals2)</span>
<span id="cb49-617"><a href="#cb49-617" aria-hidden="true" tabindex="-1"></a>dfm <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">fits =</span> fits, <span class="at">residuals =</span> residuals)</span>
<span id="cb49-618"><a href="#cb49-618" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb49-619"><a href="#cb49-619" aria-hidden="true" tabindex="-1"></a>my.plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(dfm, <span class="fu">aes</span>(<span class="at">x =</span> fits, <span class="at">y =</span> residuals)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span>
<span id="cb49-620"><a href="#cb49-620" aria-hidden="true" tabindex="-1"></a>my.plot <span class="ot">&lt;-</span> my.plot <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">"(b) Subgrouped residual pattern"</span>)</span>
<span id="cb49-621"><a href="#cb49-621" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> my.plot <span class="sc">+</span><span class="fu">theme</span>(</span>
<span id="cb49-622"><a href="#cb49-622" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.line =</span> <span class="fu">element_line</span>(),</span>
<span id="cb49-623"><a href="#cb49-623" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-624"><a href="#cb49-624" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.ticks.x =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-625"><a href="#cb49-625" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-626"><a href="#cb49-626" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.text.x =</span> <span class="fu">element_blank</span>() ) </span>
<span id="cb49-627"><a href="#cb49-627" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> p2<span class="sc">+</span><span class="fu">labs</span>(<span class="at">caption=</span><span class="st">"Fit appears poor but</span><span class="sc">\n</span><span class="st">individual models will fare well"</span>)</span>
<span id="cb49-628"><a href="#cb49-628" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> p2<span class="sc">+</span><span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fu">mean</span>(residuals))</span>
<span id="cb49-629"><a href="#cb49-629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-630"><a href="#cb49-630" aria-hidden="true" tabindex="-1"></a>gridExtra<span class="sc">::</span><span class="fu">grid.arrange</span>(p1,p2, <span class="at">ncol=</span><span class="dv">2</span>)</span>
<span id="cb49-631"><a href="#cb49-631" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-632"><a href="#cb49-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-633"><a href="#cb49-633" aria-hidden="true" tabindex="-1"></a>**(d)** **Outliers**</span>
<span id="cb49-634"><a href="#cb49-634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-635"><a href="#cb49-635" aria-hidden="true" tabindex="-1"></a>Plots of residuals against the fitted $y$ values or the explanatory variables may indicate peculiar values. It may be that a few data points are very unusual; perhaps unusual conditions prevailed at those times when those data points were recorded; errors may have been made by those taking these measurements; errors may have occurred in coding or entering data into the computer (see @fig-resipattern4(a)).</span>
<span id="cb49-636"><a href="#cb49-636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-637"><a href="#cb49-637" aria-hidden="true" tabindex="-1"></a>In @fig-resipattern4(b), the outliers may indicate that the model does not fit very well at the larger observed values of $y$.</span>
<span id="cb49-638"><a href="#cb49-638" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-641"><a href="#cb49-641" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-642"><a href="#cb49-642" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb49-643"><a href="#cb49-643" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-resipattern4</span></span>
<span id="cb49-644"><a href="#cb49-644" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Non-constant Residual Variation'</span></span>
<span id="cb49-645"><a href="#cb49-645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-646"><a href="#cb49-646" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">453</span>)</span>
<span id="cb49-647"><a href="#cb49-647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-648"><a href="#cb49-648" aria-hidden="true" tabindex="-1"></a>residuals <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">100</span>)</span>
<span id="cb49-649"><a href="#cb49-649" aria-hidden="true" tabindex="-1"></a>fits <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span></span>
<span id="cb49-650"><a href="#cb49-650" aria-hidden="true" tabindex="-1"></a>dfm <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">fits =</span> fits, <span class="at">residuals =</span> residuals)</span>
<span id="cb49-651"><a href="#cb49-651" aria-hidden="true" tabindex="-1"></a>my.plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(dfm, <span class="fu">aes</span>(<span class="at">x =</span> fits, <span class="at">y =</span> residuals)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span>
<span id="cb49-652"><a href="#cb49-652" aria-hidden="true" tabindex="-1"></a>my.plot <span class="ot">&lt;-</span> my.plot <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">"(a) Unrelated Outliers"</span>)</span>
<span id="cb49-653"><a href="#cb49-653" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> my.plot <span class="sc">+</span><span class="fu">theme</span>(</span>
<span id="cb49-654"><a href="#cb49-654" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.line =</span> <span class="fu">element_line</span>(),</span>
<span id="cb49-655"><a href="#cb49-655" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-656"><a href="#cb49-656" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.ticks.x =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-657"><a href="#cb49-657" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-658"><a href="#cb49-658" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.text.x =</span> <span class="fu">element_blank</span>()) </span>
<span id="cb49-659"><a href="#cb49-659" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> p1<span class="sc">+</span><span class="fu">labs</span>(<span class="at">caption=</span><span class="st">"Anamalous points"</span>)</span>
<span id="cb49-660"><a href="#cb49-660" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> p1<span class="sc">+</span><span class="fu">geom_hline</span>(<span class="at">yintercept =</span><span class="fu">mean</span>(residuals))</span>
<span id="cb49-661"><a href="#cb49-661" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> p1<span class="sc">+</span><span class="fu">geom_hline</span>(<span class="at">yintercept =</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">2.5</span>,<span class="fl">2.5</span>))</span>
<span id="cb49-662"><a href="#cb49-662" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-663"><a href="#cb49-663" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">672133</span>)</span>
<span id="cb49-664"><a href="#cb49-664" aria-hidden="true" tabindex="-1"></a>residuals <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">100</span>)</span>
<span id="cb49-665"><a href="#cb49-665" aria-hidden="true" tabindex="-1"></a>residuals[<span class="dv">96</span><span class="sc">:</span><span class="dv">100</span>] <span class="ot">&lt;-</span> <span class="fu">abs</span>(residuals[<span class="dv">96</span><span class="sc">:</span><span class="dv">100</span>])<span class="sc">+</span><span class="dv">3</span></span>
<span id="cb49-666"><a href="#cb49-666" aria-hidden="true" tabindex="-1"></a>fits <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span></span>
<span id="cb49-667"><a href="#cb49-667" aria-hidden="true" tabindex="-1"></a>dfm <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">fits =</span> fits, <span class="at">residuals =</span> residuals)</span>
<span id="cb49-668"><a href="#cb49-668" aria-hidden="true" tabindex="-1"></a>my.plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(dfm, <span class="fu">aes</span>(<span class="at">x =</span> fits, <span class="at">y =</span> residuals)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span>
<span id="cb49-669"><a href="#cb49-669" aria-hidden="true" tabindex="-1"></a>my.plot <span class="ot">&lt;-</span> my.plot <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">"(b) Related Outliers"</span>)</span>
<span id="cb49-670"><a href="#cb49-670" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> my.plot <span class="sc">+</span><span class="fu">theme</span>(</span>
<span id="cb49-671"><a href="#cb49-671" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.line =</span> <span class="fu">element_line</span>(),</span>
<span id="cb49-672"><a href="#cb49-672" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-673"><a href="#cb49-673" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.ticks.x =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-674"><a href="#cb49-674" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-675"><a href="#cb49-675" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.text.x =</span> <span class="fu">element_blank</span>() ) </span>
<span id="cb49-676"><a href="#cb49-676" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> p2<span class="sc">+</span><span class="fu">labs</span>(<span class="at">caption=</span><span class="st">"Model seems to fail for large Y"</span>)</span>
<span id="cb49-677"><a href="#cb49-677" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> p2<span class="sc">+</span><span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fu">mean</span>(residuals))</span>
<span id="cb49-678"><a href="#cb49-678" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> p2<span class="sc">+</span><span class="fu">geom_hline</span>(<span class="at">yintercept =</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">2.5</span>,<span class="fl">2.5</span>))</span>
<span id="cb49-679"><a href="#cb49-679" aria-hidden="true" tabindex="-1"></a>gridExtra<span class="sc">::</span><span class="fu">grid.arrange</span>(p1,p2, <span class="at">ncol=</span><span class="dv">2</span>)</span>
<span id="cb49-680"><a href="#cb49-680" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-681"><a href="#cb49-681" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-682"><a href="#cb49-682" aria-hidden="true" tabindex="-1"></a>**(e)** **Autocorrelation**</span>
<span id="cb49-683"><a href="#cb49-683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-684"><a href="#cb49-684" aria-hidden="true" tabindex="-1"></a>@fig-resipattern5 shows patterns in plots of residuals against time. In (a), a positive residual tends to be followed by another positive residual. If the residuals are correlated with themselves 'lagged' by one time period, this correlation is called autocorrelation and the coefficient would be positive for (a). In (b), the autocorrelation would be negative; this could occur with the price of potatoes as a high price one year may encourage gardeners to plant even more the next year leading to a glut and low prices, followed by a hesitancy the next year leading to scarcity and higher prices, and so on.</span>
<span id="cb49-685"><a href="#cb49-685" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-688"><a href="#cb49-688" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-689"><a href="#cb49-689" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb49-690"><a href="#cb49-690" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-resipattern5</span></span>
<span id="cb49-691"><a href="#cb49-691" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Neighbouring residuals depend on each other'</span></span>
<span id="cb49-692"><a href="#cb49-692" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-693"><a href="#cb49-693" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">453</span>)</span>
<span id="cb49-694"><a href="#cb49-694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-695"><a href="#cb49-695" aria-hidden="true" tabindex="-1"></a>e<span class="ot">&lt;-</span><span class="fu">rep</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>), <span class="at">each=</span><span class="dv">5</span>, <span class="at">length.out=</span><span class="dv">30</span>)</span>
<span id="cb49-696"><a href="#cb49-696" aria-hidden="true" tabindex="-1"></a>residuals <span class="ot">&lt;-</span> <span class="fu">abs</span>(<span class="fu">rnorm</span>(<span class="dv">30</span>, <span class="dv">20</span>,<span class="dv">10</span>))<span class="sc">*</span>e</span>
<span id="cb49-697"><a href="#cb49-697" aria-hidden="true" tabindex="-1"></a>fits <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">30</span></span>
<span id="cb49-698"><a href="#cb49-698" aria-hidden="true" tabindex="-1"></a>dfm <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">fits =</span> fits, <span class="at">residuals =</span> residuals)</span>
<span id="cb49-699"><a href="#cb49-699" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(dfm, <span class="fu">aes</span>(<span class="at">x =</span> fits, <span class="at">y =</span> residuals)) <span class="sc">+</span> <span class="fu">geom_path</span>()<span class="sc">+</span><span class="fu">geom_point</span>()</span>
<span id="cb49-700"><a href="#cb49-700" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> p1 <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">"(b) Positive Autocorrelation"</span>)</span>
<span id="cb49-701"><a href="#cb49-701" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> p1 <span class="sc">+</span> <span class="fu">geom_hline</span>(<span class="at">yintercept=</span><span class="fu">mean</span>(residuals))</span>
<span id="cb49-702"><a href="#cb49-702" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> p1 <span class="sc">+</span><span class="fu">theme</span>(</span>
<span id="cb49-703"><a href="#cb49-703" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.line =</span> <span class="fu">element_line</span>(),</span>
<span id="cb49-704"><a href="#cb49-704" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-705"><a href="#cb49-705" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.ticks.x =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-706"><a href="#cb49-706" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-707"><a href="#cb49-707" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.text.x =</span> <span class="fu">element_blank</span>()) </span>
<span id="cb49-708"><a href="#cb49-708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-709"><a href="#cb49-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-710"><a href="#cb49-710" aria-hidden="true" tabindex="-1"></a>e<span class="ot">&lt;-</span><span class="fu">rep</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>), <span class="at">each=</span><span class="dv">1</span>, <span class="at">length.out=</span><span class="dv">30</span>)</span>
<span id="cb49-711"><a href="#cb49-711" aria-hidden="true" tabindex="-1"></a>residuals <span class="ot">&lt;-</span> <span class="fu">abs</span>(<span class="fu">rnorm</span>(<span class="dv">30</span>, <span class="dv">20</span>,<span class="dv">10</span>))<span class="sc">*</span>e</span>
<span id="cb49-712"><a href="#cb49-712" aria-hidden="true" tabindex="-1"></a>fits <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">30</span></span>
<span id="cb49-713"><a href="#cb49-713" aria-hidden="true" tabindex="-1"></a>dfm <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">fits =</span> fits, <span class="at">residuals =</span> residuals)</span>
<span id="cb49-714"><a href="#cb49-714" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(dfm, <span class="fu">aes</span>(<span class="at">x =</span> fits, <span class="at">y =</span> residuals)) <span class="sc">+</span> <span class="fu">geom_path</span>()<span class="sc">+</span><span class="fu">geom_point</span>()</span>
<span id="cb49-715"><a href="#cb49-715" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> p2 <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">"(b) Negative Autocorrelation"</span>)</span>
<span id="cb49-716"><a href="#cb49-716" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> p2 <span class="sc">+</span> <span class="fu">geom_hline</span>(<span class="at">yintercept=</span><span class="fu">mean</span>(residuals))</span>
<span id="cb49-717"><a href="#cb49-717" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> p2 <span class="sc">+</span><span class="fu">theme</span>(</span>
<span id="cb49-718"><a href="#cb49-718" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.line =</span> <span class="fu">element_line</span>(),</span>
<span id="cb49-719"><a href="#cb49-719" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-720"><a href="#cb49-720" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.ticks.x =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-721"><a href="#cb49-721" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb49-722"><a href="#cb49-722" aria-hidden="true" tabindex="-1"></a>        <span class="at">axis.text.x =</span> <span class="fu">element_blank</span>() ) </span>
<span id="cb49-723"><a href="#cb49-723" aria-hidden="true" tabindex="-1"></a>gridExtra<span class="sc">::</span><span class="fu">grid.arrange</span>(p1,p2, <span class="at">ncol=</span><span class="dv">2</span>)</span>
<span id="cb49-724"><a href="#cb49-724" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-725"><a href="#cb49-725" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-726"><a href="#cb49-726" aria-hidden="true" tabindex="-1"></a>The above figures show the residuals on the $y$-axis. We may also plot the standardised residuals, deleted residuals etc. Some prefer to plot the square root of the absolute standardised residuals against the fitted values (instead of plotting ordinary residuals against the fitted values). This plot, known as the **Scale-Location plot**, helps us to judge whether the residual variation is constant, and also to identify the observations having large residuals (i.e. $\sqrt{\left|{\text {standardised residual}}\right|} &gt;\sqrt{2} =1.41$; see @fig-scaloc.</span>
<span id="cb49-727"><a href="#cb49-727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-730"><a href="#cb49-730" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-731"><a href="#cb49-731" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb49-732"><a href="#cb49-732" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-scaloc</span></span>
<span id="cb49-733"><a href="#cb49-733" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Scale-Location plot'</span></span>
<span id="cb49-734"><a href="#cb49-734" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-735"><a href="#cb49-735" aria-hidden="true" tabindex="-1"></a>full.model <span class="ot">&lt;-</span> <span class="fu">lm</span>(WEIGHT<span class="sc">~</span> ., <span class="at">data=</span>horsehearts)</span>
<span id="cb49-736"><a href="#cb49-736" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-737"><a href="#cb49-737" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(full.model, <span class="at">which=</span><span class="dv">3</span>, <span class="at">ncol=</span><span class="dv">1</span>)</span>
<span id="cb49-738"><a href="#cb49-738" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-739"><a href="#cb49-739" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-740"><a href="#cb49-740" aria-hidden="true" tabindex="-1"></a>Depending on the <span class="in">`R`</span> package used, a variety of plots for exploring the residuals can be obtained.</span>
<span id="cb49-741"><a href="#cb49-741" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-742"><a href="#cb49-742" aria-hidden="true" tabindex="-1"></a>In summary, residuals give important information about the fit of a model and how it might be improved:</span>
<span id="cb49-743"><a href="#cb49-743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-744"><a href="#cb49-744" aria-hidden="true" tabindex="-1"></a><span class="ss">1.  </span>Large variability of residuals in relation to the total variability in $Y$ indicates a feeble relationship between $Y$ and $X$. We can try transforming $Y$ or adding other variables to the fitted model.</span>
<span id="cb49-745"><a href="#cb49-745" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-746"><a href="#cb49-746" aria-hidden="true" tabindex="-1"></a><span class="ss">2.  </span>The residuals should fall in a horizontal band when plotted against the fit, that is, the variance of the residuals should be constant over different values of the fit. If not, try a transformation.</span>
<span id="cb49-747"><a href="#cb49-747" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-748"><a href="#cb49-748" aria-hidden="true" tabindex="-1"></a><span class="ss">3.  </span>Normality of the residuals confirms that the normality assumption required for the $t$ and $F$ tests is satisfied. Otherwise a transformation of the response variable may be required.</span>
<span id="cb49-749"><a href="#cb49-749" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-750"><a href="#cb49-750" aria-hidden="true" tabindex="-1"></a><span class="ss">4.  </span>Plotting the residuals against the order of the data allows us to check whether successive values are independent of one another, and hence may reveal further relationships in the data.</span>
<span id="cb49-751"><a href="#cb49-751" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-752"><a href="#cb49-752" aria-hidden="true" tabindex="-1"></a><span class="fu">## Improving Simple Regression</span></span>
<span id="cb49-753"><a href="#cb49-753" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-754"><a href="#cb49-754" aria-hidden="true" tabindex="-1"></a>If the fitted simple regression is rather poor, what can be done?</span>
<span id="cb49-755"><a href="#cb49-755" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-756"><a href="#cb49-756" aria-hidden="true" tabindex="-1"></a>**(a) Use a different predictor variable**</span>
<span id="cb49-757"><a href="#cb49-757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-758"><a href="#cb49-758" aria-hidden="true" tabindex="-1"></a>For this Chapter example, we could choose another one of the ultra-sound measurements to predict the weight of the horses heart.</span>
<span id="cb49-759"><a href="#cb49-759" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-760"><a href="#cb49-760" aria-hidden="true" tabindex="-1"></a>**(b) Transform the** $Y$ variable</span>
<span id="cb49-761"><a href="#cb49-761" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-762"><a href="#cb49-762" aria-hidden="true" tabindex="-1"></a>We could choose a transformation which makes physical sense. For example, we could argue that the weight of the heart should be closely related to the volume of the heart and volume is related to the product of three lengths or any one length cubed. Rather than cubing the $X$ variable we usually transform the response variable $Y$. Alternatively we might choose a transformation based on statistical grounds. Our previous discussion suggests that a shrinking transformation should be used, so suppose we take the logarithm of $Y$. The distribution of weights is compared before and after transformation in @fig-weighttrans.</span>
<span id="cb49-763"><a href="#cb49-763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-764"><a href="#cb49-764" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-767"><a href="#cb49-767" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-768"><a href="#cb49-768" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb49-769"><a href="#cb49-769" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-weighttrans</span></span>
<span id="cb49-770"><a href="#cb49-770" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Comparison of raw and log-transformed Weight data'</span></span>
<span id="cb49-771"><a href="#cb49-771" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 5</span></span>
<span id="cb49-772"><a href="#cb49-772" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb49-773"><a href="#cb49-773" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-774"><a href="#cb49-774" aria-hidden="true" tabindex="-1"></a>plot1 <span class="ot">&lt;-</span> <span class="fu">qplot</span>(<span class="fu">factor</span>(<span class="st">"raw data"</span>), WEIGHT, <span class="at">data=</span>horsehearts, <span class="at">geom =</span> <span class="st">"boxplot"</span>)</span>
<span id="cb49-775"><a href="#cb49-775" aria-hidden="true" tabindex="-1"></a>plot1 <span class="ot">&lt;-</span> plot1<span class="sc">+</span><span class="fu">xlab</span>(<span class="cn">NULL</span>)</span>
<span id="cb49-776"><a href="#cb49-776" aria-hidden="true" tabindex="-1"></a>plot2 <span class="ot">&lt;-</span> <span class="fu">qplot</span>(<span class="fu">factor</span>(<span class="st">"log transformed data"</span>), <span class="fu">log</span>(WEIGHT), <span class="at">data=</span>horsehearts, <span class="at">geom =</span> <span class="st">"boxplot"</span>)</span>
<span id="cb49-777"><a href="#cb49-777" aria-hidden="true" tabindex="-1"></a>plot2 <span class="ot">&lt;-</span> plot2<span class="sc">+</span><span class="fu">xlab</span>(<span class="cn">NULL</span>)</span>
<span id="cb49-778"><a href="#cb49-778" aria-hidden="true" tabindex="-1"></a>plot3 <span class="ot">&lt;-</span> <span class="fu">qplot</span>(<span class="fu">factor</span>(<span class="st">"Negative reciprocal cubic-root </span><span class="sc">\n</span><span class="st"> transformed data"</span>), <span class="sc">-</span>WEIGHT<span class="sc">^</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>), <span class="at">data=</span>horsehearts, <span class="at">geom =</span> <span class="st">"boxplot"</span>)</span>
<span id="cb49-779"><a href="#cb49-779" aria-hidden="true" tabindex="-1"></a>plot3 <span class="ot">&lt;-</span> plot3<span class="sc">+</span><span class="fu">xlab</span>(<span class="cn">NULL</span>)</span>
<span id="cb49-780"><a href="#cb49-780" aria-hidden="true" tabindex="-1"></a>gridExtra<span class="sc">::</span><span class="fu">grid.arrange</span>(plot1, plot2, plot3, <span class="at">ncol=</span><span class="dv">3</span>)</span>
<span id="cb49-781"><a href="#cb49-781" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-782"><a href="#cb49-782" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-783"><a href="#cb49-783" aria-hidden="true" tabindex="-1"></a>We can see the effect of logarithmic transformation from the boxplot in @fig-weighttrans. Clearly the distribution has become more symmetric. In order to make the distribution even more symmetric we might also try a **power** transformation as shown in @fig-weighttrans. Here we have applied the negative reciprocal cubic root transformation $-\frac {1}{Y^{1/3}}$ which makes more physical sense. This yields a slightly symmetric distribution. A minimal summary output of the regression of $WEIGHT^{1/3}$ on *EXTDIA* is shown in @tbl-transweightreg:</span>
<span id="cb49-784"><a href="#cb49-784" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-787"><a href="#cb49-787" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-788"><a href="#cb49-788" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb49-789"><a href="#cb49-789" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tbl-transweightreg</span></span>
<span id="cb49-790"><a href="#cb49-790" aria-hidden="true" tabindex="-1"></a><span class="co">#| tbl-cap: 'Cubic Root Transformed Response Model Summary'</span></span>
<span id="cb49-791"><a href="#cb49-791" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(WEIGHT<span class="sc">^</span>(<span class="dv">1</span><span class="sc">/</span><span class="dv">3</span>)<span class="sc">~</span>EXTDIA, <span class="at">data=</span>horsehearts) <span class="sc">|&gt;</span> </span>
<span id="cb49-792"><a href="#cb49-792" aria-hidden="true" tabindex="-1"></a>  <span class="fu">glance</span>() <span class="sc">|&gt;</span> </span>
<span id="cb49-793"><a href="#cb49-793" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(r.squared, sigma, statistic, p.value, AIC, BIC)<span class="sc">|&gt;</span> </span>
<span id="cb49-794"><a href="#cb49-794" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate_if</span>(is.numeric, round,<span class="dv">3</span>) <span class="sc">|&gt;</span> </span>
<span id="cb49-795"><a href="#cb49-795" aria-hidden="true" tabindex="-1"></a>  <span class="fu">t</span>() <span class="sc">|&gt;</span> </span>
<span id="cb49-796"><a href="#cb49-796" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable</span>() <span class="sc">|&gt;</span> </span>
<span id="cb49-797"><a href="#cb49-797" aria-hidden="true" tabindex="-1"></a>  <span class="fu">kable_classic</span>(<span class="at">full_width =</span> F) </span>
<span id="cb49-798"><a href="#cb49-798" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-799"><a href="#cb49-799" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-800"><a href="#cb49-800" aria-hidden="true" tabindex="-1"></a>This output shows an improvement in the $R^{2}$ value. However, for technical reasons one cannot meaningfully compare $R^{2}$ values for the raw and transformed data. The estimated standard deviation of the residuals is also meaningless when comparing raw and transformed data (recall that this quantity is the square root of the residual MeanSq). There is really only one way to confirm whether a transformed model is better than the original model and that is by analysing the residuals. Only if the residuals are better behaved, in that they comply more closely with the regression assumptions, can one claim that the transformed model is preferable. This is a very important point.</span>
<span id="cb49-801"><a href="#cb49-801" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-802"><a href="#cb49-802" aria-hidden="true" tabindex="-1"></a>In the next Chapter, we will cover more on <span class="in">`AIC`</span> and <span class="in">`BIC`</span> values shown in@tbl-transweightreg but the simple thumb rule is to opt a model with the smallest AIC or BIC while we go for a model with the largest log-likelihood.</span>
<span id="cb49-803"><a href="#cb49-803" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-804"><a href="#cb49-804" aria-hidden="true" tabindex="-1"></a>These values also support the model based on the negative reciprocal cubic root transformed data.</span>
<span id="cb49-805"><a href="#cb49-805" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-806"><a href="#cb49-806" aria-hidden="true" tabindex="-1"></a>**(c) Add other explanatory variables to the model**\</span>
<span id="cb49-807"><a href="#cb49-807" aria-hidden="true" tabindex="-1"></a>This will cause the $R^{2}$ to increase (although we may decide that the increase is not worth the effect of making the model more complicated). We will study multiple regression models having two or more predictors in the next chapter.</span>
<span id="cb49-808"><a href="#cb49-808" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-809"><a href="#cb49-809" aria-hidden="true" tabindex="-1"></a><span class="fu"># Robust Model Fitting</span></span>
<span id="cb49-810"><a href="#cb49-810" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-811"><a href="#cb49-811" aria-hidden="true" tabindex="-1"></a>The regression fit by the least squares method can be affected by outliers. If data are explored using scatterplots, then we often obtain which of the observations are suspicious or appear to be rogue.</span>
<span id="cb49-812"><a href="#cb49-812" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-813"><a href="#cb49-813" aria-hidden="true" tabindex="-1"></a>The residual standard error at a given $x$ value is given by $$s_{e_{i} } =s_{e} \sqrt{1-\left(\frac{1}{n} +\frac{x_{i} -\bar{x}}{S_{xx} } \right)}.$$ From the above expression, we see that if an $x$ value is further away from the mean $\bar{x}$, then the residual variance will be small. If an $x$ value is closer to the mean $\bar{x}$, then the residual variance will be greater. This means that $x$-values far from $\bar{x}$ pull the regression line closer to the corresponding $y$-values or alternatively such a distant $x$ value has a higher ***leverage***. This leverage is often measured by the hi values namely $$h_{ii} =\frac{1}{n} +\frac{\left(x_{i} -\bar{x}\right)^{2} }{S_{xx} }.$$ The above leverage measure $h_{ii}$ always lies between zero and one, and does not depend on the actual $y$ values. The higher the leverage of an $x$-value, the greater its *potential influence* on the regression coefficients. If a $h_{ii}$ value is greater than $\frac{3p}{n}$ (where $p$ is the number of model terms (including the constant) and $n$ is the number of observations), then the associated data point is generally regarded as having high leverage. When the number of predictors is small, say 1 to 4, some use a conservative cut-off value $\frac{4}{n}$ instead of $\frac{3p}{n}$.</span>
<span id="cb49-814"><a href="#cb49-814" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-815"><a href="#cb49-815" aria-hidden="true" tabindex="-1"></a>One of the measures of influence on the regression results is known as the **Cook's distance** which is related to difference between the regression coefficients with and without the $i^{th}$ data point. The formula for the Cook's distance for the $i^{th}$ data point is given by</span>
<span id="cb49-816"><a href="#cb49-816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-817"><a href="#cb49-817" aria-hidden="true" tabindex="-1"></a>$$D_{i} =\left(\frac{h_{ii} }{1-h_{ii} } \right)\left(\frac{r_{i}^{2} }{p} \right).$$ where $r_{i}$ is the standardised residual given by $$r_{i} =\frac{e_{i} }{s_{e} \sqrt{1-\left(\frac{1}{n} +\frac{x_{i} -\bar{x}}{S_{xx} } \right)} }.$$</span>
<span id="cb49-818"><a href="#cb49-818" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-819"><a href="#cb49-819" aria-hidden="true" tabindex="-1"></a>As a rule of thumb, points with $D_{i} &gt;0.7$ can be deemed as being influential (for $n&gt;15$). If $D_{i} &gt;1$, then the influence of this point is far greater and must be investigated further.</span>
<span id="cb49-820"><a href="#cb49-820" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-821"><a href="#cb49-821" aria-hidden="true" tabindex="-1"></a>We prefer to examine plots of $D_{i}$ (and $h_{ii}$) against the residuals, standardised residuals, explanatory variables, fitted values or time order etc for a visual identification of any observation with markedly higher influence than the other observations in the data. As an example, consider the data set **Rangitikei**. @fig-rangiHi shows that the 26th observation is clearly anomalous.</span>
<span id="cb49-822"><a href="#cb49-822" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-825"><a href="#cb49-825" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-826"><a href="#cb49-826" aria-hidden="true" tabindex="-1"></a><span class="fu">download.file</span>(</span>
<span id="cb49-827"><a href="#cb49-827" aria-hidden="true" tabindex="-1"></a>  <span class="at">url =</span> <span class="st">"http://www.massey.ac.nz/~anhsmith/data/rangitikei.RData"</span>,</span>
<span id="cb49-828"><a href="#cb49-828" aria-hidden="true" tabindex="-1"></a>  <span class="at">destfile =</span> <span class="st">"rangitikei.RData"</span>)</span>
<span id="cb49-829"><a href="#cb49-829" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-830"><a href="#cb49-830" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"rangitikei.RData"</span>)</span>
<span id="cb49-831"><a href="#cb49-831" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-832"><a href="#cb49-832" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-833"><a href="#cb49-833" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-836"><a href="#cb49-836" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-837"><a href="#cb49-837" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb49-838"><a href="#cb49-838" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-rangiHi</span></span>
<span id="cb49-839"><a href="#cb49-839" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Scatter plot of People vs Vehicle'</span></span>
<span id="cb49-840"><a href="#cb49-840" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(rangitikei, <span class="fu">aes</span>(<span class="at">x=</span>vehicle, <span class="at">y=</span>people)) <span class="sc">+</span> </span>
<span id="cb49-841"><a href="#cb49-841" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb49-842"><a href="#cb49-842" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">"lm"</span>) <span class="sc">+</span> </span>
<span id="cb49-843"><a href="#cb49-843" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Rangitikei Data"</span>) <span class="sc">+</span> </span>
<span id="cb49-844"><a href="#cb49-844" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">label =</span> <span class="st">"# 26"</span>, <span class="at">x =</span> <span class="dv">115</span>, <span class="at">y =</span> <span class="dv">475</span>, <span class="at">size =</span> <span class="dv">4</span>, <span class="at">colour =</span> <span class="st">"red"</span>)</span>
<span id="cb49-845"><a href="#cb49-845" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-846"><a href="#cb49-846" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-847"><a href="#cb49-847" aria-hidden="true" tabindex="-1"></a>@fig-rangiHiCook shows the standardised residuals vs. leverage plot of the linear regression of people ($Y$) on vehicles ($X$). This plot also shows the Cook's distance and warning limits at 0.5 and 1. Clearly the observation <span class="sc">\#</span>26 is a point of high leverage ($h_{ii}$ being 0.63) as well as influential ($D_{i}$ being 4.97).</span>
<span id="cb49-848"><a href="#cb49-848" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-851"><a href="#cb49-851" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-852"><a href="#cb49-852" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb49-853"><a href="#cb49-853" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-rangiHiCook</span></span>
<span id="cb49-854"><a href="#cb49-854" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Residual Diagnostic Plot: Cook's distance vs Leverage"</span></span>
<span id="cb49-855"><a href="#cb49-855" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-856"><a href="#cb49-856" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(<span class="fu">lm</span>(people<span class="sc">~</span>vehicle, <span class="at">data=</span>rangitikei), <span class="at">which=</span><span class="dv">6</span>, <span class="at">ncol=</span><span class="dv">1</span>)</span>
<span id="cb49-857"><a href="#cb49-857" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-858"><a href="#cb49-858" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-859"><a href="#cb49-859" aria-hidden="true" tabindex="-1"></a>The formulae for $h_{ii}$ and $D_{i}$ presented in this section are valid for simple regression only. It is general practice to examine the four plots (which are placed in a single layout) shown in @fig-fourinone) for residual analysis of a regression fit.</span>
<span id="cb49-860"><a href="#cb49-860" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-863"><a href="#cb49-863" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-864"><a href="#cb49-864" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb49-865"><a href="#cb49-865" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-fourinone</span></span>
<span id="cb49-866"><a href="#cb49-866" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Residual Diagnostic Plots'</span></span>
<span id="cb49-867"><a href="#cb49-867" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 8</span></span>
<span id="cb49-868"><a href="#cb49-868" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb49-869"><a href="#cb49-869" aria-hidden="true" tabindex="-1"></a>ggplot2<span class="sc">::</span><span class="fu">autoplot</span>(<span class="fu">lm</span>(people<span class="sc">~</span>vehicle, <span class="at">data=</span>rangitikei))</span>
<span id="cb49-870"><a href="#cb49-870" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-871"><a href="#cb49-871" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-872"><a href="#cb49-872" aria-hidden="true" tabindex="-1"></a>The fourth plot will show the Cook's distance contours when the base <span class="in">`plot()`</span> function is used instead of <span class="in">`autoplot()`</span> function.</span>
<span id="cb49-873"><a href="#cb49-873" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-874"><a href="#cb49-874" aria-hidden="true" tabindex="-1"></a>The weighted least squares regression approach places differing weights for each pair of points and minimises the sum of weighted squared residuals. The <span class="in">`R`</span> function <span class="in">`lm()`</span> allows for this. A popular approach is to employ the reciprocal of error variance of the response $Y_i$ at a given $X_i$. An example of weighted least squares line is shown in @fig-ols.</span>
<span id="cb49-875"><a href="#cb49-875" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-878"><a href="#cb49-878" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-879"><a href="#cb49-879" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb49-880"><a href="#cb49-880" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-ols</span></span>
<span id="cb49-881"><a href="#cb49-881" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Weighted least squares fit'</span></span>
<span id="cb49-882"><a href="#cb49-882" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-883"><a href="#cb49-883" aria-hidden="true" tabindex="-1"></a>ols <span class="ot">&lt;-</span> <span class="fu">lm</span>(people<span class="sc">~</span>vehicle, <span class="at">data=</span>rangitikei)</span>
<span id="cb49-884"><a href="#cb49-884" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-885"><a href="#cb49-885" aria-hidden="true" tabindex="-1"></a>wts <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">/</span> <span class="fu">lm</span>(<span class="fu">abs</span>(ols<span class="sc">$</span>residuals) <span class="sc">~</span> ols<span class="sc">$</span>fitted.values)<span class="sc">$</span>fitted.values<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb49-886"><a href="#cb49-886" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-887"><a href="#cb49-887" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(rangitikei) <span class="sc">+</span></span>
<span id="cb49-888"><a href="#cb49-888" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x=</span>vehicle, <span class="at">y=</span>people) <span class="sc">+</span> </span>
<span id="cb49-889"><a href="#cb49-889" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb49-890"><a href="#cb49-890" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">"lm"</span>, <span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">weight =</span> wts)) <span class="sc">+</span> </span>
<span id="cb49-891"><a href="#cb49-891" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Weighted regression"</span>) <span class="sc">+</span> </span>
<span id="cb49-892"><a href="#cb49-892" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">label =</span> <span class="st">"# 26"</span>, <span class="at">x =</span> <span class="dv">115</span>, <span class="at">y =</span> <span class="dv">475</span>, <span class="at">size =</span> <span class="dv">4</span>, <span class="at">colour =</span> <span class="st">"blue"</span>)</span>
<span id="cb49-893"><a href="#cb49-893" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-894"><a href="#cb49-894" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-895"><a href="#cb49-895" aria-hidden="true" tabindex="-1"></a>*median-median or resistant line*</span>
<span id="cb49-896"><a href="#cb49-896" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-897"><a href="#cb49-897" aria-hidden="true" tabindex="-1"></a>The median--median line is an alternative to the least squares regression and is resistant or robust to outliers. To obtain this line, we divide the data into three equal size groups after sorting the $X$ variable data. If equal division cannot be done, the middle group can be larger than the low and high groups. For the low and high groups, obtain the medians of the $X$ and $Y$ values separately. The median--median line (also called Rline) is the line joining these two sets of median points. A more sophisticated version of fitting a resistant line is available in statistical software programs including R, which mainly implement the procedure suggested by @Hoaglin1983. Such approaches place additional restrictions on the residuals of the fitted resistant line or shift the original line one-third of the way from its original position toward the median-median point of the middle group.</span>
<span id="cb49-898"><a href="#cb49-898" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-899"><a href="#cb49-899" aria-hidden="true" tabindex="-1"></a>The R function <span class="in">`line()`</span> will fit a resistant line using a method proposed by Tukey, and hence this fit is called **Tukey Line**.</span>
<span id="cb49-900"><a href="#cb49-900" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-903"><a href="#cb49-903" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-904"><a href="#cb49-904" aria-hidden="true" tabindex="-1"></a><span class="fu">download.file</span>(</span>
<span id="cb49-905"><a href="#cb49-905" aria-hidden="true" tabindex="-1"></a>  <span class="at">url =</span> <span class="st">"http://www.massey.ac.nz/~anhsmith/data/testmarks.RData"</span>, </span>
<span id="cb49-906"><a href="#cb49-906" aria-hidden="true" tabindex="-1"></a>  <span class="at">destfile =</span> <span class="st">"testmarks.RData"</span>)</span>
<span id="cb49-907"><a href="#cb49-907" aria-hidden="true" tabindex="-1"></a><span class="fu">load</span>(<span class="st">"testmarks.RData"</span>)</span>
<span id="cb49-908"><a href="#cb49-908" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-909"><a href="#cb49-909" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-910"><a href="#cb49-910" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, echo= TRUE, results= FALSE}</span></span>
<span id="cb49-911"><a href="#cb49-911" aria-hidden="true" tabindex="-1"></a><span class="fu">line</span>(<span class="at">x=</span> testmarks<span class="sc">$</span>Maths, <span class="at">y=</span>testmarks<span class="sc">$</span>English)</span>
<span id="cb49-912"><a href="#cb49-912" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-913"><a href="#cb49-913" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-914"><a href="#cb49-914" aria-hidden="true" tabindex="-1"></a>The fitted Tukey line is shown in @fig-tukline:</span>
<span id="cb49-915"><a href="#cb49-915" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-918"><a href="#cb49-918" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-919"><a href="#cb49-919" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb49-920"><a href="#cb49-920" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-show: hide</span></span>
<span id="cb49-921"><a href="#cb49-921" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-922"><a href="#cb49-922" aria-hidden="true" tabindex="-1"></a>Tukeyline <span class="ot">&lt;-</span> <span class="fu">line</span>(<span class="at">x =</span> testmarks<span class="sc">$</span>Maths, <span class="at">y =</span> testmarks<span class="sc">$</span>English)</span>
<span id="cb49-923"><a href="#cb49-923" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-924"><a href="#cb49-924" aria-hidden="true" tabindex="-1"></a>testmarks <span class="sc">|&gt;</span> </span>
<span id="cb49-925"><a href="#cb49-925" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">fits=</span><span class="fu">fitted</span>(Tukeyline)) <span class="sc">|&gt;</span> </span>
<span id="cb49-926"><a href="#cb49-926" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>() <span class="sc">+</span> </span>
<span id="cb49-927"><a href="#cb49-927" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x =</span> Maths, <span class="at">y =</span> English) <span class="sc">+</span> </span>
<span id="cb49-928"><a href="#cb49-928" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb49-929"><a href="#cb49-929" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">x=</span>Maths, <span class="at">y=</span>fits))</span>
<span id="cb49-930"><a href="#cb49-930" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-931"><a href="#cb49-931" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-934"><a href="#cb49-934" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-935"><a href="#cb49-935" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb49-936"><a href="#cb49-936" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-tukline</span></span>
<span id="cb49-937"><a href="#cb49-937" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Tukey line fit'</span></span>
<span id="cb49-938"><a href="#cb49-938" aria-hidden="true" tabindex="-1"></a>rline <span class="ot">&lt;-</span> <span class="fu">line</span>(<span class="at">x =</span> testmarks<span class="sc">$</span>Maths, <span class="at">y =</span> testmarks<span class="sc">$</span>English)</span>
<span id="cb49-939"><a href="#cb49-939" aria-hidden="true" tabindex="-1"></a>intercept  <span class="ot">&lt;-</span>  rline<span class="sc">$</span>coefficients[<span class="dv">1</span>]</span>
<span id="cb49-940"><a href="#cb49-940" aria-hidden="true" tabindex="-1"></a>slope  <span class="ot">&lt;-</span>  rline<span class="sc">$</span>coefficients[<span class="dv">2</span>]</span>
<span id="cb49-941"><a href="#cb49-941" aria-hidden="true" tabindex="-1"></a>my.caption<span class="ot">=</span><span class="fu">paste</span>(<span class="st">"Slope="</span>, <span class="fu">round</span>(slope,<span class="dv">2</span>), <span class="st">"  "</span>, <span class="st">"Intercept"</span>, <span class="fu">round</span>(intercept,<span class="dv">2</span>))</span>
<span id="cb49-942"><a href="#cb49-942" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb49-943"><a href="#cb49-943" aria-hidden="true" tabindex="-1"></a>my.plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(testmarks, <span class="fu">aes</span>(<span class="at">x =</span> Maths, <span class="at">y =</span> English)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span>
<span id="cb49-944"><a href="#cb49-944" aria-hidden="true" tabindex="-1"></a>my.plot <span class="ot">&lt;-</span> my.plot <span class="sc">+</span> <span class="fu">geom_abline</span>(<span class="fu">aes</span>(<span class="at">slope =</span> slope, <span class="at">intercept =</span> intercept), <span class="at">color =</span> <span class="st">"red"</span>) </span>
<span id="cb49-945"><a href="#cb49-945" aria-hidden="true" tabindex="-1"></a>my.plot <span class="ot">&lt;-</span> my.plot <span class="sc">+</span> <span class="fu">ggtitle</span>(<span class="st">"line() fit - Tukey line"</span>) <span class="sc">+</span><span class="fu">labs</span>(<span class="at">caption =</span> my.caption)</span>
<span id="cb49-946"><a href="#cb49-946" aria-hidden="true" tabindex="-1"></a>my.plot </span>
<span id="cb49-947"><a href="#cb49-947" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-948"><a href="#cb49-948" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-949"><a href="#cb49-949" aria-hidden="true" tabindex="-1"></a>There are variations to robust modelling. We may use the means rather than medians in each group after dividing the data into three parts. Generally speaking, if the data set is large or the residuals distributed nearly normally then the means of the lower and upper groups are more appropriate than the medians. The other approaches include (i) minimising the sum of absolute residuals (ii) least median of squares (LMS) etc.</span>
<span id="cb49-950"><a href="#cb49-950" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-951"><a href="#cb49-951" aria-hidden="true" tabindex="-1"></a>For best fitting procedures, we minimise the residuals in some way - for example, by minimising $\Sigma e_{i}^{p}$ for some value of *p*. For fitting regression lines, we use the method of least squares where *p* = 2, i.e. the fitted line is such that the sum of squares of the residuals is as small as possible. However this procedure of minimising sums of squares is unduly affected by large residuals and so the regression line is pulled towards points which would give large residuals.</span>
<span id="cb49-952"><a href="#cb49-952" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-953"><a href="#cb49-953" aria-hidden="true" tabindex="-1"></a>Unusual observations of $Y$ tend to have more influence on the line than we would like. Some authors suggest that a better value for *p* would be 1.5. Another approach is to use *p* = 2 if the residuals are of moderate size but to reduce the value of *p* if the residual is large. Alternatively, if the residual is larger in absolute value than some high but realistic value then the residual is replaced by this value with the appropriate sign. Other procedures have also been devised which limit the influence on the regression line of unusually large or small values of $Y$.</span>
<span id="cb49-954"><a href="#cb49-954" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-955"><a href="#cb49-955" aria-hidden="true" tabindex="-1"></a>The advantage of robust estimation is that a few peculiar values of data do not have a large influence on the estimates. However the theory behind the statistical tests done on the estimated coefficients is more complicated when compared to the traditional methods. Two further R based robust methods of fitting lines are discussed below.</span>
<span id="cb49-956"><a href="#cb49-956" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-957"><a href="#cb49-957" aria-hidden="true" tabindex="-1"></a>The <span class="in">`R`</span> package function <span class="in">`rlm()`</span> fits a robust linear model using an iterative procedure method, and we will not cover the theory behind this method in this course.</span>
<span id="cb49-958"><a href="#cb49-958" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-961"><a href="#cb49-961" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-962"><a href="#cb49-962" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb49-963"><a href="#cb49-963" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-show: hide</span></span>
<span id="cb49-964"><a href="#cb49-964" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-965"><a href="#cb49-965" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(testmarks) <span class="sc">+</span></span>
<span id="cb49-966"><a href="#cb49-966" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x =</span> Maths, <span class="at">y =</span> English) <span class="sc">+</span> </span>
<span id="cb49-967"><a href="#cb49-967" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb49-968"><a href="#cb49-968" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">"rlm"</span>)</span>
<span id="cb49-969"><a href="#cb49-969" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-970"><a href="#cb49-970" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-973"><a href="#cb49-973" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-974"><a href="#cb49-974" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb49-975"><a href="#cb49-975" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Graph showing robust linear fit'</span></span>
<span id="cb49-976"><a href="#cb49-976" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-977"><a href="#cb49-977" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS, <span class="at">exclude =</span> <span class="st">"select"</span>)</span>
<span id="cb49-978"><a href="#cb49-978" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-979"><a href="#cb49-979" aria-hidden="true" tabindex="-1"></a>rlm.line <span class="ot">&lt;-</span> <span class="fu">rlm</span>(English <span class="sc">~</span> Maths, <span class="at">data =</span> testmarks)</span>
<span id="cb49-980"><a href="#cb49-980" aria-hidden="true" tabindex="-1"></a>intercept  <span class="ot">&lt;-</span>  rlm.line<span class="sc">$</span>coefficients[<span class="dv">1</span>]</span>
<span id="cb49-981"><a href="#cb49-981" aria-hidden="true" tabindex="-1"></a>slope  <span class="ot">&lt;-</span>  rlm.line<span class="sc">$</span>coefficients[<span class="dv">2</span>]</span>
<span id="cb49-982"><a href="#cb49-982" aria-hidden="true" tabindex="-1"></a>my.caption<span class="ot">=</span><span class="fu">paste</span>(<span class="st">"Slope="</span>, <span class="fu">round</span>(slope,<span class="dv">2</span>), <span class="st">"  "</span>, <span class="st">"Intercept"</span>, <span class="fu">round</span>(intercept,<span class="dv">2</span>))</span>
<span id="cb49-983"><a href="#cb49-983" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb49-984"><a href="#cb49-984" aria-hidden="true" tabindex="-1"></a>my.plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(testmarks, <span class="fu">aes</span>(<span class="at">x =</span> Maths, <span class="at">y =</span> English)) <span class="sc">+</span> <span class="fu">geom_point</span>()</span>
<span id="cb49-985"><a href="#cb49-985" aria-hidden="true" tabindex="-1"></a>my.plot <span class="ot">&lt;-</span> my.plot <span class="sc">+</span>  <span class="fu">geom_abline</span>(<span class="fu">aes</span>(<span class="at">slope =</span> slope, <span class="at">intercept =</span> intercept), <span class="at">color =</span> <span class="st">"blue"</span>)</span>
<span id="cb49-986"><a href="#cb49-986" aria-hidden="true" tabindex="-1"></a>my.plot <span class="ot">&lt;-</span> my.plot <span class="sc">+</span>  <span class="fu">ggtitle</span>(<span class="st">"rlm() fit - MASS package"</span>) <span class="sc">+</span><span class="fu">labs</span>(<span class="at">caption =</span> my.caption)</span>
<span id="cb49-987"><a href="#cb49-987" aria-hidden="true" tabindex="-1"></a>my.plot </span>
<span id="cb49-988"><a href="#cb49-988" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-989"><a href="#cb49-989" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-990"><a href="#cb49-990" aria-hidden="true" tabindex="-1"></a>The <span class="in">`R`</span> package <span class="in">`robustbase`</span> function <span class="in">`lmrob()`</span> is another option; see @fig-robbaseline.</span>
<span id="cb49-991"><a href="#cb49-991" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-994"><a href="#cb49-994" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-995"><a href="#cb49-995" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb49-996"><a href="#cb49-996" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-robbaseline</span></span>
<span id="cb49-997"><a href="#cb49-997" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Graph showing robust regression'</span></span>
<span id="cb49-998"><a href="#cb49-998" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(testmarks) <span class="sc">+</span> </span>
<span id="cb49-999"><a href="#cb49-999" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x =</span> Maths, <span class="at">y =</span> English) <span class="sc">+</span> </span>
<span id="cb49-1000"><a href="#cb49-1000" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb49-1001"><a href="#cb49-1001" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">"lmrob"</span>)</span>
<span id="cb49-1002"><a href="#cb49-1002" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1003"><a href="#cb49-1003" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1004"><a href="#cb49-1004" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1007"><a href="#cb49-1007" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1008"><a href="#cb49-1008" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(robustbase)</span>
<span id="cb49-1009"><a href="#cb49-1009" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1010"><a href="#cb49-1010" aria-hidden="true" tabindex="-1"></a><span class="fu">lmrob</span>(English <span class="sc">~</span> Maths, <span class="at">data =</span> testmarks) <span class="sc">|&gt;</span> <span class="fu">summary</span>()</span>
<span id="cb49-1011"><a href="#cb49-1011" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1012"><a href="#cb49-1012" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1013"><a href="#cb49-1013" aria-hidden="true" tabindex="-1"></a>The slope estimates are similar for the above robust fits. The standard error of the estimated y-intercept is usually large. The slope of the line being the important parameter, we may conclude that the fitted slope of 0.72 is the robust value.</span>
<span id="cb49-1014"><a href="#cb49-1014" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1015"><a href="#cb49-1015" aria-hidden="true" tabindex="-1"></a><span class="fu">## Cross Validation (CV)</span></span>
<span id="cb49-1016"><a href="#cb49-1016" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1017"><a href="#cb49-1017" aria-hidden="true" tabindex="-1"></a>This technique is commonly employed for validating models for prediction purposes. The available data is split randomly into $k$ (equal) folds (parts), often by resampling. A model is fitted for the $(k-1)$ folds of the data, and then the prediction errors are calculated for the fold that was omitted for modelling. This process can be repeated omitting one subset (out of the $k$ subsets) so that all the $k$ subsets contribute to the estimation of prediction accuracy. This exercise is computationally intensive, and hence we will leave it to the software package such as *caret*, *rsample* or *modelr* to perform the cross validation. Consider the simple regression of WEIGHT on EXTDIA done with the horsesheart data. The following <span class="in">`R`</span> code perform the 5-fold cross validation of the model for prediction purposes and compare the root mean square errors for both the regression and robust regression models.</span>
<span id="cb49-1018"><a href="#cb49-1018" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1021"><a href="#cb49-1021" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1022"><a href="#cb49-1022" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb49-1023"><a href="#cb49-1023" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb49-1024"><a href="#cb49-1024" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-cvgraph</span></span>
<span id="cb49-1025"><a href="#cb49-1025" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Comparison of Residual Mean Square Error (RMSE) of lm() vs rlm() fits'</span></span>
<span id="cb49-1026"><a href="#cb49-1026" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1027"><a href="#cb49-1027" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb49-1028"><a href="#cb49-1028" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS, <span class="at">exclude =</span> <span class="st">"select"</span>)</span>
<span id="cb49-1029"><a href="#cb49-1029" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1030"><a href="#cb49-1030" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb49-1031"><a href="#cb49-1031" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1032"><a href="#cb49-1032" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up cross validation</span></span>
<span id="cb49-1033"><a href="#cb49-1033" aria-hidden="true" tabindex="-1"></a>fitControl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"repeatedcv"</span>, </span>
<span id="cb49-1034"><a href="#cb49-1034" aria-hidden="true" tabindex="-1"></a>                           <span class="at">number =</span> <span class="dv">5</span>, </span>
<span id="cb49-1035"><a href="#cb49-1035" aria-hidden="true" tabindex="-1"></a>                           <span class="at">repeats =</span> <span class="dv">100</span>)</span>
<span id="cb49-1036"><a href="#cb49-1036" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1037"><a href="#cb49-1037" aria-hidden="true" tabindex="-1"></a><span class="co"># lmfit</span></span>
<span id="cb49-1038"><a href="#cb49-1038" aria-hidden="true" tabindex="-1"></a>lmfit <span class="ot">&lt;-</span>  <span class="fu">train</span>(WEIGHT <span class="sc">~</span> EXTDIA,</span>
<span id="cb49-1039"><a href="#cb49-1039" aria-hidden="true" tabindex="-1"></a>                <span class="at">data =</span> horsehearts, </span>
<span id="cb49-1040"><a href="#cb49-1040" aria-hidden="true" tabindex="-1"></a>                <span class="at">trControl =</span> fitControl, </span>
<span id="cb49-1041"><a href="#cb49-1041" aria-hidden="true" tabindex="-1"></a>                <span class="at">method =</span> <span class="st">"lm"</span>)</span>
<span id="cb49-1042"><a href="#cb49-1042" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1043"><a href="#cb49-1043" aria-hidden="true" tabindex="-1"></a><span class="co"># rlmfit</span></span>
<span id="cb49-1044"><a href="#cb49-1044" aria-hidden="true" tabindex="-1"></a>rlmfit <span class="ot">&lt;-</span> <span class="fu">train</span>(WEIGHT <span class="sc">~</span> EXTDIA, </span>
<span id="cb49-1045"><a href="#cb49-1045" aria-hidden="true" tabindex="-1"></a>                <span class="at">data =</span> horsehearts, </span>
<span id="cb49-1046"><a href="#cb49-1046" aria-hidden="true" tabindex="-1"></a>                <span class="at">trControl =</span> fitControl, </span>
<span id="cb49-1047"><a href="#cb49-1047" aria-hidden="true" tabindex="-1"></a>                <span class="at">method =</span> <span class="st">"rlm"</span>)</span>
<span id="cb49-1048"><a href="#cb49-1048" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1049"><a href="#cb49-1049" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the RMSE scores</span></span>
<span id="cb49-1050"><a href="#cb49-1050" aria-hidden="true" tabindex="-1"></a>dfm <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb49-1051"><a href="#cb49-1051" aria-hidden="true" tabindex="-1"></a>  <span class="at">lm =</span> lmfit <span class="sc">|&gt;</span> <span class="fu">pluck</span>(<span class="st">"resample"</span>) <span class="sc">|&gt;</span> <span class="fu">pull</span>(RMSE),</span>
<span id="cb49-1052"><a href="#cb49-1052" aria-hidden="true" tabindex="-1"></a>  <span class="at">rlm =</span> rlmfit <span class="sc">|&gt;</span> <span class="fu">pluck</span>(<span class="st">"resample"</span>) <span class="sc">|&gt;</span> <span class="fu">pull</span>(RMSE)</span>
<span id="cb49-1053"><a href="#cb49-1053" aria-hidden="true" tabindex="-1"></a>) <span class="sc">|&gt;</span> </span>
<span id="cb49-1054"><a href="#cb49-1054" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols=</span><span class="fu">everything</span>(),</span>
<span id="cb49-1055"><a href="#cb49-1055" aria-hidden="true" tabindex="-1"></a>               <span class="at">names_to =</span> <span class="st">"Method"</span>,</span>
<span id="cb49-1056"><a href="#cb49-1056" aria-hidden="true" tabindex="-1"></a>               <span class="at">values_to =</span> <span class="st">"RMSE"</span>)</span>
<span id="cb49-1057"><a href="#cb49-1057" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb49-1058"><a href="#cb49-1058" aria-hidden="true" tabindex="-1"></a><span class="co"># Make plot of RMSE</span></span>
<span id="cb49-1059"><a href="#cb49-1059" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dfm) <span class="sc">+</span></span>
<span id="cb49-1060"><a href="#cb49-1060" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x=</span>Method, <span class="at">y=</span>RMSE, <span class="at">col =</span> Method) <span class="sc">+</span> </span>
<span id="cb49-1061"><a href="#cb49-1061" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>() <span class="sc">+</span></span>
<span id="cb49-1062"><a href="#cb49-1062" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span> </span>
<span id="cb49-1063"><a href="#cb49-1063" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>)</span>
<span id="cb49-1064"><a href="#cb49-1064" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1065"><a href="#cb49-1065" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1066"><a href="#cb49-1066" aria-hidden="true" tabindex="-1"></a>@fig-cvgraph shows that the robust <span class="in">`rlm()`</span> fit slightly outperforms the simple regression fit in terms of RMSE. The number of folds fixed can affect the comparison. The choice of k=5 or 10 is usually recommended.</span>
<span id="cb49-1067"><a href="#cb49-1067" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1068"><a href="#cb49-1068" aria-hidden="true" tabindex="-1"></a>@fig-cvgraph1 shows the cross validation RMSEs for the <span class="in">`lm()`</span> and <span class="in">`rlm()`</span> fits for the Rangitikei dataset based on <span class="in">`modelr`</span> package codes. The robust model again perform slightly better but this does not mean the fitted model is the best one for prediction.</span>
<span id="cb49-1069"><a href="#cb49-1069" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1072"><a href="#cb49-1072" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1073"><a href="#cb49-1073" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb49-1074"><a href="#cb49-1074" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb49-1075"><a href="#cb49-1075" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-cvgraph1</span></span>
<span id="cb49-1076"><a href="#cb49-1076" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Comparison of RMSEs of lm() and rlm() fits under cross validation'</span></span>
<span id="cb49-1077"><a href="#cb49-1077" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(purrr)</span>
<span id="cb49-1078"><a href="#cb49-1078" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(modelr)</span>
<span id="cb49-1079"><a href="#cb49-1079" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1080"><a href="#cb49-1080" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb49-1081"><a href="#cb49-1081" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1082"><a href="#cb49-1082" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up cross validation</span></span>
<span id="cb49-1083"><a href="#cb49-1083" aria-hidden="true" tabindex="-1"></a>cv2 <span class="ot">&lt;-</span> <span class="fu">crossv_mc</span>(rangitikei, <span class="dv">500</span>)</span>
<span id="cb49-1084"><a href="#cb49-1084" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1085"><a href="#cb49-1085" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the models</span></span>
<span id="cb49-1086"><a href="#cb49-1086" aria-hidden="true" tabindex="-1"></a>lm_models <span class="ot">&lt;-</span> <span class="fu">map</span>(cv2<span class="sc">$</span>train, <span class="sc">~</span> <span class="fu">lm</span>(people <span class="sc">~</span> vehicle, <span class="at">data =</span> .))</span>
<span id="cb49-1087"><a href="#cb49-1087" aria-hidden="true" tabindex="-1"></a>rlm_models <span class="ot">&lt;-</span> <span class="fu">map</span>(cv2<span class="sc">$</span>train, <span class="sc">~</span> <span class="fu">rlm</span>(people <span class="sc">~</span> vehicle, <span class="at">data =</span> .))</span>
<span id="cb49-1088"><a href="#cb49-1088" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1089"><a href="#cb49-1089" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the RMSE scores</span></span>
<span id="cb49-1090"><a href="#cb49-1090" aria-hidden="true" tabindex="-1"></a>dfm <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb49-1091"><a href="#cb49-1091" aria-hidden="true" tabindex="-1"></a>  <span class="at">lm =</span> <span class="fu">map2_dbl</span>(lm_models, cv2<span class="sc">$</span>test, rmse),</span>
<span id="cb49-1092"><a href="#cb49-1092" aria-hidden="true" tabindex="-1"></a>  <span class="at">rlm =</span> <span class="fu">map2_dbl</span>(rlm_models, cv2<span class="sc">$</span>test, rmse)</span>
<span id="cb49-1093"><a href="#cb49-1093" aria-hidden="true" tabindex="-1"></a>) <span class="sc">|&gt;</span> </span>
<span id="cb49-1094"><a href="#cb49-1094" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols=</span><span class="fu">everything</span>(),</span>
<span id="cb49-1095"><a href="#cb49-1095" aria-hidden="true" tabindex="-1"></a>               <span class="at">names_to =</span> <span class="st">"Method"</span>,</span>
<span id="cb49-1096"><a href="#cb49-1096" aria-hidden="true" tabindex="-1"></a>               <span class="at">values_to =</span> <span class="st">"RMSE"</span>)</span>
<span id="cb49-1097"><a href="#cb49-1097" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1098"><a href="#cb49-1098" aria-hidden="true" tabindex="-1"></a><span class="co"># Make a plot</span></span>
<span id="cb49-1099"><a href="#cb49-1099" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dfm) <span class="sc">+</span></span>
<span id="cb49-1100"><a href="#cb49-1100" aria-hidden="true" tabindex="-1"></a>  <span class="fu">aes</span>(<span class="at">x=</span>Method, <span class="at">y=</span>RMSE, <span class="at">col =</span> Method) <span class="sc">+</span> </span>
<span id="cb49-1101"><a href="#cb49-1101" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>() <span class="sc">+</span></span>
<span id="cb49-1102"><a href="#cb49-1102" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span> </span>
<span id="cb49-1103"><a href="#cb49-1103" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"none"</span>)</span>
<span id="cb49-1104"><a href="#cb49-1104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1105"><a href="#cb49-1105" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1106"><a href="#cb49-1106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1107"><a href="#cb49-1107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1108"><a href="#cb49-1108" aria-hidden="true" tabindex="-1"></a><span class="fu"># Summary</span></span>
<span id="cb49-1109"><a href="#cb49-1109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1110"><a href="#cb49-1110" aria-hidden="true" tabindex="-1"></a>Once a model is fitted to data, the question must be asked as to whether the fit is a good one. Perhaps it would be more in keeping with the spirit of statistical tests to ask if the fit is bad. The fitted model is of the general form</span>
<span id="cb49-1111"><a href="#cb49-1111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1112"><a href="#cb49-1112" aria-hidden="true" tabindex="-1"></a>$$ \text{observation = fit+ residual}$$</span>
<span id="cb49-1113"><a href="#cb49-1113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1114"><a href="#cb49-1114" aria-hidden="true" tabindex="-1"></a>Model improvement will take place to capture all the systematic variation in the data. This chapter considered only straight line models with a single predictor variable. If the fit is poor, a transformation could be tried by stretching or shrinking $Y$ by a power transformation.</span>
<span id="cb49-1115"><a href="#cb49-1115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1116"><a href="#cb49-1116" aria-hidden="true" tabindex="-1"></a>Scatterplots and correlation coefficients provide important clues to the inter-relationships between the variables and hence form the first step in building a regression model. The simple regression model is one of the most commonly used tools. Here the main aim is to fit a model (slope and $y$-intercept) by the least squares method to explain the variation in $Y$, the response variable, by fitting the explanatory ($X$) variable. Regression models are often improved in several ways after residual analysis.</span>
<span id="cb49-1117"><a href="#cb49-1117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1118"><a href="#cb49-1118" aria-hidden="true" tabindex="-1"></a>**What is THE best model for this data?** If there is an answer to this question, it should not be determined solely on statistical grounds. Statistics as a tool (often a very powerful tool) can only suggest the best model given that a number of assumptions have been agreed on. Ideally, one would not have to make a decision on the basis of a single sample as we have here. We should examine the literature to discover similar examples and see how they were tackled or, even better, one could discuss the matter with a researcher who has worked on similar data sets. If the aim is to estimate the coefficients or to predict the weight of the heart of another living horse from ultrasound measurements, we tend to select the simplest, feasible model. In this case, we could choose a model with ONE predictor variable (say *innerdia*). And a cube root or logarithm transformation might be applied. With more than one explanatory variable, the number of possibilities increases for relationships between these variables and between the response variable $Y$. These possibilities will be discussed further in the next chapter.</span>
<span id="cb49-1119"><a href="#cb49-1119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1120"><a href="#cb49-1120" aria-hidden="true" tabindex="-1"></a><span class="fu">## Main points</span></span>
<span id="cb49-1121"><a href="#cb49-1121" aria-hidden="true" tabindex="-1"></a>Concepts and practical skills you should have at the end of this chapter:</span>
<span id="cb49-1122"><a href="#cb49-1122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1123"><a href="#cb49-1123" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Understand and be able to perform a simple linear regression on bivariate related data sets</span>
<span id="cb49-1124"><a href="#cb49-1124" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Use scatter plots or other appropriate plots to visualize the data and regression line</span>
<span id="cb49-1125"><a href="#cb49-1125" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Summarize regression results and appropriate tests of significance. Interpret these results in context of your data</span>
<span id="cb49-1126"><a href="#cb49-1126" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Examine residual diagnostic plots and test assumptions, then perform appropriate transformations as necessary</span>
<span id="cb49-1127"><a href="#cb49-1127" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Use a regression line to predict new data and explain confidence and prediction intervals</span>
<span id="cb49-1128"><a href="#cb49-1128" aria-hidden="true" tabindex="-1"></a><span class="ss">-   </span>Understand and explain the concepts of robust regression modeling, Tukey Line, and cross-validation.</span>
<span id="cb49-1129"><a href="#cb49-1129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1130"><a href="#cb49-1130" aria-hidden="true" tabindex="-1"></a><span class="fu">## Models Related to Simple Regression Model</span></span>
<span id="cb49-1131"><a href="#cb49-1131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1132"><a href="#cb49-1132" aria-hidden="true" tabindex="-1"></a>For some applications, the true $y$-intercept $\alpha$ is *known* to be zero. An example is when a model is fitted with compositional characteristics as predictors such as percentage fat, protein, moisture in milk powder. The sum of these compositional characteristics is always 100% and this constraint removes the intercept due to theoretical reasons. In such cases, we will be fitting only the slope(s). When the model without the $y$-intercept is the true or correct model, both the fitted models (with and without the $y$-intercept) provide unbiased estimates of the true parameters. However the model without the intercept will provide precise estimates. This regression model without the intercept must be used with caution because a very strong assumption is made on the true $y$-intercept. The first differences of certain time series data may be analysed with a model having no intercept term.</span>
<span id="cb49-1133"><a href="#cb49-1133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1134"><a href="#cb49-1134" aria-hidden="true" tabindex="-1"></a>For some applications such as measurement system analysis in metrology **orthogonal regression** models are fitted because both X and Y variables are subject to measurement errors. In the least squares method, we minimise the sum of the squared vertical distances between the actual Y and fitted Y values. For orthogonal regression, we consider the perpendicular distances instead. This approach is a subset of a theory known as **principal components**. The orthogonal regression approach was popularised by Deming for industrial applications and hence this fit is also known as **Deming regression**. `R` software packages (such as `MethComp`, `deming` and `mcr`) will fit orthogonal regression models. @fig-dmng shows the Deming regression model to **testmarks** data but you do not have to perform this regression for this course.</span>
<span id="cb49-1135"><a href="#cb49-1135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1138"><a href="#cb49-1138" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1139"><a href="#cb49-1139" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb49-1140"><a href="#cb49-1140" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-dmng</span></span>
<span id="cb49-1141"><a href="#cb49-1141" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: 'Orthogonal regression'</span></span>
<span id="cb49-1142"><a href="#cb49-1142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1143"><a href="#cb49-1143" aria-hidden="true" tabindex="-1"></a>my.pca <span class="ot">&lt;-</span> <span class="fu">prcomp</span>( <span class="sc">~</span> Maths<span class="sc">+</span>English, <span class="at">data=</span>testmarks)</span>
<span id="cb49-1144"><a href="#cb49-1144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1145"><a href="#cb49-1145" aria-hidden="true" tabindex="-1"></a>slp <span class="ot">&lt;-</span> my.pca<span class="sc">$</span>rotation[<span class="dv">2</span>,<span class="dv">1</span>] <span class="sc">/</span> my.pca<span class="sc">$</span>rotation[<span class="dv">1</span>,<span class="dv">1</span>]</span>
<span id="cb49-1146"><a href="#cb49-1146" aria-hidden="true" tabindex="-1"></a>intr <span class="ot">&lt;-</span> my.pca<span class="sc">$</span>center[<span class="dv">2</span>] <span class="sc">-</span> slp<span class="sc">*</span>my.pca<span class="sc">$</span>center[<span class="dv">1</span>]</span>
<span id="cb49-1147"><a href="#cb49-1147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1148"><a href="#cb49-1148" aria-hidden="true" tabindex="-1"></a>my.caption <span class="ot">=</span> <span class="fu">paste</span>(<span class="st">"Slope="</span>, <span class="fu">round</span>(slp, <span class="dv">2</span>), <span class="st">"  "</span>, <span class="st">"Intercept"</span>, <span class="fu">round</span>(intr, <span class="dv">2</span>))</span>
<span id="cb49-1149"><a href="#cb49-1149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1150"><a href="#cb49-1150" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(testmarks) <span class="sc">+</span> </span>
<span id="cb49-1151"><a href="#cb49-1151" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x=</span>Maths,<span class="at">y=</span>English)) <span class="sc">+</span> </span>
<span id="cb49-1152"><a href="#cb49-1152" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> intr, <span class="at">slope =</span> slp) <span class="sc">+</span> </span>
<span id="cb49-1153"><a href="#cb49-1153" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Orthogonal Regression"</span>) <span class="sc">+</span> </span>
<span id="cb49-1154"><a href="#cb49-1154" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">caption =</span> my.caption)</span>
<span id="cb49-1155"><a href="#cb49-1155" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1156"><a href="#cb49-1156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1157"><a href="#cb49-1157" aria-hidden="true" tabindex="-1"></a>A number of relationships between variables can be linearised by transformations. For example, the relationship $y=\alpha x^{\beta }$ is linearised by taking $\log$ on both sides as $$\log (y)=\log (\alpha )+\beta \log (x).$$ The methods discussed in this chapter will equally apply for models which can be rewritten as a straight line equation.</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>